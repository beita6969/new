{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.4789915966386555</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.round_16.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        # Use Programmer to generate and execute Python code\\n        code_solution = await self.programmer(problem=problem)\\n        \\n        # Use Custom to refine and format the answer\\n        refined_solution = await self.custom(input=problem + f\\\"\\\\nCode output: {code_solution['output']}\\\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\\n        \\n        # Generate multiple solutions using Custom\\n        solutions = []\\n        for _ in range(3):\\n            solution = await self.custom(input=problem, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        # Generate a detailed step-by-step solution\\n        detailed_solution = await self.custom(input=problem, instruction=prompt_custom.DETAILED_SOLUTION_PROMPT)\\n        solutions.append(detailed_solution['response'])\\n        \\n        # Use ScEnsemble to select the best solution\\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the mathematical problem and the output from the code execution, please provide a well-formatted and detailed solution. Follow these guidelines:\\n\\n1. Begin with a clear statement of the problem.\\n2. Explain the approach and any formulas or concepts used.\\n3. Show step-by-step calculations, using LaTeX notation for mathematical expressions.\\n4. Interpret the code output and incorporate it into your explanation.\\n5. Provide a final answer, enclosed in \\\\boxed{} LaTeX notation.\\n6. Ensure all mathematical notation is in LaTeX format.\\n\\nYour response should be comprehensive, mathematically rigorous, and easy to follow.\\n\\\"\\\"\\\"\\n\\nGENERATE_SOLUTION_PROMPT = \\\"\\\"\\\"\\nPlease solve the given mathematical problem step by step. Follow these guidelines:\\n\\n1. State the problem clearly.\\n2. Outline the approach and any relevant formulas or concepts.\\n3. Provide detailed calculations, using LaTeX notation for mathematical expressions.\\n4. Explain each step of your reasoning.\\n5. Present the final answer enclosed in \\\\boxed{} LaTeX notation.\\n6. Ensure all mathematical notation is in LaTeX format.\\n\\nYour solution should be thorough, mathematically sound, and easy to understand.\\n\\\"\\\"\\\"\\n\\nDETAILED_SOLUTION_PROMPT = \\\"\\\"\\\"\\nProvide a comprehensive, step-by-step solution to the given mathematical problem. Your response should include:\\n\\n1. A clear restatement of the problem.\\n2. An explanation of the mathematical concepts and formulas involved.\\n3. A detailed, logical progression of steps to solve the problem.\\n4. Clear explanations for each step, including the reasoning behind it.\\n5. All mathematical expressions and equations in LaTeX format.\\n6. Visual aids or diagrams if applicable (described in text).\\n7. A final answer clearly marked and enclosed in \\\\boxed{} LaTeX notation.\\n8. A brief explanation of the significance of the answer in the context of the original problem.\\n\\nAim for clarity, accuracy, and thoroughness in your solution.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 17</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.round_17.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        # Use Programmer to generate and execute Python code\n        code_solution = await self.programmer(problem=problem)\n        \n        # Use Custom to refine and format the answer\n        refined_solution = await self.custom(input=problem + f\"\\nCode output: {code_solution['output']}\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n        \n        # Generate a detailed step-by-step solution using Custom\n        detailed_solution = await self.custom(input=problem, instruction=prompt_custom.DETAILED_SOLUTION_PROMPT)\n        \n        # Generate multiple solutions using Custom with different approaches\n        solutions = [\n            refined_solution['response'],\n            detailed_solution['response']\n        ]\n        for approach in ['algebraic', 'geometric', 'analytical']:\n            solution = await self.custom(input=problem, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT.format(approach=approach))\n            solutions.append(solution['response'])\n        \n        # Use ScEnsemble to select the best solution\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>REFINE_ANSWER_PROMPT = \"\"\"\nGiven the mathematical problem and the output from the code execution, please provide a well-formatted and detailed solution. Follow these guidelines:\n\n1. Begin with a clear statement of the problem.\n2. Explain the approach and any formulas or concepts used.\n3. Show step-by-step calculations, using LaTeX notation for mathematical expressions.\n4. Interpret the code output and incorporate it into your explanation.\n5. Provide a final answer, enclosed in \\boxed{} LaTeX notation.\n6. Ensure all mathematical notation is in LaTeX format.\n\nYour response should be comprehensive, mathematically rigorous, and easy to follow.\n\"\"\"\n\nGENERATE_SOLUTION_PROMPT = \"\"\"\nPlease solve the given mathematical problem using a {approach} approach. Follow these guidelines:\n\n1. State the problem clearly.\n2. Outline the {approach} approach and any relevant formulas or concepts.\n3. Provide detailed calculations, using LaTeX notation for mathematical expressions.\n4. Explain each step of your reasoning.\n5. Present the final answer enclosed in \\boxed{} LaTeX notation.\n6. Ensure all mathematical notation is in LaTeX format.\n\nYour solution should be thorough, mathematically sound, and easy to understand.\n\"\"\"\n\nDETAILED_SOLUTION_PROMPT = \"\"\"\nProvide a comprehensive, step-by-step solution to the given mathematical problem. Your response should include:\n\n1. A clear restatement of the problem.\n2. An explanation of the mathematical concepts and theorems involved.\n3. A detailed, logical progression of steps leading to the solution.\n4. Clear explanations for each step, including the reasoning behind it.\n5. All mathematical expressions and equations in LaTeX format.\n6. Visual aids or diagrams if applicable (described in text).\n7. A final answer clearly marked and enclosed in \\boxed{} LaTeX notation.\n8. A brief explanation of the significance of the result, if relevant.\n\nEnsure your solution is rigorous, easy to follow, and educational for someone learning the concept.\n\"\"\"</prompt>", "tag": "MATH", "domain": "llm_judge", "parent_round": 16, "child_round": 17, "parent_score": 0.4789915966386555, "child_score": 0.0, "performance_gain": -0.4789915966386555}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.5378151260504201</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.round_18.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        # Use Programmer to generate and execute Python code\\n        code_solution = await self.programmer(problem=problem)\\n        \\n        # Use Custom to generate a detailed step-by-step solution\\n        detailed_solution = await self.custom(input=problem + f\\\"\\\\nCode output: {code_solution['output']}\\\", instruction=prompt_custom.DETAILED_SOLUTION_PROMPT)\\n        \\n        # Use Custom to review and refine the solution\\n        refined_solution = await self.custom(input=problem + f\\\"\\\\nDetailed solution: {detailed_solution['response']}\\\", instruction=prompt_custom.REVIEW_AND_REFINE_PROMPT)\\n        \\n        # Generate multiple solutions using Custom\\n        solutions = []\\n        for _ in range(3):\\n            solution = await self.custom(input=problem, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        # Add refined_solution to the list of solutions\\n        solutions.append(refined_solution['response'])\\n        \\n        # Use ScEnsemble to select the best solution\\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>DETAILED_SOLUTION_PROMPT = \\\"\\\"\\\"\\nGiven the mathematical problem and the output from the code execution, please provide a comprehensive and detailed step-by-step solution. Follow these guidelines:\\n\\n1. Begin with a clear statement of the problem.\\n2. Explain the approach and any formulas or concepts used.\\n3. Show step-by-step calculations, using LaTeX notation for mathematical expressions.\\n4. Interpret the code output and incorporate it into your explanation.\\n5. Provide intermediate results and explanations for each step.\\n6. Ensure all mathematical notation is in LaTeX format.\\n7. Conclude with a final answer, enclosed in \\\\boxed{} LaTeX notation.\\n\\nYour response should be thorough, mathematically rigorous, and easy to follow, suitable for a student learning the concept.\\n\\\"\\\"\\\"\\n\\nREVIEW_AND_REFINE_PROMPT = \\\"\\\"\\\"\\nPlease review and refine the given detailed solution for the mathematical problem. Follow these guidelines:\\n\\n1. Check for mathematical accuracy and correctness.\\n2. Ensure all steps are logically connected and well-explained.\\n3. Verify that all LaTeX notation is correctly used and formatted.\\n4. Add any missing steps or explanations that could improve clarity.\\n5. Simplify overly complex explanations if possible.\\n6. Ensure the final answer is correct and properly enclosed in \\\\boxed{} LaTeX notation.\\n7. If any errors are found, correct them and explain the correction.\\n\\nProvide the refined solution, maintaining the step-by-step format and mathematical rigor of the original.\\n\\\"\\\"\\\"\\n\\nGENERATE_SOLUTION_PROMPT = \\\"\\\"\\\"\\nPlease solve the given mathematical problem step by step. Follow these guidelines:\\n\\n1. State the problem clearly.\\n2. Outline the approach and any relevant formulas or concepts.\\n3. Provide detailed calculations, using LaTeX notation for mathematical expressions.\\n4. Explain each step of your reasoning.\\n5. Present the final answer enclosed in \\\\boxed{} LaTeX notation.\\n6. Ensure all mathematical notation is in LaTeX format.\\n\\nYour solution should be thorough, mathematically sound, and easy to understand.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 19</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.round_19.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        # Use Programmer to generate and execute Python code\n        code_solution = await self.programmer(problem=problem)\n        \n        # Use Custom to refine and format the answer\n        refined_solution = await self.custom(input=problem + f\"\\nCode output: {code_solution['output']}\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n        \n        # Generate a detailed step-by-step solution using Custom\n        detailed_solution = await self.custom(input=problem, instruction=prompt_custom.DETAILED_SOLUTION_PROMPT)\n        \n        # Generate a simplified solution using Custom\n        simplified_solution = await self.custom(input=problem, instruction=prompt_custom.SIMPLIFIED_SOLUTION_PROMPT)\n        \n        # Generate multiple solutions using Custom\n        solutions = [\n            refined_solution['response'],\n            detailed_solution['response'],\n            simplified_solution['response']\n        ]\n        for _ in range(2):\n            solution = await self.custom(input=problem, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT)\n            solutions.append(solution['response'])\n        \n        # Use ScEnsemble to select the best solution\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>REFINE_ANSWER_PROMPT = \"\"\"\nGiven the mathematical problem and the output from the code execution, please provide a well-formatted and detailed solution. Follow these guidelines:\n\n1. Begin with a clear statement of the problem.\n2. Explain the approach and any formulas or concepts used.\n3. Show step-by-step calculations, using LaTeX notation for mathematical expressions.\n4. Interpret the code output and incorporate it into your explanation.\n5. Provide a final answer, enclosed in \\boxed{} LaTeX notation.\n6. Ensure all mathematical notation is in LaTeX format.\n\nYour response should be comprehensive, mathematically rigorous, and easy to follow.\n\"\"\"\n\nGENERATE_SOLUTION_PROMPT = \"\"\"\nPlease solve the given mathematical problem step by step. Follow these guidelines:\n\n1. State the problem clearly.\n2. Outline the approach and any relevant formulas or concepts.\n3. Provide detailed calculations, using LaTeX notation for mathematical expressions.\n4. Explain each step of your reasoning.\n5. Present the final answer enclosed in \\boxed{} LaTeX notation.\n6. Ensure all mathematical notation is in LaTeX format.\n\nYour solution should be thorough, mathematically sound, and easy to understand.\n\"\"\"\n\nDETAILED_SOLUTION_PROMPT = \"\"\"\nProvide a comprehensive, step-by-step solution to the given mathematical problem. Your response should include:\n\n1. A clear restatement of the problem.\n2. An explanation of the mathematical concepts and theorems involved.\n3. A detailed, logical progression of steps leading to the solution.\n4. Clear explanations for each step, including the reasoning behind it.\n5. All mathematical expressions and equations in LaTeX format.\n6. Visual aids or diagrams if applicable (described in text).\n7. A final answer clearly marked and enclosed in \\boxed{} LaTeX notation.\n8. A brief explanation of the significance of the result, if relevant.\n\nEnsure your solution is rigorous, easy to follow, and educational for someone learning the concept.\n\"\"\"\n\nSIMPLIFIED_SOLUTION_PROMPT = \"\"\"\nProvide a concise and simplified solution to the given mathematical problem. Your response should include:\n\n1. A brief restatement of the problem.\n2. The main approach or key concept used to solve the problem.\n3. Essential steps in the solution process, without extensive details.\n4. The final answer enclosed in \\boxed{} LaTeX notation.\n5. Use LaTeX notation for all mathematical expressions.\n\nKeep the solution clear and straightforward, focusing on the core ideas and steps needed to arrive at the answer.\n\"\"\"</prompt>", "tag": "MATH", "domain": "llm_judge", "parent_round": 18, "child_round": 19, "parent_score": 0.5378151260504201, "child_score": 0.5546218487394958, "performance_gain": 0.01680672268907568}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve QA problems.\\nReferring to the given graph and prompt, which forms a basic example of a QA solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.7034571723426213</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_5.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.answer_generate = operator.AnswerGenerate(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):  # Generate 3 solutions\\n            step_by_step = await self.answer_generate(input=problem)\\n            solutions.append(step_by_step['answer'])\\n        \\n        ensemble_solution = await self.sc_ensemble(solutions=solutions)\\n        \\n        refined_solution = await self.custom(input=f\\\"Question: {problem}\\\\nBest solution: {ensemble_solution['response']}\\\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\\n        \\n        final_solution = await self.custom(input=f\\\"Question: {problem}\\\\nRefined answer: {refined_solution['response']}\\\", instruction=prompt_custom.REVIEW_ANSWER_PROMPT)\\n\\n        return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\\n\\n1. Ensure the answer is concise and directly addresses the question.\\n2. If the answer is a number, provide only the number without additional text.\\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\\n4. Remove any explanations or reasoning from the final answer.\\n\\nYour task is to extract or refine the most accurate answer based on the provided information.\\n\\\"\\\"\\\"\\n\\nREVIEW_ANSWER_PROMPT = \\\"\\\"\\\"\\nReview the refined answer for the given question. Ensure it meets the following criteria:\\n\\n1. The answer is directly related to the question asked.\\n2. If the answer is a number, it should be provided without any additional text or symbols (e.g., no %, $, etc.).\\n3. The answer is in its simplest form (e.g., fractions are reduced, unnecessary decimal places are removed).\\n4. If multiple answers are possible, they are separated by a vertical bar (|) without spaces.\\n\\nIf the answer meets all criteria, return it as is. If not, modify the answer to meet these criteria and return the corrected version.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 6</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_6.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.answer_generate = operator.AnswerGenerate(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        step_by_step = await self.answer_generate(input=problem)\n        solution = await self.custom(input=f\"Problem: {problem}\\nStep-by-step solution: {step_by_step['thought']}\\nInitial answer: {step_by_step['answer']}\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n        return solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>REFINE_ANSWER_PROMPT = \"\"\"\nGiven the problem, step-by-step solution, and initial answer, please refine and format the answer to ensure it is concise, accurate, and directly addresses the question. Follow these guidelines:\n\n1. Review the step-by-step solution for accuracy and completeness.\n2. Ensure the final answer is clearly stated and matches the question asked.\n3. If the answer is a numerical value, include only the number without additional explanation.\n4. If the answer requires a brief explanation, keep it concise and to the point.\n5. Remove any unnecessary information or verbosity.\n\nProvide the refined answer in a clear and concise format.\n\"\"\"</prompt>", "tag": "DROP", "domain": "llm_judge", "parent_round": 5, "child_round": 6, "parent_score": 0.7034571723426213, "child_score": 0.524159663865546, "performance_gain": -0.17929750847707526}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.9333333333333333</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_20.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        # Generate multiple solutions\\n        solutions = []\\n        for _ in range(3):\\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT)\\n            solutions.append(solution['response'])\\n\\n        # Use ScEnsemble to select the best solution\\n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        # Review and improve the selected solution\\n        reviewed_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nGenerated solution: {best_solution['response']}\\\", instruction=prompt_custom.REVIEW_SOLUTION_PROMPT)\\n        \\n        # Test the reviewed solution\\n        test_result = await self.test(problem=problem, solution=reviewed_solution['response'], entry_point=entry_point)\\n        \\n        if test_result['result']:\\n            return test_result['solution'], self.llm.cost_manager.total_cost\\n        else:\\n            # If the test fails, try to improve the solution\\n            improved_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nFailed solution: {reviewed_solution['response']}\\\\nError: {test_result['solution']}\\\", instruction=prompt_custom.IMPROVE_SOLUTION_PROMPT)\\n            return improved_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>GENERATE_SOLUTION_PROMPT = \\\"\\\"\\\"\\nGenerate a Python function to solve the given problem. Ensure the solution is complete, correct, and efficient.\\n\\nYour task:\\n1. Understand the problem statement.\\n2. Implement a Python function that solves the problem.\\n3. Consider edge cases and potential optimizations.\\n4. Provide only the Python function as your response, without any additional explanations or comments.\\n\\\"\\\"\\\"\\n\\nREVIEW_SOLUTION_PROMPT = \\\"\\\"\\\"\\nReview the given problem and the generated solution. Analyze the code for correctness, efficiency, and adherence to best practices. Improve the solution if necessary.\\n\\nYour task:\\n1. Understand the problem statement.\\n2. Review the generated solution.\\n3. Check for logical errors, edge cases, and potential improvements.\\n4. Rewrite the solution if improvements are needed, or keep it as is if it's optimal.\\n5. Ensure the final solution is complete, correct, and efficient.\\n\\nProvide only the reviewed and potentially improved Python function as your response, without any additional explanations or comments.\\n\\\"\\\"\\\"\\n\\nIMPROVE_SOLUTION_PROMPT = \\\"\\\"\\\"\\nAnalyze the given problem and the failed solution. Identify the errors and improve the code to solve the problem correctly. Make sure to handle edge cases and follow best practices in Python programming.\\n\\nYour task:\\n1. Understand the problem statement.\\n2. Review the failed solution and the error message.\\n3. Identify the cause of the failure.\\n4. Rewrite the solution, addressing the identified issues.\\n5. Ensure the new solution is complete, correct, and efficient.\\n\\nProvide only the improved Python function as your response, without any additional explanations or comments.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 21</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_21.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        \"\"\"\n        Implementation of the graph\n        Custom operator to generate anything you want.\n        But when you want to get standard code, you should use custom_code_generate operator.\n        \"\"\"\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=\"\")\n        test_result = await self.test(problem=problem, solution=solution['response'], entry_point=entry_point)\n        \n        if test_result['result']:\n            return test_result['solution'], self.llm.cost_manager.total_cost\n        else:\n            # If the test fails, try to improve the solution\n            improved_solution = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {solution['response']}\\nError: {test_result['solution']}\", instruction=prompt_custom.IMPROVE_SOLUTION_PROMPT)\n            return improved_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>IMPROVE_SOLUTION_PROMPT = \"\"\"\nYou are an expert programmer. The given solution failed to pass the test cases. Your task is to analyze the problem, the failed solution, and the error message, then provide an improved solution that should pass all test cases. Focus on fixing the logical errors and edge cases.\n\nPlease provide only the improved code solution without any additional explanations or comments.\n\"\"\"</prompt>", "tag": "HumanEval", "domain": "llm_judge", "parent_round": 20, "child_round": 21, "parent_score": 0.9333333333333333, "child_score": 0.9666666666666667, "performance_gain": 0.033333333333333326}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve QA problems.\\nReferring to the given graph and prompt, which forms a basic example of a QA solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.7200980392156862</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_4.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.answer_generate = operator.AnswerGenerate(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):  # Generate 3 solutions\\n            step_by_step = await self.answer_generate(input=problem)\\n            solution = await self.custom(input=f\\\"Question: {problem}\\\\nStep-by-step solution: {step_by_step['thought']}\\\\nInitial answer: {step_by_step['answer']}\\\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions)\\n        return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\\n\\n1. Ensure the answer is concise and directly addresses the question.\\n2. If the answer is a number, provide only the number without additional text.\\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\\n4. Remove any explanations or reasoning from the final answer.\\n5. Double-check the calculations and logic in the step-by-step solution to ensure accuracy.\\n6. If the answer involves counting or summing items, verify that all relevant items are included.\\n\\nYour task is to extract or refine the most accurate answer based on the provided information. Pay special attention to numerical answers and ensure they are correctly calculated and formatted.\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 5</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_5.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.answer_generate = operator.AnswerGenerate(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):  # Generate 3 solutions\n            step_by_step = await self.answer_generate(input=problem)\n            solutions.append(step_by_step['answer'])\n        \n        ensemble_solution = await self.sc_ensemble(solutions=solutions)\n        \n        refined_solution = await self.custom(input=f\"Question: {problem}\\nBest solution: {ensemble_solution['response']}\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n        \n        final_solution = await self.custom(input=f\"Question: {problem}\\nRefined answer: {refined_solution['response']}\", instruction=prompt_custom.REVIEW_ANSWER_PROMPT)\n\n        return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>REFINE_ANSWER_PROMPT = \"\"\"\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\n\n1. Ensure the answer is concise and directly addresses the question.\n2. If the answer is a number, provide only the number without additional text.\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\n4. Remove any explanations or reasoning from the final answer.\n\nYour task is to extract or refine the most accurate answer based on the provided information.\n\"\"\"\n\nREVIEW_ANSWER_PROMPT = \"\"\"\nReview the refined answer for the given question. Ensure it meets the following criteria:\n\n1. The answer is directly related to the question asked.\n2. If the answer is a number, it should be provided without any additional text or symbols (e.g., no %, $, etc.).\n3. The answer is in its simplest form (e.g., fractions are reduced, unnecessary decimal places are removed).\n4. If multiple answers are possible, they are separated by a vertical bar (|) without spaces.\n\nIf the answer meets all criteria, return it as is. If not, modify the answer to meet these criteria and return the corrected version.\n\"\"\"</prompt>", "tag": "DROP", "domain": "llm_judge", "parent_round": 4, "child_round": 5, "parent_score": 0.7200980392156862, "child_score": 0.725515995872033, "performance_gain": 0.005417956656346812}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve QA problems.\\nReferring to the given graph and prompt, which forms a basic example of a QA solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.671078431372549</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_15.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.answer_generate = operator.AnswerGenerate(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):  # Generate 3 solutions\\n            step_by_step = await self.answer_generate(input=problem)\\n            solution = await self.custom(input=f\\\"Question: {problem}\\\\nStep-by-step solution: {step_by_step['thought']}\\\\nInitial answer: {step_by_step['answer']}\\\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions)\\n        \\n        # Add a final verification step\\n        verified_solution = await self.custom(input=f\\\"Question: {problem}\\\\nProposed answer: {final_solution['response']}\\\", instruction=prompt_custom.VERIFY_ANSWER_PROMPT)\\n        \\n        return verified_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\\n\\n1. Ensure the answer is concise and directly addresses the question.\\n2. If the answer is a number, provide only the number without additional text.\\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\\n4. Remove any explanations or reasoning from the final answer.\\n5. Double-check that the refined answer is consistent with the step-by-step solution and initial answer.\\n6. If the answer involves selecting between options, clearly state the chosen option.\\n\\nYour task is to extract or refine the most accurate answer based on the provided information.\\n\\\"\\\"\\\"\\n\\nVERIFY_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the original question and the proposed answer, please verify and, if necessary, correct the answer. Follow these guidelines:\\n\\n1. Ensure the answer directly addresses the question asked.\\n2. If the answer should be a number, make sure it's provided as a number without additional text.\\n3. If multiple correct answers are possible, they should be separated by a vertical bar (|).\\n4. The answer should not include any explanations or reasoning.\\n5. If the question asks for a percentage, ensure the answer is in the correct percentage format (e.g., 74.60 instead of 0.746).\\n6. If the answer involves selecting between options, make sure the chosen option is clearly stated.\\n7. If the answer is correct and properly formatted, return it as is. If not, provide the corrected version.\\n\\nYour task is to ensure the final answer is accurate, properly formatted, and consistent with the question requirements.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 16</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_16.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.answer_generate = operator.AnswerGenerate(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):  # Generate 3 solutions\n            step_by_step = await self.answer_generate(input=problem)\n            solutions.append(step_by_step['answer'])\n        \n        ensemble_solution = await self.sc_ensemble(solutions=solutions)\n        \n        refined_solution = await self.custom(input=f\"Question: {problem}\\nBest solution: {ensemble_solution['response']}\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n        \n        final_solution = await self.custom(input=f\"Question: {problem}\\nRefined answer: {refined_solution['response']}\", instruction=prompt_custom.EXTRACT_VALIDATE_PROMPT)\n\n        return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>REFINE_ANSWER_PROMPT = \"\"\"\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\n\n1. Ensure the answer is concise and directly addresses the question.\n2. If the answer is a number, provide only the number without additional text.\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\n4. Remove any explanations or reasoning from the final answer.\n\nYour task is to extract or refine the most accurate answer based on the provided information.\n\"\"\"\n\nEXTRACT_VALIDATE_PROMPT = \"\"\"\nGiven the question and the refined answer, please extract and validate the numerical answer. Follow these guidelines:\n\n1. Extract only the numerical value from the refined answer.\n2. Ensure the extracted number is relevant to the question asked.\n3. If the answer is a decimal, maintain the original decimal places.\n4. If the answer is a whole number, do not add decimal places.\n5. If no valid numerical answer can be extracted, respond with \"Unable to extract a valid numerical answer.\"\n\nProvide only the extracted and validated numerical answer without any additional text or explanations.\n\"\"\"</prompt>", "tag": "DROP", "domain": "llm_judge", "parent_round": 15, "child_round": 16, "parent_score": 0.671078431372549, "child_score": 0.6405228758169935, "performance_gain": -0.030555555555555447}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve QA problems.\\nReferring to the given graph and prompt, which forms a basic example of a QA solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.7348039215686274</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_4.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.answer_generate = operator.AnswerGenerate(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):  # Generate 3 solutions\\n            step_by_step = await self.answer_generate(input=problem)\\n            solution = await self.custom(input=f\\\"Question: {problem}\\\\nStep-by-step solution: {step_by_step['thought']}\\\\nInitial answer: {step_by_step['answer']}\\\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions)\\n        return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\\n\\n1. Ensure the answer is concise and directly addresses the question.\\n2. If the answer is a number, provide only the number without additional text.\\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\\n4. Remove any explanations or reasoning from the final answer.\\n5. Double-check the calculations and logic in the step-by-step solution to ensure accuracy.\\n6. If the answer involves counting or summing items, verify that all relevant items are included.\\n\\nYour task is to extract or refine the most accurate answer based on the provided information. Pay special attention to numerical answers and ensure they are correctly calculated and formatted.\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 5</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_5.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.answer_generate = operator.AnswerGenerate(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):  # Generate 3 solutions\n            step_by_step = await self.answer_generate(input=problem)\n            solutions.append(step_by_step['answer'])\n        \n        ensemble_solution = await self.sc_ensemble(solutions=solutions)\n        \n        refined_solution = await self.custom(input=f\"Question: {problem}\\nBest solution: {ensemble_solution['response']}\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n        \n        final_solution = await self.custom(input=f\"Question: {problem}\\nRefined answer: {refined_solution['response']}\", instruction=prompt_custom.REVIEW_ANSWER_PROMPT)\n\n        return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>REFINE_ANSWER_PROMPT = \"\"\"\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\n\n1. Ensure the answer is concise and directly addresses the question.\n2. If the answer is a number, provide only the number without additional text.\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\n4. Remove any explanations or reasoning from the final answer.\n\nYour task is to extract or refine the most accurate answer based on the provided information.\n\"\"\"\n\nREVIEW_ANSWER_PROMPT = \"\"\"\nReview the refined answer for the given question. Ensure it meets the following criteria:\n\n1. The answer is directly related to the question asked.\n2. If the answer is a number, it should be provided without any additional text or symbols (e.g., no %, $, etc.).\n3. The answer is in its simplest form (e.g., fractions are reduced, unnecessary decimal places are removed).\n4. If multiple answers are possible, they are separated by a vertical bar (|) without spaces.\n\nIf the answer meets all criteria, return it as is. If not, modify the answer to meet these criteria and return the corrected version.\n\"\"\"</prompt>", "tag": "DROP", "domain": "llm_judge", "parent_round": 4, "child_round": 5, "parent_score": 0.7348039215686274, "child_score": 0.725515995872033, "performance_gain": -0.009287925696594423}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve QA problems.\\nReferring to the given graph and prompt, which forms a basic example of a QA solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>\\nPrevious failed modifications:\\n  - Modify the graph to include a verification step using the Custom operator. This step will check if the answer meets the specific formatting requirements mentioned in the logs, such as removing percentage signs and ensuring numerical answers are provided when appropriate. (Score: 0.6897058823529412)\\n  - Add a verification step using the Custom operator to check and refine numerical answers, ensuring they are consistent with the question and step-by-step solution. (Score: 0.5920092057481131)\\n  - Add a verification step using the Custom operator to check and refine the final answer, ensuring it meets specific formatting requirements such as removing percentage signs and providing numerical answers when appropriate. (Score: 0.7230392156862744)\\n  - Add a final verification step using the Custom operator to ensure the answer is correct and properly formatted according to the question requirements. (Score: 0.6607843137254901)</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.755392156862745</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_10.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.answer_generate = operator.AnswerGenerate(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):  # Generate 3 solutions\\n            step_by_step = await self.answer_generate(input=problem)\\n            solution = await self.custom(input=f\\\"Question: {problem}\\\\nStep-by-step solution: {step_by_step['thought']}\\\\nInitial answer: {step_by_step['answer']}\\\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions)\\n        return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\\n\\n1. Ensure the answer is concise and directly addresses the question.\\n2. If the answer is a number, provide only the number without additional text.\\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\\n4. Remove any explanations or reasoning from the final answer.\\n5. Double-check that the refined answer is consistent with the step-by-step solution and initial answer.\\n6. If the answer involves selecting between options, clearly state the chosen option.\\n\\nYour task is to extract or refine the most accurate answer based on the provided information.\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 11</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_11.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.answer_generate = operator.AnswerGenerate(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):  # Generate 3 solutions\n            step_by_step = await self.answer_generate(input=problem)\n            solutions.append(step_by_step['answer'])\n        \n        ensemble_solution = await self.sc_ensemble(solutions=solutions)\n        \n        refined_solution = await self.custom(input=f\"Question: {problem}\\nBest solution: {ensemble_solution['response']}\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n        \n        final_solution = await self.custom(input=f\"Question: {problem}\\nRefined answer: {refined_solution['response']}\", instruction=prompt_custom.CHECK_NUMERICAL_ANSWER_PROMPT)\n\n        return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>REFINE_ANSWER_PROMPT = \"\"\"\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\n\n1. Ensure the answer is concise and directly addresses the question.\n2. If the answer is a number, provide only the number without additional text.\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\n4. Remove any explanations or reasoning from the final answer.\n\nYour task is to extract or refine the most accurate answer based on the provided information.\n\"\"\"\n\nCHECK_NUMERICAL_ANSWER_PROMPT = \"\"\"\nGiven the question and the refined answer, please perform a numerical check and correction if necessary. Follow these steps:\n\n1. Identify if the answer is numerical.\n2. If it is numerical, carefully review the question and the given answer to ensure its accuracy.\n3. If you find any discrepancies or errors in the numerical answer, provide the correct numerical answer.\n4. If the answer is correct or not numerical, return the original answer without changes.\n5. Ensure the final answer follows the format guidelines: numbers only, no additional text, and use vertical bars (|) for multiple possible answers.\n\nYour task is to verify and correct numerical answers while maintaining the correct answer format.\n\"\"\"</prompt>", "tag": "DROP", "domain": "llm_judge", "parent_round": 10, "child_round": 11, "parent_score": 0.755392156862745, "child_score": 0.2688218042446621, "performance_gain": -0.48657035261808285}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.7209302325581395</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_3.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        Custom operator to generate anything you want.\\n        But when you want to get standard code, you should use custom_code_generate operator.\\n        \\\"\\\"\\\"\\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\\n        test_result = await self.test(problem=problem, solution=solution['response'], entry_point=entry_point)\\n        \\n        if not test_result['result']:\\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.IMPROVED_CODE_GENERATE_PROMPT)\\n        \\n        return solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>CODE_GENERATE_PROMPT = \\\"\\\"\\\"\\nGenerate a Python function that solves the given problem. Make sure to handle edge cases and use efficient algorithms where possible.\\n\\nProblem:\\n{problem}\\n\\nEntry point:\\n{entry_point}\\n\\nGenerate the solution:\\n\\\"\\\"\\\"\\n\\nIMPROVED_CODE_GENERATE_PROMPT = \\\"\\\"\\\"\\nThe previous solution failed some test cases. Please generate an improved Python function that solves the given problem. Pay extra attention to edge cases and efficiency.\\n\\nProblem:\\n{problem}\\n\\nEntry point:\\n{entry_point}\\n\\nPrevious solution:\\n{previous_solution}\\n\\nGenerate an improved solution:\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 4</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_4.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\n        \n        # New step: Analyze and improve the solution before testing\n        improved_solution = await self.custom(input=f\"Problem: {problem}\\nGenerated solution: {solution['response']}\", instruction=prompt_custom.ANALYZE_IMPROVE_PROMPT)\n        \n        test_result = await self.test(problem=problem, solution=improved_solution['response'], entry_point=entry_point)\n        \n        if test_result['result']:\n            return test_result['solution'], self.llm.cost_manager.total_cost\n        else:\n            # If the test fails, try to fix the solution\n            fixed_solution = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {improved_solution['response']}\\nError: {test_result['solution']}\", instruction=prompt_custom.FIX_CODE_PROMPT)\n            return fixed_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>CODE_GENERATE_PROMPT = \"\"\"\nGenerate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity.\n\nProblem:\n{problem}\n\nFunction signature:\n{entry_point}\n\nGenerate the complete function below:\n\"\"\"\n\nANALYZE_IMPROVE_PROMPT = \"\"\"\nAnalyze the following Python function and suggest improvements for better performance, readability, and correctness. Consider edge cases, potential errors, and optimization opportunities. Provide an improved version of the function.\n\nProblem:\n{input}\n\nProvide the improved function below:\n\"\"\"\n\nFIX_CODE_PROMPT = \"\"\"\nThe provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation.\n\nProblem:\n{input}\n\nProvide the corrected function below:\n\"\"\"</prompt>", "tag": "MBPP", "domain": "llm_judge", "parent_round": 3, "child_round": 4, "parent_score": 0.7209302325581395, "child_score": 0.6162790697674418, "performance_gain": -0.10465116279069764}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.88</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_16.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(5):  # Generate 5 solutions\\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        # Add a verification step using the Programmer operator\\n        verification = await self.programmer(problem=problem, analysis=final_solution['response'])\\n        \\n        # Double-check the final answer with a focus on total cost calculation\\n        double_check = await self.custom(input=problem + f\\\"\\\\nPrevious solution: {verification['output']}\\\", instruction=prompt_custom.DOUBLE_CHECK_PROMPT)\\n        \\n        if double_check['response'] != verification['output']:\\n            return double_check['response'], self.llm.cost_manager.total_cost\\n        else:\\n            return verification['output'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>MATH_SOLVE_PROMPT = \\\"\\\"\\\"\\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps carefully:\\n\\n1. Read and understand the problem thoroughly.\\n2. Identify all key information, variables, and relationships.\\n3. Determine the appropriate mathematical concepts, formulas, or equations to use.\\n4. Solve the problem step-by-step, showing all your work clearly.\\n5. Double-check your calculations and reasoning at each step.\\n6. Provide a clear and concise final answer.\\n7. Verify your solution by plugging it back into the original problem or using an alternative method if possible.\\n\\nFormat your answer as follows:\\n- Use LaTeX notation for mathematical expressions where appropriate.\\n- Show each step of your solution process clearly.\\n- Clearly state your final answer at the end of your solution.\\n- Express numerical answers as precise values (avoid rounding unless specified).\\n- Ensure that your final answer is a single numerical value without any units or additional text.\\n- Do not include any explanatory text with your final answer, just the number itself.\\n\\nFor example, if the final answer is 42.5, your response should end with just:\\n42.5\\n\\nHere's the problem to solve:\\n\\n\\\"\\\"\\\"\\n\\nDOUBLE_CHECK_PROMPT = \\\"\\\"\\\"\\nYou are a meticulous math problem solver. Your task is to double-check the solution to a given problem, focusing on total cost calculation and considering all given information, including discounts and multiple time periods if applicable.\\n\\n1. Carefully read the original problem.\\n2. Review the previous solution provided.\\n3. Pay special attention to:\\n   - Total cost calculations\\n   - Discounts or percentage-based calculations\\n   - Multiple time periods or quantities\\n   - Any information that might have been overlooked\\n\\n4. If you find any errors or discrepancies, recalculate the solution step-by-step.\\n5. If the previous solution is correct, confirm it.\\n\\nProvide your final answer as a single numerical value without any units or additional text. For example:\\n\\n342.0\\n\\nHere's the original problem and the previous solution:\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 17</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_17.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(5):  # Generate 5 solutions\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\n            solutions.append(solution['response'])\n        \n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Add a verification step using the Programmer operator\n        verification = await self.programmer(problem=problem, analysis=final_solution['response'])\n        \n        if verification['output']:\n            final_answer = verification['output']\n        else:\n            final_answer = final_solution['response']\n        \n        # Final check to ensure the answer is a single numerical value\n        try:\n            final_answer = float(final_answer)\n        except ValueError:\n            final_answer = float(final_solution['response'])\n        \n        return str(final_answer), self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>MATH_SOLVE_PROMPT = \"\"\"\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps carefully:\n\n1. Read and understand the problem thoroughly, paying close attention to ALL given information.\n2. Identify all key information, variables, and relationships, including any discounts or time-related factors.\n3. Determine the appropriate mathematical concepts, formulas, or equations to use.\n4. Solve the problem step-by-step, showing all your work clearly.\n5. Double-check your calculations and reasoning at each step.\n6. If the problem involves multiple time periods or discounts, ensure these are correctly applied in your calculations.\n7. Calculate the total cost or final answer, considering ALL factors mentioned in the problem.\n8. Provide a clear and concise final answer.\n9. Verify your solution by plugging it back into the original problem or using an alternative method if possible.\n\nFormat your answer as follows:\n- Use LaTeX notation for mathematical expressions where appropriate.\n- Show each step of your solution process clearly.\n- Clearly state your final answer at the end of your solution.\n- Express numerical answers as precise values (avoid rounding unless specified).\n- Ensure that your final answer is a single numerical value without any units or additional text.\n- Do not include any explanatory text with your final answer, just the number itself.\n\nFor example, if the final answer is 42.5, your response should end with just:\n42.5\n\nHere's the problem to solve:\n\n\"\"\"</prompt>", "tag": "GSM8K", "domain": "llm_judge", "parent_round": 16, "child_round": 17, "parent_score": 0.88, "child_score": 0.89, "performance_gain": 0.010000000000000009}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.87</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_12.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):\\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        ensemble_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        # Add a review step using the Programmer operator\\n        review_result = await self.programmer(problem=problem, analysis=ensemble_solution['response'])\\n        \\n        if review_result['output']:\\n            final_answer = review_result['output']\\n        else:\\n            final_answer = ensemble_solution['response']\\n        \\n        # Final verification step\\n        verification = await self.custom(input=f\\\"{problem}\\\\nProposed answer: {final_answer}\\\", instruction=prompt_custom.VERIFY_PROMPT)\\n        \\n        return verification['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>MATH_SOLVE_PROMPT = \\\"\\\"\\\"\\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps:\\n\\n1. Carefully read and understand the problem.\\n2. Identify the key information and variables.\\n3. Determine the appropriate mathematical concepts or formulas to use.\\n4. Solve the problem step by step, showing all your work.\\n5. Double-check your calculations and reasoning.\\n6. Provide a clear and concise final answer.\\n\\nRemember to format your answer as follows:\\n- Use LaTeX notation for mathematical expressions where appropriate.\\n- Clearly state your final answer at the end of your solution.\\n- Express numerical answers as precise values (avoid rounding unless specified).\\n- Ensure that your final answer is a single numerical value without any units or additional text.\\n- Do not include any explanatory text with your final answer, just the number itself.\\n\\nFor example, if the final answer is 42.5, your response should end with just:\\n42.5\\n\\nHere's the problem to solve:\\n\\n\\\"\\\"\\\"\\n\\nVERIFY_PROMPT = \\\"\\\"\\\"\\nYou are a meticulous math verifier. Your task is to verify the proposed answer to a given math problem. Follow these steps:\\n\\n1. Carefully read the original problem.\\n2. Review the proposed answer.\\n3. Independently solve the problem, showing your work step-by-step.\\n4. Compare your solution with the proposed answer.\\n5. If the proposed answer is correct, return it as is.\\n6. If the proposed answer is incorrect, provide the correct answer.\\n\\nRemember:\\n- Ensure your final answer is a single numerical value without units or additional text.\\n- Double-check all calculations for accuracy.\\n- If correcting the answer, use the same format as the original problem (i.e., same level of precision).\\n\\nHere's the problem and proposed answer to verify:\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 13</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_13.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(5):  # Generate 5 solutions\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\n            solutions.append(solution['response'])\n        \n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Add a verification step using the Programmer operator\n        verification = await self.programmer(problem=problem, analysis=final_solution['response'])\n        \n        if verification['output']:\n            return verification['output'], self.llm.cost_manager.total_cost\n        else:\n            return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>MATH_SOLVE_PROMPT = \"\"\"\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps carefully:\n\n1. Read and understand the problem thoroughly.\n2. Identify all key information, variables, and relationships.\n3. Determine the appropriate mathematical concepts, formulas, or equations to use.\n4. Solve the problem step-by-step, showing all your work clearly.\n5. Double-check your calculations and reasoning at each step.\n6. Provide a clear and concise final answer.\n7. Verify your solution by plugging it back into the original problem or using an alternative method if possible.\n\nFormat your answer as follows:\n- Use LaTeX notation for mathematical expressions where appropriate.\n- Show each step of your solution process clearly.\n- Clearly state your final answer at the end of your solution.\n- Express numerical answers as precise values (avoid rounding unless specified).\n- Ensure that your final answer is a single numerical value without any units or additional text.\n- Do not include any explanatory text with your final answer, just the number itself.\n\nFor example, if the final answer is 42.5, your response should end with just:\n42.5\n\nHere's the problem to solve:\n\n\"\"\"</prompt>", "tag": "GSM8K", "domain": "llm_judge", "parent_round": 12, "child_round": 13, "parent_score": 0.87, "child_score": 0.91, "performance_gain": 0.040000000000000036}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve QA problems.\\nReferring to the given graph and prompt, which forms a basic example of a QA solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.5360934240692026</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.round_9.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.answer_generate = operator.AnswerGenerate(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):\\n            initial_response = await self.answer_generate(input=problem)\\n            thought_process = initial_response['thought']\\n            initial_answer = initial_response['answer']\\n            solutions.append(initial_answer)\\n\\n        ensemble_result = await self.sc_ensemble(solutions=solutions)\\n        best_answer = ensemble_result['response']\\n        \\n        fact_checked_answer = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nBest answer: {best_answer}\\\",\\n            instruction=prompt_custom.FACT_CHECK_PROMPT\\n        )\\n        \\n        refined_solution = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nVerified answer: {fact_checked_answer['response']}\\\",\\n            instruction=prompt_custom.FORMAT_ANSWER_PROMPT\\n        )\\n        \\n        return refined_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>FORMAT_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question and the verified answer, format the final answer to be concise, accurate, and directly addressing the question. Ensure the answer is clear and brief, without unnecessary explanation. Follow these guidelines:\\n\\n1. For questions about people, provide only the name or profession.\\n2. For questions about dates or numbers, provide only the specific date or number.\\n3. For questions asking about differences or comparisons, provide a brief, one-sentence explanation highlighting the key difference.\\n4. For questions about facts or events, provide a concise statement of the fact or event.\\n\\nDo not include any prefixes like \\\"The answer is\\\" or \\\"The difference is\\\". Provide only the essential information to answer the question.\\n\\nQuestion: {question}\\nVerified answer: {verified_answer}\\n\\nFormat your response accordingly:\\n\\\"\\\"\\\"\\n\\nFACT_CHECK_PROMPT = \\\"\\\"\\\"\\nGiven the question and the best answer, carefully analyze the information provided and perform a fact-check. If you find any inconsistencies or errors in the best answer, provide a corrected version. If the best answer appears accurate, simply restate it. Focus on verifying key facts, names, dates, and other critical information related to the question.\\n\\nQuestion: {question}\\nBest answer: {best_answer}\\n\\nYour task:\\n1. Analyze the question and the best answer.\\n2. Identify any potential errors or inconsistencies.\\n3. If errors are found, provide a corrected answer.\\n4. If no errors are found, restate the best answer.\\n\\nProvide your response in a concise manner, focusing solely on the corrected or verified answer without additional explanations.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 10</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.round_10.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.answer_generate = operator.AnswerGenerate(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):\n            initial_response = await self.answer_generate(input=problem)\n            thought_process = initial_response['thought']\n            initial_answer = initial_response['answer']\n            solutions.append(initial_answer)\n\n        ensemble_result = await self.sc_ensemble(solutions=solutions)\n        best_answer = ensemble_result['response']\n        \n        name_extracted_answer = await self.custom(\n            input=f\"Question: {problem}\\nBest answer: {best_answer}\",\n            instruction=prompt_custom.NAME_EXTRACTION_PROMPT\n        )\n        \n        fact_checked_answer = await self.custom(\n            input=f\"Question: {problem}\\nName-extracted answer: {name_extracted_answer['response']}\",\n            instruction=prompt_custom.FACT_CHECK_PROMPT\n        )\n        \n        style_check_answer = await self.custom(\n            input=f\"Question: {problem}\\nFact-checked answer: {fact_checked_answer['response']}\",\n            instruction=prompt_custom.STYLE_CHECK_PROMPT\n        )\n        \n        additional_verification = await self.custom(\n            input=f\"Question: {problem}\\nStyle-checked answer: {style_check_answer['response']}\",\n            instruction=prompt_custom.ADDITIONAL_VERIFICATION_PROMPT\n        )\n        \n        refined_solution = await self.custom(\n            input=f\"Question: {problem}\\nDouble-verified answer: {additional_verification['response']}\",\n            instruction=prompt_custom.FORMAT_ANSWER_PROMPT\n        )\n        \n        return refined_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>FORMAT_ANSWER_PROMPT = \"\"\"\nGiven the question and the double-verified answer, format the final answer to be extremely concise and directly addressing the question. Provide only the essential information without any explanation or additional context. For names, professions, or short phrases, give only that specific information.\n\nExamples:\n- For a person's name: \"John Doe\"\n- For a profession: \"Doctor\"\n- For a short phrase: \"Once in a blue moon\"\n\nDo not include any prefixes or explanatory text. Provide only the answer itself.\n\"\"\"\n\nNAME_EXTRACTION_PROMPT = \"\"\"\nGiven the question and the best answer, focus on extracting and verifying any names mentioned. Pay special attention to:\n\n1. Full names (first name, middle name, last name)\n2. Nicknames or aliases\n3. Correct spelling of names\n\nIf the answer contains a name, ensure it is accurate and complete. If a name is incorrect or incomplete, provide the correct full name. If no name is present or needed, simply restate the answer.\n\nProvide your response in a concise manner, focusing solely on the corrected or verified answer without additional explanations.\n\"\"\"\n\nFACT_CHECK_PROMPT = \"\"\"\nGiven the question and the name-extracted answer, carefully analyze the information provided and perform a fact-check. If you find any inconsistencies or errors in the answer, provide a corrected version. If the answer appears accurate, simply restate it. Focus on verifying key facts, names, dates, and other critical information related to the question.\n\nYour task:\n1. Analyze the question and the answer.\n2. Identify any potential errors or inconsistencies.\n3. If errors are found, provide a corrected answer.\n4. If no errors are found, restate the answer.\n\nProvide your response in a concise manner, focusing solely on the corrected or verified answer without additional explanations.\n\"\"\"\n\nSTYLE_CHECK_PROMPT = \"\"\"\nReview the fact-checked answer, focusing specifically on architectural and historical style terms. Verify the accuracy of any mentioned styles, ensuring they are correctly identified and placed in the proper historical context. Pay special attention to:\n\n1. Architectural styles (e.g., Gothic, Baroque, Neoclassical)\n2. Historical periods and their associated styles\n3. Relationships between different styles (e.g., which style influenced or preceded another)\n\nIf you find any errors or misidentifications in the architectural or historical style terms, provide a corrected version. If the answer is accurate, simply restate it. Be concise and direct in your response, providing only the verified or corrected answer without explanations.\n\"\"\"\n\nADDITIONAL_VERIFICATION_PROMPT = \"\"\"\nPerform an additional verification on the previously style-checked answer. Focus on:\n\n1. Consistency with the question\n2. Accuracy of specific details (names, dates, places, styles)\n3. Completeness of the answer\n4. Ensure the answer is a single word, number, or short phrase when appropriate\n\nIf any issues are found, provide a corrected version. If the answer is accurate and complete, restate it. Be concise and direct in your response, providing only the verified or corrected answer without explanations.\n\"\"\"</prompt>", "tag": "HotpotQA", "domain": "llm_judge", "parent_round": 9, "child_round": 10, "parent_score": 0.5360934240692026, "child_score": 0.6437567334626157, "performance_gain": 0.10766330939341318}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.76</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_5.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):\\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        review_result = await self.programmer(problem=problem, analysis=final_solution['response'])\\n        \\n        if review_result['output']:\\n            initial_answer = review_result['output']\\n        else:\\n            initial_answer = final_solution['response']\\n        \\n        # Add a final check and correction step\\n        final_check = await self.custom(input=f\\\"Problem: {problem}\\\\nInitial Answer: {initial_answer}\\\", instruction=prompt_custom.FINAL_CHECK_PROMPT)\\n        \\n        return final_check['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>MATH_SOLVE_PROMPT = \\\"\\\"\\\"\\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps:\\n\\n1. Carefully read and understand the problem.\\n2. Identify the key information and variables.\\n3. Determine the appropriate mathematical concepts or formulas to use.\\n4. Solve the problem step by step, showing all your work.\\n5. Double-check your calculations and reasoning.\\n6. Provide a clear and concise final answer.\\n\\nRemember to format your answer as follows:\\n- Use LaTeX notation for mathematical expressions where appropriate.\\n- Clearly state your final answer at the end of your solution.\\n- Express numerical answers as precise values (avoid rounding unless specified).\\n- Ensure that your final answer is a single numerical value without any units or additional text.\\n\\nHere's the problem to solve:\\n\\n\\\"\\\"\\\"\\n\\nFINAL_CHECK_PROMPT = \\\"\\\"\\\"\\nYou are a meticulous math problem checker. Your task is to review the given problem and the initial answer, then perform a final check and correction if necessary. Pay special attention to:\\n\\n1. Discount calculations: Ensure discounts are applied correctly and to the right items.\\n2. Multiple item purchases: Verify that quantities are accounted for accurately.\\n3. Addition and multiplication: Double-check all arithmetic operations.\\n4. Problem constraints: Make sure all conditions in the problem are satisfied.\\n\\nIf you find any errors, provide the correct solution with a brief explanation. If the initial answer is correct, simply confirm it.\\n\\nYour response should be a single numerical value representing the final, correct answer. Do not include any units or additional text.\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 6</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_6.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\n            solutions.append(solution['response'])\n        \n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Add a review step using the Programmer operator\n        review_result = await self.programmer(problem=problem, analysis=final_solution['response'])\n        \n        if review_result['output']:\n            return review_result['output'], self.llm.cost_manager.total_cost\n        else:\n            return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>MATH_SOLVE_PROMPT = \"\"\"\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps:\n\n1. Carefully read and understand the problem.\n2. Identify the key information and variables.\n3. Determine the appropriate mathematical concepts or formulas to use.\n4. Solve the problem step by step, showing all your work.\n5. Double-check your calculations and reasoning.\n6. Provide a clear and concise final answer.\n7. Format your final answer as a single numerical value without units or additional text.\n\nRemember to format your answer as follows:\n- Use LaTeX notation for mathematical expressions where appropriate.\n- Clearly state your final answer at the end of your solution.\n- Express numerical answers as precise values (avoid rounding unless specified).\n- Ensure that your final answer is a single numerical value without any units or additional text.\n\nHere's the problem to solve:\n\n\"\"\"</prompt>", "tag": "GSM8K", "domain": "llm_judge", "parent_round": 5, "child_round": 6, "parent_score": 0.76, "child_score": 0.88, "performance_gain": 0.12}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.813953488372093</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_17.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        Custom operator to generate anything you want.\\n        But when you want to get standard code, you should use custom_code_generate operator.\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):  # Generate 3 solutions\\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        test_result = await self.test(problem=problem, solution=best_solution['response'], entry_point=entry_point)\\n        \\n        if test_result['result']:\\n            return test_result['solution'], self.llm.cost_manager.total_cost\\n        else:\\n            # If the test fails, try to fix the solution\\n            fixed_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nFailed solution: {best_solution['response']}\\\\nError: {test_result['solution']}\\\", instruction=prompt_custom.FIX_CODE_PROMPT)\\n            return fixed_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>CODE_GENERATE_PROMPT = \\\"\\\"\\\"\\nGenerate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity.\\n\\nProblem:\\n{problem}\\n\\nFunction signature:\\n{entry_point}\\n\\nGenerate the complete function below:\\n\\\"\\\"\\\"\\n\\nFIX_CODE_PROMPT = \\\"\\\"\\\"\\nThe provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation.\\n\\nProblem:\\n{input}\\n\\nProvide the corrected function below:\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 18</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_18.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        solutions = []\n        for _ in range(3):  # Generate 3 solutions\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\n            solutions.append(solution['response'])\n        \n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Generate additional test cases\n        additional_tests = await self.custom(input=f\"Problem: {problem}\\nSolution: {best_solution['response']}\", instruction=prompt_custom.GENERATE_TESTS_PROMPT)\n        \n        # Combine original problem and additional tests\n        enhanced_problem = f\"{problem}\\n\\nAdditional test cases:\\n{additional_tests['response']}\"\n        \n        test_result = await self.test(problem=enhanced_problem, solution=best_solution['response'], entry_point=entry_point)\n        \n        if test_result['result']:\n            return test_result['solution'], self.llm.cost_manager.total_cost\n        else:\n            # If the test fails, try to fix the solution\n            fixed_solution = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {best_solution['response']}\\nError: {test_result['solution']}\", instruction=prompt_custom.FIX_CODE_PROMPT)\n            return fixed_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>CODE_GENERATE_PROMPT = \"\"\"\nGenerate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity.\n\nProblem:\n{problem}\n\nFunction signature:\n{entry_point}\n\nGenerate the complete function below:\n\"\"\"\n\nFIX_CODE_PROMPT = \"\"\"\nThe provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation.\n\nProblem:\n{input}\n\nProvide the corrected function below:\n\"\"\"\n\nGENERATE_TESTS_PROMPT = \"\"\"\nGiven the problem and a potential solution, generate additional test cases to thoroughly evaluate the function. Include edge cases and typical scenarios. Format the test cases as assert statements that can be directly added to a Python test function.\n\nProblem:\n{input}\n\nGenerate 3-5 additional test cases as assert statements:\n\"\"\"</prompt>", "tag": "MBPP", "domain": "llm_judge", "parent_round": 17, "child_round": 18, "parent_score": 0.813953488372093, "child_score": 0.813953488372093, "performance_gain": 0.0}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve QA problems.\\nReferring to the given graph and prompt, which forms a basic example of a QA solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.25080497986121764</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_11.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.answer_generate = operator.AnswerGenerate(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):  # Generate 3 solutions\\n            step_by_step = await self.answer_generate(input=problem)\\n            solutions.append(step_by_step['answer'])\\n        \\n        ensemble_solution = await self.sc_ensemble(solutions=solutions)\\n        \\n        refined_solution = await self.custom(input=f\\\"Question: {problem}\\\\nBest solution: {ensemble_solution['response']}\\\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\\n        \\n        final_solution = await self.custom(input=f\\\"Question: {problem}\\\\nRefined answer: {refined_solution['response']}\\\", instruction=prompt_custom.CHECK_NUMERICAL_ANSWER_PROMPT)\\n\\n        return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\\n\\n1. Ensure the answer is concise and directly addresses the question.\\n2. If the answer is a number, provide only the number without additional text.\\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\\n4. Remove any explanations or reasoning from the final answer.\\n\\nYour task is to extract or refine the most accurate answer based on the provided information.\\n\\\"\\\"\\\"\\n\\nCHECK_NUMERICAL_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question and the refined answer, please perform a numerical check and correction if necessary. Follow these steps:\\n\\n1. Identify if the answer is numerical.\\n2. If it is numerical, carefully review the question and the given answer to ensure its accuracy.\\n3. If you find any discrepancies or errors in the numerical answer, provide the correct numerical answer.\\n4. If the answer is correct or not numerical, return the original answer without changes.\\n5. Ensure the final answer follows the format guidelines: numbers only, no additional text, and use vertical bars (|) for multiple possible answers.\\n\\nYour task is to verify and correct numerical answers while maintaining the correct answer format.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 12</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_12.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.answer_generate = operator.AnswerGenerate(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):  # Generate 3 solutions\n            step_by_step = await self.answer_generate(input=problem)\n            solutions.append(step_by_step['answer'])\n        \n        ensemble_solution = await self.sc_ensemble(solutions=solutions)\n        \n        refined_solution = await self.custom(input=f\"Question: {problem}\\nBest solution: {ensemble_solution['response']}\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n        \n        final_solution = await self.custom(input=f\"Answer: {refined_solution['response']}\", instruction=prompt_custom.FORMAT_NUMERIC_ANSWER_PROMPT)\n\n        return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>REFINE_ANSWER_PROMPT = \"\"\"\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\n\n1. Ensure the answer is concise and directly addresses the question.\n2. If the answer is a number, provide only the number without additional text.\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\n4. Remove any explanations or reasoning from the final answer.\n\nYour task is to extract or refine the most accurate answer based on the provided information.\n\"\"\"\n\nFORMAT_NUMERIC_ANSWER_PROMPT = \"\"\"\nGiven an answer, please format it according to these rules:\n\n1. If the answer contains a single number:\n   - Remove any additional text or symbols (like %, $, etc.)\n   - Present the number without commas\n   - If it's a whole number, remove any decimal places\n   - If it's a decimal, keep up to two decimal places\n\n2. If the answer contains multiple numbers separated by '|':\n   - Apply the above rules to each number\n   - Keep the '|' separator between numbers\n\n3. If the answer doesn't contain any numbers, return it as is.\n\nExamples:\n\"74.60%\" should become \"74.60\"\n\"3 | 20 | 32\" should remain \"3 | 20 | 32\"\n\"$1,234,567.89\" should become \"1234567.89\"\n\"42 years old\" should become \"42\"\n\nYour task is to format the given answer according to these rules.\n\"\"\"</prompt>", "tag": "DROP", "domain": "llm_judge", "parent_round": 11, "child_round": 12, "parent_score": 0.25080497986121764, "child_score": 0.7544117647058823, "performance_gain": 0.5036067848446647}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.9</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_10.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        Custom operator to generate anything you want.\\n        But when you want to get standard code, you should use custom_code_generate operator.\\n        \\\"\\\"\\\"\\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=\\\"\\\")\\n        \\n        # Add a review step\\n        review_result = await self.custom(input=problem + f\\\"\\\\nGenerated solution:\\\\n{solution['response']}\\\", instruction=prompt_custom.REVIEW_CODE_PROMPT)\\n        \\n        if \\\"improvements needed\\\" in review_result['response'].lower():\\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.IMPROVE_CODE_PROMPT)\\n        \\n        test_result = await self.test(problem=problem, solution=solution['response'], entry_point=entry_point)\\n        \\n        if test_result['result']:\\n            return test_result['solution'], self.llm.cost_manager.total_cost\\n        else:\\n            # If the test fails, try to generate a new solution\\n            new_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.IMPROVE_CODE_PROMPT)\\n            return new_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>IMPROVE_CODE_PROMPT = \\\"\\\"\\\"\\nThe previous solution failed some test cases. Please analyze the problem carefully and provide an improved solution that addresses all edge cases and requirements. Ensure your code is efficient and follows best practices.\\n\\\"\\\"\\\"\\n\\nREVIEW_CODE_PROMPT = \\\"\\\"\\\"\\nPlease review the following code solution and provide feedback. Analyze the code for potential issues, edge cases, and adherence to the problem requirements. If you find any areas for improvement, please respond with \\\"Improvements needed:\\\" followed by a brief explanation. If the code appears to be correct and efficient, respond with \\\"No improvements needed.\\\"\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 11</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_11.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        \"\"\"\n        Implementation of the graph\n        Custom operator to generate anything you want.\n        But when you want to get standard code, you should use custom_code_generate operator.\n        \"\"\"\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=\"Generate a Python function to solve the given problem.\")\n        \n        # Test the generated solution\n        test_result = await self.test(problem=problem, solution=solution['response'], entry_point=entry_point)\n        \n        if test_result['result']:\n            return test_result['solution'], self.llm.cost_manager.total_cost\n        else:\n            # If the test fails, try to improve the solution\n            improved_solution = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {solution['response']}\\nError: {test_result['solution']}\", instruction=prompt_custom.IMPROVE_SOLUTION_PROMPT)\n            return improved_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>IMPROVE_SOLUTION_PROMPT = \"\"\"\nAnalyze the given problem and the failed solution. Identify the errors and improve the code to solve the problem correctly. Make sure to handle edge cases and follow best practices in Python programming.\n\nYour task:\n1. Understand the problem statement.\n2. Review the failed solution and the error message.\n3. Identify the cause of the failure.\n4. Rewrite the solution, addressing the identified issues.\n5. Ensure the new solution is complete, correct, and efficient.\n\nProvide only the improved Python function as your response, without any additional explanations or comments.\n\"\"\"</prompt>", "tag": "HumanEval", "domain": "llm_judge", "parent_round": 10, "child_round": 11, "parent_score": 0.9, "child_score": 0.9333333333333333, "performance_gain": 0.033333333333333326}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>Previous successful modifications:\\n  - Add a review step using the Custom operator to analyze and improve the generated solution before testing it. This can help catch potential issues and enhance the solution quality before running the test cases. (Score: 0.9466666666666667)\\n\\nPrevious failed modifications:\\n  - Add a review step using the Custom operator to analyze and improve the generated solution before testing it. This can help catch potential issues and enhance the solution quality before running the test cases. (Score: 0.8866666666666667)</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.9333333333333333</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_11.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        Custom operator to generate anything you want.\\n        But when you want to get standard code, you should use custom_code_generate operator.\\n        \\\"\\\"\\\"\\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=\\\"Generate a Python function to solve the given problem.\\\")\\n        \\n        # Test the generated solution\\n        test_result = await self.test(problem=problem, solution=solution['response'], entry_point=entry_point)\\n        \\n        if test_result['result']:\\n            return test_result['solution'], self.llm.cost_manager.total_cost\\n        else:\\n            # If the test fails, try to improve the solution\\n            improved_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nFailed solution: {solution['response']}\\\\nError: {test_result['solution']}\\\", instruction=prompt_custom.IMPROVE_SOLUTION_PROMPT)\\n            return improved_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>IMPROVE_SOLUTION_PROMPT = \\\"\\\"\\\"\\nAnalyze the given problem and the failed solution. Identify the errors and improve the code to solve the problem correctly. Make sure to handle edge cases and follow best practices in Python programming.\\n\\nYour task:\\n1. Understand the problem statement.\\n2. Review the failed solution and the error message.\\n3. Identify the cause of the failure.\\n4. Rewrite the solution, addressing the identified issues.\\n5. Ensure the new solution is complete, correct, and efficient.\\n\\nProvide only the improved Python function as your response, without any additional explanations or comments.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 12</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_12.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=\"\")\n        \n        # Add a review step\n        review_result = await self.custom(input=f\"Problem: {problem}\\nSolution: {solution['response']}\", instruction=prompt_custom.REVIEW_CODE_PROMPT)\n        \n        if \"No issues found\" not in review_result['response']:\n            # If issues are found, generate an improved solution\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.IMPROVE_CODE_PROMPT + f\"\\nReview feedback: {review_result['response']}\")\n        \n        test_result = await self.test(problem=problem, solution=solution['response'], entry_point=entry_point)\n        \n        if test_result['result']:\n            return test_result['solution'], self.llm.cost_manager.total_cost\n        else:\n            # If the test fails, try to generate a new solution\n            new_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.IMPROVE_CODE_PROMPT)\n            return new_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>IMPROVE_CODE_PROMPT = \"\"\"\nThe previous solution failed some test cases. Please analyze the problem carefully and provide an improved solution that addresses all edge cases and requirements. Ensure your code is efficient and follows best practices.\n\"\"\"\n\nREVIEW_CODE_PROMPT = \"\"\"\nPlease review the following code solution for the given problem. Analyze it for potential issues, edge cases, and adherence to best practices. If you find any issues or areas for improvement, describe them briefly. If no issues are found, respond with \"No issues found\".\n\"\"\"</prompt>", "tag": "HumanEval", "domain": "llm_judge", "parent_round": 11, "child_round": 12, "parent_score": 0.9333333333333333, "child_score": 0.9666666666666667, "performance_gain": 0.033333333333333326}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.88</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_15.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(5):  # Generate 5 solutions\\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        # Add a verification step using the Programmer operator\\n        verification = await self.programmer(problem=problem, analysis=final_solution['response'])\\n        \\n        # Double-check the final answer\\n        double_check = await self.custom(input=problem + f\\\"\\\\nInitial solution: {final_solution['response']}\\\\nVerification result: {verification['output']}\\\", instruction=prompt_custom.DOUBLE_CHECK_PROMPT)\\n        \\n        return double_check['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>MATH_SOLVE_PROMPT = \\\"\\\"\\\"\\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps carefully:\\n\\n1. Read and understand the problem thoroughly, ensuring you consider ALL given information.\\n2. Identify all key information, variables, and relationships, including any discounts or special conditions.\\n3. Determine the appropriate mathematical concepts, formulas, or equations to use.\\n4. Solve the problem step-by-step, showing all your work clearly.\\n5. Double-check your calculations and reasoning at each step.\\n6. Provide a clear and concise final answer.\\n7. Verify your solution by plugging it back into the original problem or using an alternative method if possible.\\n8. Explicitly calculate the total cost, including any discounts or special conditions mentioned in the problem.\\n\\nFormat your answer as follows:\\n- Use LaTeX notation for mathematical expressions where appropriate.\\n- Show each step of your solution process clearly.\\n- Clearly state your final answer at the end of your solution.\\n- Express numerical answers as precise values (avoid rounding unless specified).\\n- Ensure that your final answer is a single numerical value without any units or additional text.\\n- Do not include any explanatory text with your final answer, just the number itself.\\n\\nFor example, if the final answer is 42.5, your response should end with just:\\n42.5\\n\\nHere's the problem to solve:\\n\\n\\\"\\\"\\\"\\n\\nDOUBLE_CHECK_PROMPT = \\\"\\\"\\\"\\nYou are a meticulous math checker. Your task is to review the given problem, the initial solution, and the verification result. Then, determine the most accurate final answer.\\n\\nFollow these steps:\\n1. Carefully read the original problem, paying attention to all details and conditions.\\n2. Review the initial solution and the verification result.\\n3. If there are discrepancies, analyze both approaches to identify any errors or overlooked information.\\n4. Recalculate the problem yourself, ensuring all conditions and discounts are properly applied.\\n5. Provide the final, correct answer as a single numerical value without any units or additional text.\\n\\nRemember:\\n- Consider ALL information given in the problem, including any discounts or special conditions.\\n- Ensure that your calculations account for the entire problem, not just part of it.\\n- Double-check your math to avoid simple calculation errors.\\n- Your final answer should be a single number without any explanations.\\n\\nFor example, if the correct final answer is 123.0, your response should be just:\\n123.0\\n\\nHere's the problem and previous results to review:\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 16</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_16.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(5):  # Generate 5 solutions\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\n            solutions.append(solution['response'])\n        \n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Add a verification step using the Programmer operator\n        verification = await self.programmer(problem=problem, analysis=final_solution['response'])\n        \n        # Double-check the final answer with a focus on total cost calculation\n        double_check = await self.custom(input=problem + f\"\\nPrevious solution: {verification['output']}\", instruction=prompt_custom.DOUBLE_CHECK_PROMPT)\n        \n        if double_check['response'] != verification['output']:\n            return double_check['response'], self.llm.cost_manager.total_cost\n        else:\n            return verification['output'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>MATH_SOLVE_PROMPT = \"\"\"\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps carefully:\n\n1. Read and understand the problem thoroughly.\n2. Identify all key information, variables, and relationships.\n3. Determine the appropriate mathematical concepts, formulas, or equations to use.\n4. Solve the problem step-by-step, showing all your work clearly.\n5. Double-check your calculations and reasoning at each step.\n6. Provide a clear and concise final answer.\n7. Verify your solution by plugging it back into the original problem or using an alternative method if possible.\n\nFormat your answer as follows:\n- Use LaTeX notation for mathematical expressions where appropriate.\n- Show each step of your solution process clearly.\n- Clearly state your final answer at the end of your solution.\n- Express numerical answers as precise values (avoid rounding unless specified).\n- Ensure that your final answer is a single numerical value without any units or additional text.\n- Do not include any explanatory text with your final answer, just the number itself.\n\nFor example, if the final answer is 42.5, your response should end with just:\n42.5\n\nHere's the problem to solve:\n\n\"\"\"\n\nDOUBLE_CHECK_PROMPT = \"\"\"\nYou are a meticulous math problem solver. Your task is to double-check the solution to a given problem, focusing on total cost calculation and considering all given information, including discounts and multiple time periods if applicable.\n\n1. Carefully read the original problem.\n2. Review the previous solution provided.\n3. Pay special attention to:\n   - Total cost calculations\n   - Discounts or percentage-based calculations\n   - Multiple time periods or quantities\n   - Any information that might have been overlooked\n\n4. If you find any errors or discrepancies, recalculate the solution step-by-step.\n5. If the previous solution is correct, confirm it.\n\nProvide your final answer as a single numerical value without any units or additional text. For example:\n\n342.0\n\nHere's the original problem and the previous solution:\n\n\"\"\"</prompt>", "tag": "GSM8K", "domain": "llm_judge", "parent_round": 15, "child_round": 16, "parent_score": 0.88, "child_score": 0.89, "performance_gain": 0.010000000000000009}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.79</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_23.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(5):  # Generate 5 solutions\\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        # Add a verification step using the Programmer operator\\n        verification = await self.programmer(problem=problem, analysis=final_solution['response'])\\n        \\n        # Double-check the total cost calculation\\n        total_cost_check = await self.custom(input=problem + f\\\"\\\\nPrevious solution: {final_solution['response']}\\\", instruction=prompt_custom.TOTAL_COST_CHECK_PROMPT)\\n        \\n        if verification['output'] and total_cost_check['response']:\\n            return total_cost_check['response'], self.llm.cost_manager.total_cost\\n        else:\\n            return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>MATH_SOLVE_PROMPT = \\\"\\\"\\\"\\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps carefully:\\n\\n1. Read and understand the problem thoroughly.\\n2. Identify all key information, variables, and relationships, including multiple items and any discounts mentioned.\\n3. Determine the appropriate mathematical concepts, formulas, or equations to use.\\n4. Solve the problem step-by-step, showing all your work clearly.\\n5. Calculate the total cost, considering all items and applying any discounts mentioned in the problem.\\n6. Double-check your calculations and reasoning at each step.\\n7. Provide a clear and concise final answer.\\n8. Verify your solution by plugging it back into the original problem or using an alternative method if possible.\\n\\nFormat your answer as follows:\\n- Use LaTeX notation for mathematical expressions where appropriate.\\n- Show each step of your solution process clearly.\\n- Clearly state your final answer at the end of your solution.\\n- Express numerical answers as precise values (avoid rounding unless specified).\\n- Ensure that your final answer is a single numerical value without any units or additional text.\\n- Do not include any explanatory text with your final answer, just the number itself.\\n\\nFor example, if the final answer is 42.5, your response should end with just:\\n42.5\\n\\nHere's the problem to solve:\\n\\n\\\"\\\"\\\"\\n\\nTOTAL_COST_CHECK_PROMPT = \\\"\\\"\\\"\\nYou are a detail-oriented accountant tasked with double-checking a total cost calculation. Review the given problem and the previous solution, then recalculate the total cost, paying special attention to:\\n\\n1. All items mentioned in the problem\\n2. Any discounts or special pricing\\n3. Quantities of each item\\n\\nProvide only the final total cost as a single numerical value, without any units or additional text. If you find an error in the previous solution, correct it in your calculation.\\n\\nHere's the problem and previous solution:\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 24</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_24.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\n            solutions.append(solution['response'])\n        \n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Add a verification step using the Programmer operator\n        verification_result = await self.programmer(problem=problem, analysis=final_solution['response'])\n        \n        # Add a final review step using the Custom operator\n        review_result = await self.custom(input=f\"Problem: {problem}\\nCalculated answer: {verification_result['output']}\", instruction=prompt_custom.FINAL_REVIEW_PROMPT)\n        \n        return review_result['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>MATH_SOLVE_PROMPT = \"\"\"\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps:\n\n1. Carefully read and understand the problem.\n2. Identify the key information and variables.\n3. Determine the appropriate mathematical concepts or formulas to use.\n4. Pay special attention to time-based calculations and unit conversions.\n5. Solve the problem step by step, showing all your work.\n6. Double-check your calculations and reasoning.\n7. Provide a clear and concise final answer.\n\nRemember to format your answer as follows:\n- Use LaTeX notation for mathematical expressions where appropriate.\n- Clearly state your final answer at the end of your solution.\n- Express numerical answers as precise values (avoid rounding unless specified).\n- Ensure that your final answer is a single numerical value without any units or additional text.\n- Do not include any explanatory text with your final answer, just the number itself.\n\nFor example, if the final answer is 42.5, your response should end with just:\n42.5\n\nHere's the problem to solve:\n\n\"\"\"\n\nFINAL_REVIEW_PROMPT = \"\"\"\nYou are a meticulous reviewer tasked with ensuring the correctness and proper formatting of a mathematical solution. Please review the problem and the calculated answer, then follow these steps:\n\n1. Verify that the answer is logically consistent with the problem statement.\n2. Check if the answer is a single numerical value without any units or additional text.\n3. If the answer includes units or explanatory text, remove them and keep only the numerical value.\n4. If the answer is not a single numerical value, attempt to extract or calculate the correct single numerical value based on the problem and the given answer.\n5. Ensure the final answer is expressed as a precise value (avoid rounding unless specified in the original problem).\n\nProvide your final reviewed answer as a single numerical value without any additional text or explanation.\n\n\"\"\"</prompt>", "tag": "GSM8K", "domain": "llm_judge", "parent_round": 23, "child_round": 24, "parent_score": 0.79, "child_score": 0.88, "performance_gain": 0.08999999999999997}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>\\nPrevious failed modifications:\\n  - Add a new Custom operator to generate multiple solutions, then use ScEnsemble to select the best one. This modification aims to improve the accuracy and consistency of the final answer. (Score: 0.5243697478991596)\\n  - Add a new Custom operator to generate a more detailed step-by-step solution, and modify the ScEnsemble operator to compare and select the best solution from multiple generated solutions. (Score: 0.5176470588235293)</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.5462184873949579</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.round_14.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        # Use Programmer to generate and execute Python code\\n        code_solution = await self.programmer(problem=problem)\\n        \\n        # Use Custom to generate a detailed step-by-step solution\\n        detailed_solution = await self.custom(input=problem + f\\\"\\\\nCode output: {code_solution['output']}\\\", instruction=prompt_custom.DETAILED_SOLUTION_PROMPT)\\n        \\n        # Use Custom to review and refine the solution\\n        refined_solution = await self.custom(input=problem + f\\\"\\\\nDetailed solution: {detailed_solution['response']}\\\", instruction=prompt_custom.REVIEW_AND_REFINE_PROMPT)\\n        \\n        # Generate multiple solutions using Custom\\n        solutions = []\\n        for _ in range(3):\\n            solution = await self.custom(input=problem, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        # Use ScEnsemble to select the most consistent solution\\n        final_solution = await self.sc_ensemble(solutions=solutions + [refined_solution['response']], problem=problem)\\n        \\n        return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>DETAILED_SOLUTION_PROMPT = \\\"\\\"\\\"\\nGiven the mathematical problem and the output from the code execution, please provide a comprehensive and detailed step-by-step solution. Follow these guidelines:\\n\\n1. Begin with a clear statement of the problem.\\n2. Explain the approach and any formulas or concepts used.\\n3. Show step-by-step calculations, using LaTeX notation for mathematical expressions.\\n4. Interpret the code output and incorporate it into your explanation.\\n5. Provide intermediate results and explanations for each step.\\n6. Ensure all mathematical notation is in LaTeX format.\\n7. Conclude with a final answer, enclosed in \\\\boxed{} LaTeX notation.\\n\\nYour response should be thorough, mathematically rigorous, and easy to follow, suitable for a student learning the concept.\\n\\\"\\\"\\\"\\n\\nREVIEW_AND_REFINE_PROMPT = \\\"\\\"\\\"\\nPlease review and refine the given detailed solution for the mathematical problem. Follow these guidelines:\\n\\n1. Check for mathematical accuracy and correctness.\\n2. Ensure all steps are logically connected and well-explained.\\n3. Verify that all LaTeX notation is correctly used and formatted.\\n4. Add any missing steps or explanations that could improve clarity.\\n5. Simplify overly complex explanations if possible.\\n6. Ensure the final answer is correct and properly enclosed in \\\\boxed{} LaTeX notation.\\n7. If any errors are found, correct them and explain the correction.\\n\\nProvide the refined solution, maintaining the step-by-step format and mathematical rigor of the original.\\n\\\"\\\"\\\"\\n\\nGENERATE_SOLUTION_PROMPT = \\\"\\\"\\\"\\nPlease solve the given mathematical problem step by step. Follow these guidelines:\\n\\n1. State the problem clearly.\\n2. Outline the approach and any relevant formulas or concepts.\\n3. Provide detailed calculations, using LaTeX notation for mathematical expressions.\\n4. Explain each step of your reasoning.\\n5. Present the final answer enclosed in \\\\boxed{} LaTeX notation.\\n6. Ensure all mathematical notation is in LaTeX format.\\n\\nYour solution should be thorough, mathematically sound, and easy to understand.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Add a new Custom operator to generate multiple solutions, then use ScEnsemble to select the best one. This modification aims to improve the accuracy and consistency of the final answer.</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.round_15.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        # Use Programmer to generate and execute Python code\n        code_solution = await self.programmer(problem=problem)\n        \n        # Use Custom to generate a detailed step-by-step solution\n        detailed_solution = await self.custom(input=problem + f\"\\nCode output: {code_solution['output']}\", instruction=prompt_custom.DETAILED_SOLUTION_PROMPT)\n        \n        # Use Custom to review and refine the solution\n        refined_solution = await self.custom(input=problem + f\"\\nDetailed solution: {detailed_solution['response']}\", instruction=prompt_custom.REVIEW_AND_REFINE_PROMPT)\n        \n        # Generate multiple solutions using Custom\n        solutions = []\n        for _ in range(3):\n            solution = await self.custom(input=problem, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT)\n            solutions.append(solution['response'])\n        \n        # Add the refined solution to the list of solutions\n        solutions.append(refined_solution['response'])\n        \n        # Use ScEnsemble to select the most consistent solution\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>DETAILED_SOLUTION_PROMPT = \"\"\"\nGiven the mathematical problem and the output from the code execution, please provide a comprehensive and detailed step-by-step solution. Follow these guidelines:\n\n1. Begin with a clear statement of the problem.\n2. Explain the approach and any formulas or concepts used.\n3. Show step-by-step calculations, using LaTeX notation for mathematical expressions.\n4. Interpret the code output and incorporate it into your explanation.\n5. Provide intermediate results and explanations for each step.\n6. Ensure all mathematical notation is in LaTeX format.\n7. Conclude with a final answer, enclosed in \\boxed{} LaTeX notation.\n\nYour response should be thorough, mathematically rigorous, and easy to follow, suitable for a student learning the concept.\n\"\"\"\n\nREVIEW_AND_REFINE_PROMPT = \"\"\"\nPlease review and refine the given detailed solution for the mathematical problem. Follow these guidelines:\n\n1. Check for mathematical accuracy and correctness.\n2. Ensure all steps are logically connected and well-explained.\n3. Verify that all LaTeX notation is correctly used and formatted.\n4. Add any missing steps or explanations that could improve clarity.\n5. Simplify overly complex explanations if possible.\n6. Ensure the final answer is correct and properly enclosed in \\boxed{} LaTeX notation.\n7. If any errors are found, correct them and explain the correction.\n\nProvide the refined solution, maintaining the step-by-step format and mathematical rigor of the original.\n\"\"\"\n\nGENERATE_SOLUTION_PROMPT = \"\"\"\nPlease solve the given mathematical problem step by step. Follow these guidelines:\n\n1. State the problem clearly.\n2. Outline the approach and any relevant formulas or concepts.\n3. Provide detailed calculations, using LaTeX notation for mathematical expressions.\n4. Explain each step of your reasoning.\n5. Present the final answer enclosed in \\boxed{} LaTeX notation.\n6. Ensure all mathematical notation is in LaTeX format.\n\nYour solution should be thorough, mathematically sound, and easy to understand.\n\"\"\"</prompt>", "tag": "MATH", "domain": "llm_judge", "parent_round": 14, "child_round": 15, "parent_score": 0.5462184873949579, "child_score": 0.5378151260504201, "performance_gain": -0.008403361344537785}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.5294117647058824</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.round_19.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        # Use Programmer to generate and execute Python code\\n        code_solution = await self.programmer(problem=problem)\\n        \\n        # Use Custom to refine and format the answer\\n        refined_solution = await self.custom(input=problem + f\\\"\\\\nCode output: {code_solution['output']}\\\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\\n        \\n        # Generate a detailed step-by-step solution using Custom\\n        detailed_solution = await self.custom(input=problem, instruction=prompt_custom.DETAILED_SOLUTION_PROMPT)\\n        \\n        # Generate a simplified solution using Custom\\n        simplified_solution = await self.custom(input=problem, instruction=prompt_custom.SIMPLIFIED_SOLUTION_PROMPT)\\n        \\n        # Generate multiple solutions using Custom\\n        solutions = [\\n            refined_solution['response'],\\n            detailed_solution['response'],\\n            simplified_solution['response']\\n        ]\\n        for _ in range(2):\\n            solution = await self.custom(input=problem, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        # Use ScEnsemble to select the best solution\\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the mathematical problem and the output from the code execution, please provide a well-formatted and detailed solution. Follow these guidelines:\\n\\n1. Begin with a clear statement of the problem.\\n2. Explain the approach and any formulas or concepts used.\\n3. Show step-by-step calculations, using LaTeX notation for mathematical expressions.\\n4. Interpret the code output and incorporate it into your explanation.\\n5. Provide a final answer, enclosed in \\\\boxed{} LaTeX notation.\\n6. Ensure all mathematical notation is in LaTeX format.\\n\\nYour response should be comprehensive, mathematically rigorous, and easy to follow.\\n\\\"\\\"\\\"\\n\\nGENERATE_SOLUTION_PROMPT = \\\"\\\"\\\"\\nPlease solve the given mathematical problem step by step. Follow these guidelines:\\n\\n1. State the problem clearly.\\n2. Outline the approach and any relevant formulas or concepts.\\n3. Provide detailed calculations, using LaTeX notation for mathematical expressions.\\n4. Explain each step of your reasoning.\\n5. Present the final answer enclosed in \\\\boxed{} LaTeX notation.\\n6. Ensure all mathematical notation is in LaTeX format.\\n\\nYour solution should be thorough, mathematically sound, and easy to understand.\\n\\\"\\\"\\\"\\n\\nDETAILED_SOLUTION_PROMPT = \\\"\\\"\\\"\\nProvide a comprehensive, step-by-step solution to the given mathematical problem. Your response should include:\\n\\n1. A clear restatement of the problem.\\n2. An explanation of the mathematical concepts and theorems involved.\\n3. A detailed, logical progression of steps leading to the solution.\\n4. Clear explanations for each step, including the reasoning behind it.\\n5. All mathematical expressions and equations in LaTeX format.\\n6. Visual aids or diagrams if applicable (described in text).\\n7. A final answer clearly marked and enclosed in \\\\boxed{} LaTeX notation.\\n8. A brief explanation of the significance of the result, if relevant.\\n\\nEnsure your solution is rigorous, easy to follow, and educational for someone learning the concept.\\n\\\"\\\"\\\"\\n\\nSIMPLIFIED_SOLUTION_PROMPT = \\\"\\\"\\\"\\nProvide a concise and simplified solution to the given mathematical problem. Your response should include:\\n\\n1. A brief restatement of the problem.\\n2. The main approach or key concept used to solve the problem.\\n3. Essential steps in the solution process, without extensive details.\\n4. The final answer enclosed in \\\\boxed{} LaTeX notation.\\n5. Use LaTeX notation for all mathematical expressions.\\n\\nKeep the solution clear and straightforward, focusing on the core ideas and steps needed to arrive at the answer.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 20</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.round_20.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        # Generate a summary of the problem and key concepts\n        summary = await self.custom(input=problem, instruction=prompt_custom.SUMMARIZE_PROBLEM_PROMPT)\n        \n        # Use Programmer to generate and execute Python code\n        code_solution = await self.programmer(problem=problem)\n        \n        # Use Custom to refine and format the answer\n        refined_solution = await self.custom(input=problem + f\"\\nSummary: {summary['response']}\\nCode output: {code_solution['output']}\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n        \n        # Generate multiple solutions using Custom\n        solutions = []\n        for _ in range(3):\n            solution = await self.custom(input=problem + f\"\\nSummary: {summary['response']}\", instruction=prompt_custom.GENERATE_SOLUTION_PROMPT)\n            solutions.append(solution['response'])\n        \n        # Generate a detailed step-by-step solution\n        detailed_solution = await self.custom(input=problem + f\"\\nSummary: {summary['response']}\", instruction=prompt_custom.DETAILED_SOLUTION_PROMPT)\n        solutions.append(detailed_solution['response'])\n        \n        # Use ScEnsemble to select the best solution\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>SUMMARIZE_PROBLEM_PROMPT = \"\"\"\nProvide a concise summary of the given mathematical problem, highlighting the key concepts and formulas involved. Your summary should:\n\n1. Restate the problem briefly.\n2. Identify the main mathematical topics or areas relevant to the problem.\n3. List any important formulas or theorems that may be useful in solving the problem.\n4. Mention any specific constraints or conditions given in the problem.\n\nKeep your summary clear and concise, focusing on the essential elements needed to understand and approach the problem.\n\"\"\"\n\nREFINE_ANSWER_PROMPT = \"\"\"\nGiven the mathematical problem, the problem summary, and the output from the code execution, please provide a well-formatted and detailed solution. Follow these guidelines:\n\n1. Begin with a clear statement of the problem.\n2. Briefly mention the key concepts identified in the summary.\n3. Explain the approach and any formulas or concepts used.\n4. Show step-by-step calculations, using LaTeX notation for mathematical expressions.\n5. Interpret the code output and incorporate it into your explanation.\n6. Provide a final answer, enclosed in \\boxed{} LaTeX notation.\n7. Ensure all mathematical notation is in LaTeX format.\n\nYour response should be comprehensive, mathematically rigorous, and easy to follow.\n\"\"\"\n\nGENERATE_SOLUTION_PROMPT = \"\"\"\nPlease solve the given mathematical problem step by step, taking into account the provided problem summary. Follow these guidelines:\n\n1. State the problem clearly.\n2. Reference the key concepts and formulas mentioned in the summary.\n3. Outline the approach and any relevant formulas or concepts.\n4. Provide detailed calculations, using LaTeX notation for mathematical expressions.\n5. Explain each step of your reasoning.\n6. Present the final answer enclosed in \\boxed{} LaTeX notation.\n7. Ensure all mathematical notation is in LaTeX format.\n\nYour solution should be thorough, mathematically sound, and easy to understand.\n\"\"\"\n\nDETAILED_SOLUTION_PROMPT = \"\"\"\nProvide a comprehensive, step-by-step solution to the given mathematical problem, incorporating the information from the problem summary. Your response should include:\n\n1. A clear restatement of the problem.\n2. An explanation of the mathematical concepts and formulas involved, referencing the summary.\n3. A detailed, logical progression of steps to solve the problem.\n4. Clear explanations for each step, including the reasoning behind it.\n5. All mathematical expressions and equations in LaTeX format.\n6. Visual aids or diagrams if applicable (described in text).\n7. A final answer clearly marked and enclosed in \\boxed{} LaTeX notation.\n8. A brief explanation of the significance of the answer in the context of the original problem.\n\nAim for clarity, accuracy, and thoroughness in your solution.\n\"\"\"</prompt>", "tag": "MATH", "domain": "llm_judge", "parent_round": 19, "child_round": 20, "parent_score": 0.5294117647058824, "child_score": 0.5378151260504201, "performance_gain": 0.008403361344537785}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.9666666666666667</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_19.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=\\\"\\\")\\n        \\n        # Add a review step\\n        review_result = await self.custom(input=f\\\"Problem: {problem}\\\\nSolution: {solution['response']}\\\", instruction=prompt_custom.REVIEW_CODE_PROMPT)\\n        \\n        if \\\"No issues found\\\" not in review_result['response']:\\n            # If issues are found, generate a new solution\\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.IMPROVE_CODE_PROMPT + f\\\"\\\\nReview feedback: {review_result['response']}\\\")\\n        \\n        test_result = await self.test(problem=problem, solution=solution['response'], entry_point=entry_point)\\n        \\n        if test_result['result']:\\n            return test_result['solution'], self.llm.cost_manager.total_cost\\n        else:\\n            # If the test fails, try to generate a new solution\\n            new_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.IMPROVE_CODE_PROMPT)\\n            return new_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>IMPROVE_CODE_PROMPT = \\\"\\\"\\\"\\nThe previous solution failed some test cases. Please analyze the problem carefully and provide an improved solution that addresses all edge cases and requirements. Ensure your code is efficient and follows best practices.\\n\\\"\\\"\\\"\\n\\nREVIEW_CODE_PROMPT = \\\"\\\"\\\"\\nPlease review the following code solution and identify any potential issues, edge cases, or improvements that could be made. If no issues are found, respond with \\\"No issues found\\\". Otherwise, provide a brief description of the issues and suggestions for improvement.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 20</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_20.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        # Generate multiple solutions\n        solutions = []\n        for _ in range(3):\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT)\n            solutions.append(solution['response'])\n\n        # Use ScEnsemble to select the best solution\n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Review and improve the selected solution\n        reviewed_solution = await self.custom(input=f\"Problem: {problem}\\nGenerated solution: {best_solution['response']}\", instruction=prompt_custom.REVIEW_SOLUTION_PROMPT)\n        \n        # Test the reviewed solution\n        test_result = await self.test(problem=problem, solution=reviewed_solution['response'], entry_point=entry_point)\n        \n        if test_result['result']:\n            return test_result['solution'], self.llm.cost_manager.total_cost\n        else:\n            # If the test fails, try to improve the solution\n            improved_solution = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {reviewed_solution['response']}\\nError: {test_result['solution']}\", instruction=prompt_custom.IMPROVE_SOLUTION_PROMPT)\n            return improved_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>GENERATE_SOLUTION_PROMPT = \"\"\"\nGenerate a Python function to solve the given problem. Ensure the solution is complete, correct, and efficient.\n\nYour task:\n1. Understand the problem statement.\n2. Implement a Python function that solves the problem.\n3. Consider edge cases and potential optimizations.\n4. Provide only the Python function as your response, without any additional explanations or comments.\n\"\"\"\n\nREVIEW_SOLUTION_PROMPT = \"\"\"\nReview the given problem and the generated solution. Analyze the code for correctness, efficiency, and adherence to best practices. Improve the solution if necessary.\n\nYour task:\n1. Understand the problem statement.\n2. Review the generated solution.\n3. Check for logical errors, edge cases, and potential improvements.\n4. Rewrite the solution if improvements are needed, or keep it as is if it's optimal.\n5. Ensure the final solution is complete, correct, and efficient.\n\nProvide only the reviewed and potentially improved Python function as your response, without any additional explanations or comments.\n\"\"\"\n\nIMPROVE_SOLUTION_PROMPT = \"\"\"\nAnalyze the given problem and the failed solution. Identify the errors and improve the code to solve the problem correctly. Make sure to handle edge cases and follow best practices in Python programming.\n\nYour task:\n1. Understand the problem statement.\n2. Review the failed solution and the error message.\n3. Identify the cause of the failure.\n4. Rewrite the solution, addressing the identified issues.\n5. Ensure the new solution is complete, correct, and efficient.\n\nProvide only the improved Python function as your response, without any additional explanations or comments.\n\"\"\"</prompt>", "tag": "HumanEval", "domain": "llm_judge", "parent_round": 19, "child_round": 20, "parent_score": 0.9666666666666667, "child_score": 0.9333333333333333, "performance_gain": -0.033333333333333326}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve QA problems.\\nReferring to the given graph and prompt, which forms a basic example of a QA solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.6897058823529412</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_17.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.answer_generate = operator.AnswerGenerate(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):  # Generate 3 solutions\\n            step_by_step = await self.answer_generate(input=problem)\\n            solution = await self.custom(input=f\\\"Question: {problem}\\\\nStep-by-step solution: {step_by_step['thought']}\\\\nInitial answer: {step_by_step['answer']}\\\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions)\\n        \\n        # Add verification step\\n        verified_solution = await self.custom(input=f\\\"Question: {problem}\\\\nProposed answer: {final_solution['response']}\\\", instruction=prompt_custom.VERIFY_ANSWER_PROMPT)\\n        \\n        return verified_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\\n\\n1. Ensure the answer is concise and directly addresses the question.\\n2. If the answer is a number, provide only the number without additional text.\\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\\n4. Remove any explanations or reasoning from the final answer.\\n5. Double-check that the refined answer is consistent with the step-by-step solution and initial answer.\\n6. If the answer involves selecting between options, clearly state the chosen option.\\n\\nYour task is to extract or refine the most accurate answer based on the provided information.\\n\\\"\\\"\\\"\\n\\nVERIFY_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question and the proposed answer, please verify and format the answer according to the following rules:\\n\\n1. If the answer is a single number, ensure it's provided without any units or additional text (e.g., \\\"5\\\" instead of \\\"5%\\\").\\n2. If the answer consists of multiple numbers, separate them with a vertical bar (|) without spaces (e.g., \\\"3|20|32\\\").\\n3. Remove any explanatory text or reasoning from the answer.\\n4. Ensure the answer directly addresses the question without any extraneous information.\\n5. If the original answer doesn't meet these criteria, modify it to comply.\\n\\nProvide only the verified and formatted answer without any additional explanation.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 18</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_18.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.answer_generate = operator.AnswerGenerate(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):  # Generate 3 solutions\n            step_by_step = await self.answer_generate(input=problem)\n            solution = await self.custom(input=f\"Question: {problem}\\nStep-by-step solution: {step_by_step['thought']}\\nInitial answer: {step_by_step['answer']}\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n            solutions.append(solution['response'])\n        \n        final_solution = await self.sc_ensemble(solutions=solutions)\n        verified_solution = await self.custom(input=f\"Question: {problem}\\nFinal answer: {final_solution['response']}\", instruction=prompt_custom.VERIFY_ANSWER_PROMPT)\n        return verified_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>REFINE_ANSWER_PROMPT = \"\"\"\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\n\n1. Ensure the answer is concise and directly addresses the question.\n2. If the answer is a number, provide only the number without additional text.\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\n4. Remove any explanations or reasoning from the final answer.\n5. Double-check that the refined answer is consistent with the step-by-step solution and initial answer.\n6. If the answer involves selecting between options, clearly state the chosen option.\n\nYour task is to extract or refine the most accurate answer based on the provided information.\n\"\"\"\n\nVERIFY_ANSWER_PROMPT = \"\"\"\nGiven the question and the final answer, please verify and refine the answer to ensure it meets the following criteria:\n\n1. The answer should be a single number or a short phrase, without any additional explanations.\n2. If the answer is a percentage, remove the percentage sign and provide only the numerical value.\n3. Ensure that the answer is properly formatted according to the question requirements.\n4. If the answer should be a whole number, round it to the nearest integer.\n5. Double-check that the answer directly addresses the question asked.\n\nYour task is to provide the verified and refined answer that meets these criteria. If the answer already meets all criteria, return it unchanged.\n\"\"\"</prompt>", "tag": "DROP", "domain": "llm_judge", "parent_round": 17, "child_round": 18, "parent_score": 0.6897058823529412, "child_score": 0.7348039215686274, "performance_gain": 0.045098039215686225}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.7333333333333333</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_3.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        Custom operator to generate anything you want.\\n        But when you want to get standard code, you should use custom_code_generate operator.\\n        \\\"\\\"\\\"\\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=\\\"\\\")\\n        \\n        # Add a review step using the Custom operator\\n        review_result = await self.custom(input=f\\\"Problem: {problem}\\\\nGenerated Solution: {solution['response']}\\\", instruction=prompt_custom.REVIEW_PROMPT)\\n        \\n        if \\\"Improved Solution:\\\" in review_result['response']:\\n            final_solution = review_result['response'].split(\\\"Improved Solution:\\\")[1].strip()\\n        else:\\n            final_solution = solution['response']\\n        \\n        return final_solution, self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>REVIEW_PROMPT = \\\"\\\"\\\"\\nReview the following problem and the generated solution. If you find any issues or potential improvements, provide an improved solution. If the solution is already optimal, state that no improvements are needed.\\n\\nProblem: {input}\\n\\nYour response should be in the following format:\\nReview: [Your review comments]\\nImproved Solution: [The improved solution if any, or \\\"No improvements needed\\\" if the original solution is optimal]\\n\\nEnsure that your review is thorough and that any improved solution addresses the problem correctly and efficiently.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 4</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_4.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\n        \n        # Add a review step\n        review = await self.custom(input=f\"Problem: {problem}\\nGenerated solution: {solution['response']}\", instruction=prompt_custom.REVIEW_PROMPT)\n        \n        # Improve the solution based on the review\n        improved_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\"{prompt_custom.CODE_GENERATE_PROMPT}\\n\\nConsider this review: {review['response']}\")\n        \n        test_result = await self.test(problem=problem, solution=improved_solution['response'], entry_point=entry_point)\n        \n        if not test_result['result']:\n            analysis = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {improved_solution['response']}\\nTest result: {test_result['solution']}\", instruction=prompt_custom.ANALYZE_AND_IMPROVE_PROMPT)\n            final_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\"{prompt_custom.CODE_GENERATE_PROMPT}\\n\\nConsider this analysis: {analysis['response']}\")\n            return final_solution['response'], self.llm.cost_manager.total_cost\n        \n        return improved_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>CODE_GENERATE_PROMPT = \"\"\"\nGenerate a Python function that solves the given problem. Ensure the function signature matches the problem description. Include docstrings and comments to explain the logic. The solution should be efficient and handle edge cases. Pay special attention to the order of operations and ensure that the function evaluates the expression correctly.\n\"\"\"\n\nREVIEW_PROMPT = \"\"\"\nReview the generated solution and suggest improvements. Consider the following:\n1. Does the function correctly implement the order of operations?\n2. Are all required operators (+, -, *, //, **) handled properly?\n3. Is there proper error handling for cases like division by zero?\n4. Does the function handle the case where the operator list is empty?\n5. Is the code efficient and readable?\nProvide specific suggestions for improvement.\n\"\"\"\n\nANALYZE_AND_IMPROVE_PROMPT = \"\"\"\nAnalyze the failed solution and provide suggestions for improvement. Consider the following:\n1. Identify logical errors or misunderstandings of the problem.\n2. Check for edge cases that might not be handled correctly.\n3. Ensure the order of operations is correctly implemented.\n4. Suggest optimizations or alternative approaches if applicable.\n5. Provide specific code snippets or pseudocode to address the issues found.\n\"\"\"</prompt>", "tag": "HumanEval", "domain": "llm_judge", "parent_round": 3, "child_round": 4, "parent_score": 0.7333333333333333, "child_score": 0.9333333333333333, "performance_gain": 0.20000000000000007}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.9</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_19.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=\\\"\\\")\\n        \\n        # Add a review step\\n        review_result = await self.custom(input=f\\\"Problem: {problem}\\\\nSolution: {solution['response']}\\\", instruction=prompt_custom.REVIEW_CODE_PROMPT)\\n        \\n        if \\\"No issues found\\\" not in review_result['response']:\\n            # If issues are found, generate a new solution\\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.IMPROVE_CODE_PROMPT + f\\\"\\\\nReview feedback: {review_result['response']}\\\")\\n        \\n        test_result = await self.test(problem=problem, solution=solution['response'], entry_point=entry_point)\\n        \\n        if test_result['result']:\\n            return test_result['solution'], self.llm.cost_manager.total_cost\\n        else:\\n            # If the test fails, try to generate a new solution\\n            new_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.IMPROVE_CODE_PROMPT)\\n            return new_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>IMPROVE_CODE_PROMPT = \\\"\\\"\\\"\\nThe previous solution failed some test cases. Please analyze the problem carefully and provide an improved solution that addresses all edge cases and requirements. Ensure your code is efficient and follows best practices.\\n\\\"\\\"\\\"\\n\\nREVIEW_CODE_PROMPT = \\\"\\\"\\\"\\nPlease review the following code solution and identify any potential issues, edge cases, or improvements that could be made. If no issues are found, respond with \\\"No issues found\\\". Otherwise, provide a brief description of the issues and suggestions for improvement.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 20</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_20.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        # Generate multiple solutions\n        solutions = []\n        for _ in range(3):\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT)\n            solutions.append(solution['response'])\n\n        # Use ScEnsemble to select the best solution\n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Review and improve the selected solution\n        reviewed_solution = await self.custom(input=f\"Problem: {problem}\\nGenerated solution: {best_solution['response']}\", instruction=prompt_custom.REVIEW_SOLUTION_PROMPT)\n        \n        # Test the reviewed solution\n        test_result = await self.test(problem=problem, solution=reviewed_solution['response'], entry_point=entry_point)\n        \n        if test_result['result']:\n            return test_result['solution'], self.llm.cost_manager.total_cost\n        else:\n            # If the test fails, try to improve the solution\n            improved_solution = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {reviewed_solution['response']}\\nError: {test_result['solution']}\", instruction=prompt_custom.IMPROVE_SOLUTION_PROMPT)\n            return improved_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>GENERATE_SOLUTION_PROMPT = \"\"\"\nGenerate a Python function to solve the given problem. Ensure the solution is complete, correct, and efficient.\n\nYour task:\n1. Understand the problem statement.\n2. Implement a Python function that solves the problem.\n3. Consider edge cases and potential optimizations.\n4. Provide only the Python function as your response, without any additional explanations or comments.\n\"\"\"\n\nREVIEW_SOLUTION_PROMPT = \"\"\"\nReview the given problem and the generated solution. Analyze the code for correctness, efficiency, and adherence to best practices. Improve the solution if necessary.\n\nYour task:\n1. Understand the problem statement.\n2. Review the generated solution.\n3. Check for logical errors, edge cases, and potential improvements.\n4. Rewrite the solution if improvements are needed, or keep it as is if it's optimal.\n5. Ensure the final solution is complete, correct, and efficient.\n\nProvide only the reviewed and potentially improved Python function as your response, without any additional explanations or comments.\n\"\"\"\n\nIMPROVE_SOLUTION_PROMPT = \"\"\"\nAnalyze the given problem and the failed solution. Identify the errors and improve the code to solve the problem correctly. Make sure to handle edge cases and follow best practices in Python programming.\n\nYour task:\n1. Understand the problem statement.\n2. Review the failed solution and the error message.\n3. Identify the cause of the failure.\n4. Rewrite the solution, addressing the identified issues.\n5. Ensure the new solution is complete, correct, and efficient.\n\nProvide only the improved Python function as your response, without any additional explanations or comments.\n\"\"\"</prompt>", "tag": "HumanEval", "domain": "llm_judge", "parent_round": 19, "child_round": 20, "parent_score": 0.9, "child_score": 0.9333333333333333, "performance_gain": 0.033333333333333326}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.8488372093023255</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_17.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        Custom operator to generate anything you want.\\n        But when you want to get standard code, you should use custom_code_generate operator.\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):  # Generate 3 solutions\\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        test_result = await self.test(problem=problem, solution=best_solution['response'], entry_point=entry_point)\\n        \\n        if test_result['result']:\\n            return test_result['solution'], self.llm.cost_manager.total_cost\\n        else:\\n            # If the test fails, try to fix the solution\\n            fixed_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nFailed solution: {best_solution['response']}\\\\nError: {test_result['solution']}\\\", instruction=prompt_custom.FIX_CODE_PROMPT)\\n            return fixed_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>CODE_GENERATE_PROMPT = \\\"\\\"\\\"\\nGenerate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity.\\n\\nProblem:\\n{problem}\\n\\nFunction signature:\\n{entry_point}\\n\\nGenerate the complete function below:\\n\\\"\\\"\\\"\\n\\nFIX_CODE_PROMPT = \\\"\\\"\\\"\\nThe provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation.\\n\\nProblem:\\n{input}\\n\\nProvide the corrected function below:\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 18</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_18.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        solutions = []\n        for _ in range(3):  # Generate 3 solutions\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\n            solutions.append(solution['response'])\n        \n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Generate additional test cases\n        additional_tests = await self.custom(input=f\"Problem: {problem}\\nSolution: {best_solution['response']}\", instruction=prompt_custom.GENERATE_TESTS_PROMPT)\n        \n        # Combine original problem and additional tests\n        enhanced_problem = f\"{problem}\\n\\nAdditional test cases:\\n{additional_tests['response']}\"\n        \n        test_result = await self.test(problem=enhanced_problem, solution=best_solution['response'], entry_point=entry_point)\n        \n        if test_result['result']:\n            return test_result['solution'], self.llm.cost_manager.total_cost\n        else:\n            # If the test fails, try to fix the solution\n            fixed_solution = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {best_solution['response']}\\nError: {test_result['solution']}\", instruction=prompt_custom.FIX_CODE_PROMPT)\n            return fixed_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>CODE_GENERATE_PROMPT = \"\"\"\nGenerate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity.\n\nProblem:\n{problem}\n\nFunction signature:\n{entry_point}\n\nGenerate the complete function below:\n\"\"\"\n\nFIX_CODE_PROMPT = \"\"\"\nThe provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation.\n\nProblem:\n{input}\n\nProvide the corrected function below:\n\"\"\"\n\nGENERATE_TESTS_PROMPT = \"\"\"\nGiven the problem and a potential solution, generate additional test cases to thoroughly evaluate the function. Include edge cases and typical scenarios. Format the test cases as assert statements that can be directly added to a Python test function.\n\nProblem:\n{input}\n\nGenerate 3-5 additional test cases as assert statements:\n\"\"\"</prompt>", "tag": "MBPP", "domain": "llm_judge", "parent_round": 17, "child_round": 18, "parent_score": 0.8488372093023255, "child_score": 0.813953488372093, "performance_gain": -0.03488372093023251}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>Previous successful modifications:\\n  - Modify the Custom operator to generate a more detailed step-by-step solution, and add a new Custom operator to review and refine the final answer. This will improve the clarity, accuracy, and completeness of the solution process. (Score: 0.5310924369747899)\\n  - Add a new Custom operator to generate a detailed step-by-step solution, and modify the ScEnsemble operator to compare and select the best solution from multiple approaches. (Score: 0.5512605042016807)\\n  - Add a new Custom operator to generate a detailed step-by-step solution, and modify the ScEnsemble operator to compare and select the best solution from multiple approaches. (Score: 0.5378151260504201)\\n\\nPrevious failed modifications:\\n  - Add a new Custom operator to generate a step-by-step solution, and modify the ScEnsemble operator to compare and select the best solution from multiple approaches. (Score: 0.5042016806722688)\\n  - Modify the Custom operator to generate a more detailed step-by-step solution, and add a new Custom operator to refine and format the final answer. This will improve the clarity and accuracy of the solution process. (Score: 0.5193277310924369)\\n  - Add a new Custom operator to generate multiple solutions using different approaches, then use ScEnsemble to select the best solution. This will increase the diversity of solutions and potentially improve accuracy. (Score: 0.0)</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.5462184873949579</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.round_3.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        # Use Programmer to generate and execute Python code\\n        code_solution = await self.programmer(problem=problem)\\n        \\n        # Use Custom to refine and format the answer\\n        refined_solution = await self.custom(input=problem + f\\\"\\\\nCode output: {code_solution['output']}\\\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\\n        \\n        # Generate multiple solutions using Custom\\n        solutions = []\\n        for _ in range(3):\\n            solution = await self.custom(input=problem, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        # Use ScEnsemble to select the most consistent solution\\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the mathematical problem and the output from the code execution, please provide a well-formatted and detailed solution. Follow these guidelines:\\n\\n1. Begin with a clear statement of the problem.\\n2. Explain the approach and any formulas or concepts used.\\n3. Show step-by-step calculations, using LaTeX notation for mathematical expressions.\\n4. Interpret the code output and incorporate it into your explanation.\\n5. Provide a final answer, enclosed in \\\\boxed{} LaTeX notation.\\n6. Ensure all mathematical notation is in LaTeX format.\\n\\nYour response should be comprehensive, mathematically rigorous, and easy to follow.\\n\\\"\\\"\\\"\\n\\nGENERATE_SOLUTION_PROMPT = \\\"\\\"\\\"\\nPlease solve the given mathematical problem step by step. Follow these guidelines:\\n\\n1. State the problem clearly.\\n2. Outline the approach and any relevant formulas or concepts.\\n3. Provide detailed calculations, using LaTeX notation for mathematical expressions.\\n4. Explain each step of your reasoning.\\n5. Present the final answer enclosed in \\\\boxed{} LaTeX notation.\\n6. Ensure all mathematical notation is in LaTeX format.\\n\\nYour solution should be thorough, mathematically sound, and easy to understand.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Add a new Custom operator to generate multiple solutions using different approaches, then use ScEnsemble to select the best solution. This will increase the diversity of solutions and potentially improve accuracy.</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.round_4.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        # Use Programmer to generate and execute Python code\n        code_solution = await self.programmer(problem=problem)\n        \n        # Use Custom to refine and format the answer\n        refined_solution = await self.custom(input=problem + f\"\\nCode output: {code_solution['output']}\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n        \n        # Generate multiple solutions using Custom with different approaches\n        solutions = []\n        for approach in ['algebraic', 'geometric', 'analytical']:\n            solution = await self.custom(input=problem, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT.format(approach=approach))\n            solutions.append(solution['response'])\n        \n        # Add the refined solution to the list of solutions\n        solutions.append(refined_solution['response'])\n        \n        # Use ScEnsemble to select the most consistent solution\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>REFINE_ANSWER_PROMPT = \"\"\"\nGiven the mathematical problem and the output from the code execution, please provide a well-formatted and detailed solution. Follow these guidelines:\n\n1. Begin with a clear statement of the problem.\n2. Explain the approach and any formulas or concepts used.\n3. Show step-by-step calculations, using LaTeX notation for mathematical expressions.\n4. Interpret the code output and incorporate it into your explanation.\n5. Provide a final answer, enclosed in \\boxed{} LaTeX notation.\n6. Ensure all mathematical notation is in LaTeX format.\n\nYour response should be comprehensive, mathematically rigorous, and easy to follow.\n\"\"\"\n\nGENERATE_SOLUTION_PROMPT = \"\"\"\nPlease solve the given mathematical problem using a {approach} approach. Follow these guidelines:\n\n1. State the problem clearly.\n2. Outline the {approach} approach and any relevant formulas or concepts.\n3. Provide detailed calculations, using LaTeX notation for mathematical expressions.\n4. Explain each step of your reasoning.\n5. Present the final answer enclosed in \\boxed{} LaTeX notation.\n6. Ensure all mathematical notation is in LaTeX format.\n\nYour solution should be thorough, mathematically sound, and easy to understand.\n\"\"\"</prompt>", "tag": "MATH", "domain": "llm_judge", "parent_round": 3, "child_round": 4, "parent_score": 0.5462184873949579, "child_score": 0.0, "performance_gain": -0.5462184873949579}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>\\nPrevious failed modifications:\\n  - Add a step to generate multiple solutions using different prompts, then use the ScEnsemble operator to select the best solution. This will increase the chances of finding a correct solution by leveraging the ensemble approach. (Score: 0.9333333333333333)\\n  - Add a step to generate multiple solutions using the custom_code_generate operator, then use the ScEnsemble operator to select the best solution. This will increase the chances of finding a correct solution by leveraging the ensemble approach. (Score: 0.9266666666666667)</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.9666666666666667</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_14.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        Custom operator to generate anything you want.\\n        But when you want to get standard code, you should use custom_code_generate operator.\\n        \\\"\\\"\\\"\\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=\\\"Generate a Python function to solve the given problem.\\\")\\n        \\n        # Review and improve the generated solution\\n        reviewed_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nGenerated solution: {solution['response']}\\\", instruction=prompt_custom.REVIEW_SOLUTION_PROMPT)\\n        \\n        # Test the reviewed solution\\n        test_result = await self.test(problem=problem, solution=reviewed_solution['response'], entry_point=entry_point)\\n        \\n        if test_result['result']:\\n            return test_result['solution'], self.llm.cost_manager.total_cost\\n        else:\\n            # If the test fails, try to improve the solution\\n            improved_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nFailed solution: {reviewed_solution['response']}\\\\nError: {test_result['solution']}\\\", instruction=prompt_custom.IMPROVE_SOLUTION_PROMPT)\\n            return improved_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>REVIEW_SOLUTION_PROMPT = \\\"\\\"\\\"\\nReview the given problem and the generated solution. Analyze the code for correctness, efficiency, and adherence to best practices. Improve the solution if necessary.\\n\\nYour task:\\n1. Understand the problem statement.\\n2. Review the generated solution.\\n3. Check for logical errors, edge cases, and potential improvements.\\n4. Rewrite the solution if improvements are needed, or keep it as is if it's optimal.\\n5. Ensure the final solution is complete, correct, and efficient.\\n\\nProvide only the reviewed and potentially improved Python function as your response, without any additional explanations or comments.\\n\\\"\\\"\\\"\\n\\nIMPROVE_SOLUTION_PROMPT = \\\"\\\"\\\"\\nAnalyze the given problem and the failed solution. Identify the errors and improve the code to solve the problem correctly. Make sure to handle edge cases and follow best practices in Python programming.\\n\\nYour task:\\n1. Understand the problem statement.\\n2. Review the failed solution and the error message.\\n3. Identify the cause of the failure.\\n4. Rewrite the solution, addressing the identified issues.\\n5. Ensure the new solution is complete, correct, and efficient.\\n\\nProvide only the improved Python function as your response, without any additional explanations or comments.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 15</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_15.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\n        \n        # Add a review step\n        review = await self.custom(input=f\"Problem: {problem}\\nGenerated solution: {solution['response']}\", instruction=prompt_custom.REVIEW_PROMPT)\n        \n        # If review suggests improvements, apply them\n        if \"No improvements needed\" not in review['response']:\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\"{prompt_custom.CODE_GENERATE_PROMPT}\\n\\nConsider these improvements: {review['response']}\")\n        \n        test_result = await self.test(problem=problem, solution=solution['response'], entry_point=entry_point)\n        \n        if not test_result['result']:\n            # Comprehensive analysis of the problem and failed solution\n            analysis = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {solution['response']}\\nTest result: {test_result['solution']}\", instruction=prompt_custom.COMPREHENSIVE_ANALYSIS_PROMPT)\n            \n            # Generate improved solution based on the comprehensive analysis\n            improved_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\"{prompt_custom.CODE_GENERATE_PROMPT}\\n\\nConsider this analysis: {analysis['response']}\")\n            \n            # Test the improved solution\n            improved_test_result = await self.test(problem=problem, solution=improved_solution['response'], entry_point=entry_point)\n            \n            if improved_test_result['result']:\n                return improved_solution['response'], self.llm.cost_manager.total_cost\n            else:\n                # If the improved solution still fails, return the original solution\n                return solution['response'], self.llm.cost_manager.total_cost\n        \n        return solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>CODE_GENERATE_PROMPT = \"\"\"\nGenerate a Python function that solves the given problem. Ensure the function signature matches the problem description. Include docstrings and comments to explain the logic. The solution should be efficient and handle edge cases.\n\"\"\"\n\nREVIEW_PROMPT = \"\"\"\nReview the generated solution for the given problem. Check for:\n1. Correctness: Does the solution solve the problem as described?\n2. Efficiency: Is the solution optimized for performance?\n3. Readability: Is the code well-structured and easy to understand?\n4. Edge cases: Are all possible scenarios handled?\n5. Python best practices: Does the code follow PEP 8 and other Python conventions?\n\nIf improvements are needed, provide specific suggestions. If no improvements are needed, state \"No improvements needed\".\n\"\"\"\n\nCOMPREHENSIVE_ANALYSIS_PROMPT = \"\"\"\nPerform a comprehensive analysis of the problem and the failed solution. Consider the following aspects:\n\n1. Problem understanding: Identify any potential misinterpretations of the problem statement.\n2. Logical errors: Pinpoint any flaws in the solution's logic or algorithm.\n3. Edge cases: Determine if all possible input scenarios are properly handled.\n4. Efficiency: Evaluate the time and space complexity of the solution.\n5. Coding style: Assess the readability and adherence to Python best practices.\n6. Test case failures: Analyze why specific test cases are failing.\n7. Alternative approaches: Suggest different algorithms or data structures that might be more suitable.\n\nProvide a detailed breakdown of these aspects and suggest specific improvements for each identified issue.\n\"\"\"</prompt>", "tag": "HumanEval", "domain": "llm_judge", "parent_round": 14, "child_round": 15, "parent_score": 0.9666666666666667, "child_score": 0.9, "performance_gain": -0.06666666666666665}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.9333333333333333</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_17.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        Custom operator to generate anything you want.\\n        But when you want to get standard code, you should use custom_code_generate operator.\\n        \\\"\\\"\\\"\\n        # Generate multiple solutions using different prompts\\n        solution1 = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT1)\\n        solution2 = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT2)\\n        solution3 = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT3)\\n        \\n        # Use ScEnsemble to select the best solution\\n        solutions = [solution1['response'], solution2['response'], solution3['response']]\\n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        # Review and improve the selected solution\\n        reviewed_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nGenerated solution: {best_solution['response']}\\\", instruction=prompt_custom.REVIEW_SOLUTION_PROMPT)\\n        \\n        # Test the reviewed solution\\n        test_result = await self.test(problem=problem, solution=reviewed_solution['response'], entry_point=entry_point)\\n        \\n        if test_result['result']:\\n            return test_result['solution'], self.llm.cost_manager.total_cost\\n        else:\\n            # If the test fails, try to improve the solution\\n            improved_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nFailed solution: {reviewed_solution['response']}\\\\nError: {test_result['solution']}\\\", instruction=prompt_custom.IMPROVE_SOLUTION_PROMPT)\\n            return improved_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>GENERATE_SOLUTION_PROMPT1 = \\\"\\\"\\\"\\nGenerate a Python function to solve the given problem. Focus on correctness and efficiency.\\n\\\"\\\"\\\"\\n\\nGENERATE_SOLUTION_PROMPT2 = \\\"\\\"\\\"\\nCreate a Python function that solves the given problem. Pay special attention to edge cases and input validation.\\n\\\"\\\"\\\"\\n\\nGENERATE_SOLUTION_PROMPT3 = \\\"\\\"\\\"\\nDevelop a Python function to address the given problem. Prioritize readability and maintainability in your code.\\n\\\"\\\"\\\"\\n\\nREVIEW_SOLUTION_PROMPT = \\\"\\\"\\\"\\nReview the given problem and the generated solution. Analyze the code for correctness, efficiency, and adherence to best practices. Improve the solution if necessary.\\n\\nYour task:\\n1. Understand the problem statement.\\n2. Review the generated solution.\\n3. Check for logical errors, edge cases, and potential improvements.\\n4. Rewrite the solution if improvements are needed, or keep it as is if it's optimal.\\n5. Ensure the final solution is complete, correct, and efficient.\\n\\nProvide only the reviewed and potentially improved Python function as your response, without any additional explanations or comments.\\n\\\"\\\"\\\"\\n\\nIMPROVE_SOLUTION_PROMPT = \\\"\\\"\\\"\\nAnalyze the given problem and the failed solution. Identify the errors and improve the code to solve the problem correctly. Make sure to handle edge cases and follow best practices in Python programming.\\n\\nYour task:\\n1. Understand the problem statement.\\n2. Review the failed solution and the error message.\\n3. Identify the cause of the failure.\\n4. Rewrite the solution, addressing the identified issues.\\n5. Ensure the new solution is complete, correct, and efficient.\\n\\nProvide only the improved Python function as your response, without any additional explanations or comments.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 18</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_18.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        \"\"\"\n        Implementation of the graph\n        Custom operator to generate anything you want.\n        But when you want to get standard code, you should use custom_code_generate operator.\n        \"\"\"\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=\"\")\n        \n        # Add a review step\n        review_result = await self.custom(input=f\"Problem: {problem}\\nGenerated Solution: {solution['response']}\", instruction=prompt_custom.REVIEW_PROMPT)\n        \n        if \"Improvements needed\" in review_result['response']:\n            improved_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=review_result['response'])\n            return improved_solution['response'], self.llm.cost_manager.total_cost\n        else:\n            return solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>REVIEW_PROMPT = \"\"\"\nReview the following generated solution for the given problem. If the solution is correct and optimal, respond with 'No improvements needed'. If there are any issues or potential improvements, describe them in detail.\n\nProblem: {problem}\n\nGenerated Solution:\n{solution}\n\nYour review:\n\"\"\"</prompt>", "tag": "HumanEval", "domain": "llm_judge", "parent_round": 17, "child_round": 18, "parent_score": 0.9333333333333333, "child_score": 0.9333333333333333, "performance_gain": 0.0}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.8023255813953488</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_16.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        solutions = []\\n        for _ in range(3):  # Generate 3 solutions\\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        # Add code review step\\n        reviewed_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nSolution: {best_solution['response']}\\\", instruction=prompt_custom.CODE_REVIEW_PROMPT)\\n        \\n        test_result = await self.test(problem=problem, solution=reviewed_solution['response'], entry_point=entry_point)\\n        \\n        if test_result['result']:\\n            return test_result['solution'], self.llm.cost_manager.total_cost\\n        else:\\n            # If the test fails, try to fix the solution\\n            fixed_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nFailed solution: {reviewed_solution['response']}\\\\nError: {test_result['solution']}\\\", instruction=prompt_custom.FIX_CODE_PROMPT)\\n            return fixed_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>CODE_GENERATE_PROMPT = \\\"\\\"\\\"\\nGenerate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity.\\n\\nProblem:\\n{problem}\\n\\nFunction signature:\\n{entry_point}\\n\\nGenerate the complete function below:\\n\\\"\\\"\\\"\\n\\nCODE_REVIEW_PROMPT = \\\"\\\"\\\"\\nReview and improve the given Python code solution. Ensure it follows best practices, is efficient, and correctly solves the problem. Make any necessary improvements while maintaining the original function name and signature.\\n\\nProblem:\\n{input}\\n\\nProvide the improved function below:\\n\\\"\\\"\\\"\\n\\nFIX_CODE_PROMPT = \\\"\\\"\\\"\\nThe provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation.\\n\\nProblem:\\n{input}\\n\\nProvide the corrected function below:\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 17</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_17.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        \"\"\"\n        Implementation of the graph\n        Custom operator to generate anything you want.\n        But when you want to get standard code, you should use custom_code_generate operator.\n        \"\"\"\n        solutions = []\n        for _ in range(3):  # Generate 3 solutions\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\n            solutions.append(solution['response'])\n        \n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        test_result = await self.test(problem=problem, solution=best_solution['response'], entry_point=entry_point)\n        \n        if test_result['result']:\n            return test_result['solution'], self.llm.cost_manager.total_cost\n        else:\n            # If the test fails, try to fix the solution\n            fixed_solution = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {best_solution['response']}\\nError: {test_result['solution']}\", instruction=prompt_custom.FIX_CODE_PROMPT)\n            return fixed_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>CODE_GENERATE_PROMPT = \"\"\"\nGenerate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity.\n\nProblem:\n{problem}\n\nFunction signature:\n{entry_point}\n\nGenerate the complete function below:\n\"\"\"\n\nFIX_CODE_PROMPT = \"\"\"\nThe provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation.\n\nProblem:\n{input}\n\nProvide the corrected function below:\n\"\"\"</prompt>", "tag": "MBPP", "domain": "llm_judge", "parent_round": 16, "child_round": 17, "parent_score": 0.8023255813953488, "child_score": 0.8488372093023255, "performance_gain": 0.046511627906976716}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>Previous successful modifications:\\n  - Add a ScEnsemble operator to improve the reliability of the final answer by generating multiple solutions and selecting the most consistent one. (Score: 0.5277310924369747)\\n\\nPrevious failed modifications:\\n  - Add a ScEnsemble operator to improve the reliability of the final answer by generating multiple solutions and selecting the most consistent one. (Score: 0.4722689075630252)\\n  - Add a ScEnsemble operator to improve the reliability of the final answer by generating multiple solutions and selecting the most consistent one. (Score: 0.5243697478991597)</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.5294117647058824</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.round_2.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        # Use Programmer to generate and execute Python code\\n        code_solution = await self.programmer(problem=problem)\\n        \\n        # Use Custom to refine and format the final answer\\n        solution = await self.custom(input=problem + f\\\"\\\\nCode output: {code_solution['output']}\\\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\\n        \\n        return solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the mathematical problem and the output from the code execution, please provide a well-formatted and detailed solution. Follow these guidelines:\\n\\n1. Begin with a clear statement of the problem.\\n2. Explain the approach and any formulas or concepts used.\\n3. Show step-by-step calculations, using LaTeX notation for mathematical expressions.\\n4. Interpret the code output and incorporate it into your explanation.\\n5. Provide a final answer, enclosed in \\\\boxed{} LaTeX notation.\\n6. Ensure all mathematical notation is in LaTeX format.\\n\\nYour response should be comprehensive, mathematically rigorous, and easy to follow.\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Add a ScEnsemble operator to improve the reliability of the final answer by generating multiple solutions and selecting the most consistent one.</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.round_3.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        # Use Programmer to generate and execute Python code\n        code_solution = await self.programmer(problem=problem)\n        \n        # Use Custom to refine and format the answer\n        refined_solution = await self.custom(input=problem + f\"\\nCode output: {code_solution['output']}\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n        \n        # Generate multiple solutions using Custom\n        solutions = []\n        for _ in range(3):\n            solution = await self.custom(input=problem, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT)\n            solutions.append(solution['response'])\n        \n        # Use ScEnsemble to select the most consistent solution\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>REFINE_ANSWER_PROMPT = \"\"\"\nGiven the mathematical problem and the output from the code execution, please provide a well-formatted and detailed solution. Follow these guidelines:\n\n1. Begin with a clear statement of the problem.\n2. Explain the approach and any formulas or concepts used.\n3. Show step-by-step calculations, using LaTeX notation for mathematical expressions.\n4. Interpret the code output and incorporate it into your explanation.\n5. Provide a final answer, enclosed in \\boxed{} LaTeX notation.\n6. Ensure all mathematical notation is in LaTeX format.\n\nYour response should be comprehensive, mathematically rigorous, and easy to follow.\n\"\"\"\n\nGENERATE_SOLUTION_PROMPT = \"\"\"\nPlease solve the given mathematical problem step by step. Follow these guidelines:\n\n1. State the problem clearly.\n2. Outline the approach and any relevant formulas or concepts.\n3. Provide detailed calculations, using LaTeX notation for mathematical expressions.\n4. Explain each step of your reasoning.\n5. Present the final answer enclosed in \\boxed{} LaTeX notation.\n6. Ensure all mathematical notation is in LaTeX format.\n\nYour solution should be thorough, mathematically sound, and easy to understand.\n\"\"\"</prompt>", "tag": "MATH", "domain": "llm_judge", "parent_round": 2, "child_round": 3, "parent_score": 0.5294117647058824, "child_score": 0.5546218487394958, "performance_gain": 0.025210084033613467}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve QA problems.\\nReferring to the given graph and prompt, which forms a basic example of a QA solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.2408126585789074</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_11.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.answer_generate = operator.AnswerGenerate(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):  # Generate 3 solutions\\n            step_by_step = await self.answer_generate(input=problem)\\n            solutions.append(step_by_step['answer'])\\n        \\n        ensemble_solution = await self.sc_ensemble(solutions=solutions)\\n        \\n        refined_solution = await self.custom(input=f\\\"Question: {problem}\\\\nBest solution: {ensemble_solution['response']}\\\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\\n        \\n        final_solution = await self.custom(input=f\\\"Question: {problem}\\\\nRefined answer: {refined_solution['response']}\\\", instruction=prompt_custom.CHECK_NUMERICAL_ANSWER_PROMPT)\\n\\n        return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\\n\\n1. Ensure the answer is concise and directly addresses the question.\\n2. If the answer is a number, provide only the number without additional text.\\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\\n4. Remove any explanations or reasoning from the final answer.\\n\\nYour task is to extract or refine the most accurate answer based on the provided information.\\n\\\"\\\"\\\"\\n\\nCHECK_NUMERICAL_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question and the refined answer, please perform a numerical check and correction if necessary. Follow these steps:\\n\\n1. Identify if the answer is numerical.\\n2. If it is numerical, carefully review the question and the given answer to ensure its accuracy.\\n3. If you find any discrepancies or errors in the numerical answer, provide the correct numerical answer.\\n4. If the answer is correct or not numerical, return the original answer without changes.\\n5. Ensure the final answer follows the format guidelines: numbers only, no additional text, and use vertical bars (|) for multiple possible answers.\\n\\nYour task is to verify and correct numerical answers while maintaining the correct answer format.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 12</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_12.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.answer_generate = operator.AnswerGenerate(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):  # Generate 3 solutions\n            step_by_step = await self.answer_generate(input=problem)\n            solutions.append(step_by_step['answer'])\n        \n        ensemble_solution = await self.sc_ensemble(solutions=solutions)\n        \n        refined_solution = await self.custom(input=f\"Question: {problem}\\nBest solution: {ensemble_solution['response']}\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n        \n        final_solution = await self.custom(input=f\"Answer: {refined_solution['response']}\", instruction=prompt_custom.FORMAT_NUMERIC_ANSWER_PROMPT)\n\n        return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>REFINE_ANSWER_PROMPT = \"\"\"\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\n\n1. Ensure the answer is concise and directly addresses the question.\n2. If the answer is a number, provide only the number without additional text.\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\n4. Remove any explanations or reasoning from the final answer.\n\nYour task is to extract or refine the most accurate answer based on the provided information.\n\"\"\"\n\nFORMAT_NUMERIC_ANSWER_PROMPT = \"\"\"\nGiven an answer, please format it according to these rules:\n\n1. If the answer contains a single number:\n   - Remove any additional text or symbols (like %, $, etc.)\n   - Present the number without commas\n   - If it's a whole number, remove any decimal places\n   - If it's a decimal, keep up to two decimal places\n\n2. If the answer contains multiple numbers separated by '|':\n   - Apply the above rules to each number\n   - Keep the '|' separator between numbers\n\n3. If the answer doesn't contain any numbers, return it as is.\n\nExamples:\n\"74.60%\" should become \"74.60\"\n\"3 | 20 | 32\" should remain \"3 | 20 | 32\"\n\"$1,234,567.89\" should become \"1234567.89\"\n\"42 years old\" should become \"42\"\n\nYour task is to format the given answer according to these rules.\n\"\"\"</prompt>", "tag": "DROP", "domain": "llm_judge", "parent_round": 11, "child_round": 12, "parent_score": 0.2408126585789074, "child_score": 0.7544117647058823, "performance_gain": 0.5135991061269749}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.0</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.round_4.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        # Use Programmer to generate and execute Python code\\n        code_solution = await self.programmer(problem=problem)\\n        \\n        # Use Custom to refine and format the answer\\n        refined_solution = await self.custom(input=problem + f\\\"\\\\nCode output: {code_solution['output']}\\\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\\n        \\n        # Generate multiple solutions using Custom with different approaches\\n        solutions = []\\n        for approach in ['algebraic', 'geometric', 'analytical']:\\n            solution = await self.custom(input=problem, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT.format(approach=approach))\\n            solutions.append(solution['response'])\\n        \\n        # Add the refined solution to the list of solutions\\n        solutions.append(refined_solution['response'])\\n        \\n        # Use ScEnsemble to select the most consistent solution\\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the mathematical problem and the output from the code execution, please provide a well-formatted and detailed solution. Follow these guidelines:\\n\\n1. Begin with a clear statement of the problem.\\n2. Explain the approach and any formulas or concepts used.\\n3. Show step-by-step calculations, using LaTeX notation for mathematical expressions.\\n4. Interpret the code output and incorporate it into your explanation.\\n5. Provide a final answer, enclosed in \\\\boxed{} LaTeX notation.\\n6. Ensure all mathematical notation is in LaTeX format.\\n\\nYour response should be comprehensive, mathematically rigorous, and easy to follow.\\n\\\"\\\"\\\"\\n\\nGENERATE_SOLUTION_PROMPT = \\\"\\\"\\\"\\nPlease solve the given mathematical problem using a {approach} approach. Follow these guidelines:\\n\\n1. State the problem clearly.\\n2. Outline the {approach} approach and any relevant formulas or concepts.\\n3. Provide detailed calculations, using LaTeX notation for mathematical expressions.\\n4. Explain each step of your reasoning.\\n5. Present the final answer enclosed in \\\\boxed{} LaTeX notation.\\n6. Ensure all mathematical notation is in LaTeX format.\\n\\nYour solution should be thorough, mathematically sound, and easy to understand.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 5</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.round_5.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        # Use Programmer to generate and execute Python code\n        code_solution = await self.programmer(problem=problem)\n        \n        # Use Custom to refine and format the answer\n        refined_solution = await self.custom(input=problem + f\"\\nCode output: {code_solution['output']}\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n        \n        # Generate a detailed step-by-step solution using Custom\n        detailed_solution = await self.custom(input=problem, instruction=prompt_custom.DETAILED_SOLUTION_PROMPT)\n        \n        # Generate multiple solutions using Custom\n        solutions = [\n            refined_solution['response'],\n            detailed_solution['response']\n        ]\n        for _ in range(2):\n            solution = await self.custom(input=problem, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT)\n            solutions.append(solution['response'])\n        \n        # Use ScEnsemble to select the best solution\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>REFINE_ANSWER_PROMPT = \"\"\"\nGiven the mathematical problem and the output from the code execution, please provide a well-formatted and detailed solution. Follow these guidelines:\n\n1. Begin with a clear statement of the problem.\n2. Explain the approach and any formulas or concepts used.\n3. Show step-by-step calculations, using LaTeX notation for mathematical expressions.\n4. Interpret the code output and incorporate it into your explanation.\n5. Provide a final answer, enclosed in \\boxed{} LaTeX notation.\n6. Ensure all mathematical notation is in LaTeX format.\n\nYour response should be comprehensive, mathematically rigorous, and easy to follow.\n\"\"\"\n\nGENERATE_SOLUTION_PROMPT = \"\"\"\nPlease solve the given mathematical problem step by step. Follow these guidelines:\n\n1. State the problem clearly.\n2. Outline the approach and any relevant formulas or concepts.\n3. Provide detailed calculations, using LaTeX notation for mathematical expressions.\n4. Explain each step of your reasoning.\n5. Present the final answer enclosed in \\boxed{} LaTeX notation.\n6. Ensure all mathematical notation is in LaTeX format.\n\nYour solution should be thorough, mathematically sound, and easy to understand.\n\"\"\"\n\nDETAILED_SOLUTION_PROMPT = \"\"\"\nProvide a comprehensive, step-by-step solution to the given mathematical problem. Your response should include:\n\n1. A clear restatement of the problem.\n2. An explanation of the mathematical concepts and theorems involved.\n3. A detailed, logical progression of steps leading to the solution.\n4. Clear explanations for each step, including the reasoning behind it.\n5. All mathematical expressions and equations in LaTeX format.\n6. Visual aids or diagrams if applicable (described in text).\n7. A final answer clearly marked and enclosed in \\boxed{} LaTeX notation.\n8. A brief explanation of the significance of the result, if relevant.\n\nEnsure your solution is rigorous, easy to follow, and educational for someone learning the concept.\n\"\"\"</prompt>", "tag": "MATH", "domain": "llm_judge", "parent_round": 4, "child_round": 5, "parent_score": 0.0, "child_score": 0.5714285714285714, "performance_gain": 0.5714285714285714}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve QA problems.\\nReferring to the given graph and prompt, which forms a basic example of a QA solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.7161764705882352</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_8.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.answer_generate = operator.AnswerGenerate(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):  # Generate 3 solutions\\n            step_by_step = await self.answer_generate(input=problem)\\n            solutions.append(step_by_step['answer'])\\n        \\n        ensemble_solution = await self.sc_ensemble(solutions=solutions)\\n        \\n        refined_solution = await self.custom(input=f\\\"Question: {problem}\\\\nBest solution: {ensemble_solution['response']}\\\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\\n        \\n        final_solution = await self.custom(input=f\\\"Question: {problem}\\\\nRefined answer: {refined_solution['response']}\\\", instruction=prompt_custom.MATH_CORRECTION_PROMPT)\\n\\n        return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\\n\\n1. Ensure the answer is concise and directly addresses the question.\\n2. If the answer is a number, provide only the number without additional text.\\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\\n4. Remove any explanations or reasoning from the final answer.\\n\\nYour task is to extract or refine the most accurate answer based on the provided information.\\n\\n\\\"\\\"\\\"\\n\\nMATH_CORRECTION_PROMPT = \\\"\\\"\\\"\\nGiven the question and the refined answer, perform the following tasks:\\n\\n1. Identify if the answer involves a mathematical calculation or a numerical value.\\n2. If it does, verify the calculation or the numerical value for accuracy.\\n3. If you find any discrepancies or errors, correct them and provide the accurate result.\\n4. If the answer is already correct or doesn't involve calculations, return the original answer.\\n5. Ensure the final answer follows the format guidelines:\\n   - Provide only the number without additional text for numerical answers.\\n   - Use a vertical bar (|) to separate multiple correct answers.\\n   - Do not include any explanations or reasoning in the final answer.\\n\\nYour task is to ensure mathematical accuracy while maintaining the concise answer format.\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 9</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_9.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.answer_generate = operator.AnswerGenerate(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        step_by_step = await self.answer_generate(input=problem)\n        refined_solution = await self.custom(input=f\"Question: {problem}\\nStep-by-step solution: {step_by_step['thought']}\\nInitial answer: {step_by_step['answer']}\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n        verified_solution = await self.custom(input=f\"Question: {problem}\\nRefined answer: {refined_solution['response']}\", instruction=prompt_custom.VERIFY_ANSWER_PROMPT)\n        return verified_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>REFINE_ANSWER_PROMPT = \"\"\"\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\n\n1. Ensure the answer is concise and directly addresses the question.\n2. If the answer is a number, provide only the number without additional text.\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\n4. Remove any explanations or reasoning from the final answer.\n\nYour task is to extract or refine the most accurate answer based on the provided information.\n\"\"\"\n\nVERIFY_ANSWER_PROMPT = \"\"\"\nGiven the original question and the refined answer, please verify and correct the answer if necessary. Follow these guidelines:\n\n1. Check if the answer directly addresses the question.\n2. Ensure the answer format is correct (number only for numerical answers, multiple answers separated by |).\n3. Verify that the answer is consistent with the information provided in the question.\n4. If the answer is incorrect or needs adjustment, provide the corrected answer following the same formatting rules.\n\nYour task is to ensure the final answer is accurate, concise, and properly formatted.\n\"\"\"</prompt>", "tag": "DROP", "domain": "llm_judge", "parent_round": 8, "child_round": 9, "parent_score": 0.7161764705882352, "child_score": 0.05235863151800452, "performance_gain": -0.6638178390702307}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve QA problems.\\nReferring to the given graph and prompt, which forms a basic example of a QA solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>\\nPrevious failed modifications:\\n  - Add a new custom operator to check for missing information and attempt to infer or research it based on the context of the question. (Score: 0.609809128779717)\\n  - Modify the FORMAT_ANSWER_PROMPT to ensure more specific and concise answers, particularly for location-based questions. Add a new custom operator to refine location-based answers. (Score: 0.5912117457705692)\\n  - Add a new custom operator to perform a detailed context analysis and cross-reference check, focusing on identifying and correcting potential mismatches between the question and the answer. (Score: 0.6186813186813187)</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.6241488903253609</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.round_15.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.answer_generate = operator.AnswerGenerate(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):\\n            initial_response = await self.answer_generate(input=problem)\\n            thought_process = initial_response['thought']\\n            initial_answer = initial_response['answer']\\n            solutions.append(initial_answer)\\n\\n        ensemble_result = await self.sc_ensemble(solutions=solutions)\\n        best_answer = ensemble_result['response']\\n        \\n        name_extracted_answer = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nBest answer: {best_answer}\\\",\\n            instruction=prompt_custom.NAME_EXTRACTION_PROMPT\\n        )\\n        \\n        disambiguated_answer = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nName-extracted answer: {name_extracted_answer['response']}\\\",\\n            instruction=prompt_custom.ENTITY_DISAMBIGUATION_PROMPT\\n        )\\n        \\n        identity_check_answer = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nDisambiguated answer: {disambiguated_answer['response']}\\\",\\n            instruction=prompt_custom.IDENTITY_CHECK_PROMPT\\n        )\\n        \\n        fact_checked_answer = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nIdentity-checked answer: {identity_check_answer['response']}\\\",\\n            instruction=prompt_custom.FACT_CHECK_PROMPT\\n        )\\n        \\n        style_check_answer = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nFact-checked answer: {fact_checked_answer['response']}\\\",\\n            instruction=prompt_custom.STYLE_CHECK_PROMPT\\n        )\\n        \\n        additional_verification = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nStyle-checked answer: {style_check_answer['response']}\\\",\\n            instruction=prompt_custom.ADDITIONAL_VERIFICATION_PROMPT\\n        )\\n        \\n        refined_solution = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nDouble-verified answer: {additional_verification['response']}\\\",\\n            instruction=prompt_custom.FORMAT_ANSWER_PROMPT\\n        )\\n        \\n        return refined_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>FORMAT_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question and the double-verified answer, format the final answer to be extremely concise and directly addressing the question. Provide only the essential information without any explanation or additional context. For names, professions, or short phrases, give only that specific information.\\n\\nExamples:\\n- For a person's name: \\\"John Doe\\\"\\n- For a profession: \\\"Doctor\\\"\\n- For a short phrase: \\\"Once in a blue moon\\\"\\n\\nDo not include any prefixes or explanatory text. Provide only the answer itself.\\n\\\"\\\"\\\"\\n\\nNAME_EXTRACTION_PROMPT = \\\"\\\"\\\"\\nGiven the question and the best answer, focus on extracting and verifying any names mentioned. Pay special attention to:\\n\\n1. Full names (first name, middle name, last name)\\n2. Nicknames or aliases\\n3. Correct spelling of names\\n\\nIf the answer contains a name, ensure it is accurate and complete. If a name is incorrect or incomplete, provide the correct full name. If no name is present or needed, simply restate the answer.\\n\\nProvide your response in a concise manner, focusing solely on the corrected or verified answer without additional explanations.\\n\\\"\\\"\\\"\\n\\nENTITY_DISAMBIGUATION_PROMPT = \\\"\\\"\\\"\\nGiven the question and the name-extracted answer, perform entity disambiguation to ensure the correct identification of individuals, companies, or other entities mentioned. Consider:\\n\\n1. Different entities with similar names\\n2. Context-specific identities (e.g., a person's role in a specific project)\\n3. Common misconceptions or frequently confused entities\\n\\nIf there's any ambiguity or potential misidentification, clarify the entity's identity based on the context of the question. If no disambiguation is needed, restate the answer.\\n\\nProvide your response in a concise manner, focusing solely on the disambiguated or verified answer without additional explanations.\\n\\\"\\\"\\\"\\n\\nIDENTITY_CHECK_PROMPT = \\\"\\\"\\\"\\nGiven the question and the disambiguated answer, perform a thorough identity check, especially for individuals who may have changed their names, use stage names, or have multiple identities. Consider:\\n\\n1. Birth names vs. stage names or pseudonyms\\n2. Name changes due to personal reasons (e.g., marriage, gender transition)\\n3. Professional names vs. legal names\\n\\nIf the answer involves a person's identity and there's a discrepancy or additional information about their name, provide the most accurate and relevant name based on the context of the question. If no changes are needed, restate the answer.\\n\\nProvide your response in a concise manner, focusing solely on the verified or corrected identity without additional explanations.\\n\\\"\\\"\\\"\\n\\nFACT_CHECK_PROMPT = \\\"\\\"\\\"\\nGiven the question and the identity-checked answer, carefully analyze the information provided and perform a fact-check. If you find any inconsistencies or errors in the answer, provide a corrected version. If the answer appears accurate, simply restate it. Focus on verifying key facts, names, dates, and other critical information related to the question.\\n\\nYour task:\\n1. Analyze the question and the answer.\\n2. Identify any potential errors or inconsistencies.\\n3. If errors are found, provide a corrected answer.\\n4. If no errors are found, restate the answer.\\n\\nProvide your response in a concise manner, focusing solely on the corrected or verified answer without additional explanations.\\n\\\"\\\"\\\"\\n\\nSTYLE_CHECK_PROMPT = \\\"\\\"\\\"\\nReview the fact-checked answer, focusing specifically on architectural and historical style terms. Verify the accuracy of any mentioned styles, ensuring they are correctly identified and placed in the proper historical context. Pay special attention to:\\n\\n1. Architectural styles (e.g., Gothic, Baroque, Neoclassical)\\n2. Historical periods and their associated styles\\n3. Relationships between different styles (e.g., which style influenced or preceded another)\\n\\nIf you find any errors or misidentifications in the architectural or historical style terms, provide a corrected version. If the answer is accurate, simply restate it. Be concise and direct in your response, providing only the verified or corrected answer without explanations.\\n\\\"\\\"\\\"\\n\\nADDITIONAL_VERIFICATION_PROMPT = \\\"\\\"\\\"\\nPerform an additional verification on the previously style-checked answer. Focus on:\\n\\n1. Consistency with the question\\n2. Accuracy of specific details (names, dates, places, styles)\\n3. Completeness of the answer\\n4. Ensure the answer is a single word, number, or short phrase when appropriate\\n\\nIf any issues are found, provide a corrected version. If the answer is accurate and complete, restate it. Be concise and direct in your response, providing only the verified or corrected answer without explanations.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 16</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.round_16.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.answer_generate = operator.AnswerGenerate(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):\n            initial_response = await self.answer_generate(input=problem)\n            thought_process = initial_response['thought']\n            initial_answer = initial_response['answer']\n            solutions.append(initial_answer)\n\n        ensemble_result = await self.sc_ensemble(solutions=solutions)\n        best_answer = ensemble_result['response']\n        \n        name_extracted_answer = await self.custom(\n            input=f\"Question: {problem}\\nBest answer: {best_answer}\",\n            instruction=prompt_custom.NAME_EXTRACTION_PROMPT\n        )\n        \n        identity_check_answer = await self.custom(\n            input=f\"Question: {problem}\\nName-extracted answer: {name_extracted_answer['response']}\",\n            instruction=prompt_custom.IDENTITY_CHECK_PROMPT\n        )\n        \n        profession_check_answer = await self.custom(\n            input=f\"Question: {problem}\\nIdentity-checked answer: {identity_check_answer['response']}\",\n            instruction=prompt_custom.PROFESSION_CHECK_PROMPT\n        )\n        \n        fact_checked_answer = await self.custom(\n            input=f\"Question: {problem}\\nProfession-checked answer: {profession_check_answer['response']}\",\n            instruction=prompt_custom.FACT_CHECK_PROMPT\n        )\n        \n        style_check_answer = await self.custom(\n            input=f\"Question: {problem}\\nFact-checked answer: {fact_checked_answer['response']}\",\n            instruction=prompt_custom.STYLE_CHECK_PROMPT\n        )\n        \n        additional_verification = await self.custom(\n            input=f\"Question: {problem}\\nStyle-checked answer: {style_check_answer['response']}\",\n            instruction=prompt_custom.ADDITIONAL_VERIFICATION_PROMPT\n        )\n        \n        refined_solution = await self.custom(\n            input=f\"Question: {problem}\\nDouble-verified answer: {additional_verification['response']}\",\n            instruction=prompt_custom.FORMAT_ANSWER_PROMPT\n        )\n        \n        return refined_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>FORMAT_ANSWER_PROMPT = \"\"\"\nGiven the question and the double-verified answer, format the final answer to be extremely concise and directly addressing the question. Provide only the essential information without any explanation or additional context. For names, professions, or short phrases, give only that specific information.\n\nExamples:\n- For a person's name: \"John Doe\"\n- For a profession: \"Doctor\"\n- For a short phrase: \"Once in a blue moon\"\n\nDo not include any prefixes or explanatory text. Provide only the answer itself.\n\"\"\"\n\nNAME_EXTRACTION_PROMPT = \"\"\"\nGiven the question and the best answer, focus on extracting and verifying any names mentioned. Pay special attention to:\n\n1. Full names (first name, middle name, last name)\n2. Nicknames or aliases\n3. Correct spelling of names\n\nIf the answer contains a name, ensure it is accurate and complete. If a name is incorrect or incomplete, provide the correct full name. If no name is present or needed, simply restate the answer.\n\nProvide your response in a concise manner, focusing solely on the corrected or verified answer without additional explanations.\n\"\"\"\n\nIDENTITY_CHECK_PROMPT = \"\"\"\nGiven the question and the name-extracted answer, perform a thorough identity check, especially for individuals who may have changed their names, use stage names, or have multiple identities. Consider:\n\n1. Birth names vs. stage names or pseudonyms\n2. Name changes due to personal reasons (e.g., marriage, gender transition)\n3. Professional names vs. legal names\n\nIf the answer involves a person's identity and there's a discrepancy or additional information about their name, provide the most accurate and relevant name based on the context of the question. If no changes are needed, restate the answer.\n\nProvide your response in a concise manner, focusing solely on the verified or corrected identity without additional explanations.\n\"\"\"\n\nPROFESSION_CHECK_PROMPT = \"\"\"\nGiven the question and the identity-checked answer, focus on verifying and specifying any professions mentioned. Pay special attention to:\n\n1. Accurate job titles or occupations\n2. Specific roles within a broader field\n3. Multiple professions if applicable\n\nIf the answer involves a profession, ensure it is accurate and as specific as possible. If a profession is mentioned but is too general, provide a more precise description. If multiple professions are relevant, list them all.\n\nProvide your response in a concise manner, focusing solely on the verified or corrected profession(s) without additional explanations.\n\"\"\"\n\nFACT_CHECK_PROMPT = \"\"\"\nGiven the question and the profession-checked answer, carefully analyze the information provided and perform a fact-check. If you find any inconsistencies or errors in the answer, provide a corrected version. If the answer appears accurate, simply restate it. Focus on verifying key facts, names, dates, and other critical information related to the question.\n\nYour task:\n1. Analyze the question and the answer.\n2. Identify any potential errors or inconsistencies.\n3. If errors are found, provide a corrected answer.\n4. If no errors are found, restate the answer.\n\nProvide your response in a concise manner, focusing solely on the corrected or verified answer without additional explanations.\n\"\"\"\n\nSTYLE_CHECK_PROMPT = \"\"\"\nReview the fact-checked answer, focusing specifically on architectural and historical style terms. Verify the accuracy of any mentioned styles, ensuring they are correctly identified and placed in the proper historical context. Pay special attention to:\n\n1. Architectural styles (e.g., Gothic, Baroque, Neoclassical)\n2. Historical periods and their associated styles\n3. Relationships between different styles (e.g., which style influenced or preceded another)\n\nIf you find any errors or misidentifications in the architectural or historical style terms, provide a corrected version. If the answer is accurate, simply restate it. Be concise and direct in your response, providing only the verified or corrected answer without explanations.\n\"\"\"\n\nADDITIONAL_VERIFICATION_PROMPT = \"\"\"\nPerform an additional verification on the previously style-checked answer. Focus on:\n\n1. Consistency with the question\n2. Accuracy of specific details (names, dates, places, styles)\n3. Completeness of the answer\n4. Ensure the answer is a single word, number, or short phrase when appropriate\n\nIf any issues are found, provide a corrected version. If the answer is accurate and complete, restate it. Be concise and direct in your response, providing only the verified or corrected answer without explanations.\n\"\"\"</prompt>", "tag": "HotpotQA", "domain": "llm_judge", "parent_round": 15, "child_round": 16, "parent_score": 0.6241488903253609, "child_score": 0.6423561732385261, "performance_gain": 0.0182072829131652}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve QA problems.\\nReferring to the given graph and prompt, which forms a basic example of a QA solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>Previous successful modifications:\\n  - Add a ScEnsemble operator to generate multiple answers and select the best one. Modify the Custom operator to focus on answer formatting and conciseness. (Score: 0.6152391725921138)</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.4136257254097812</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.round_2.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.answer_generate = operator.AnswerGenerate(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        initial_response = await self.answer_generate(input=problem)\\n        thought_process = initial_response['thought']\\n        initial_answer = initial_response['answer']\\n        \\n        refined_solution = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nThought process: {thought_process}\\\\nInitial answer: {initial_answer}\\\",\\n            instruction=prompt_custom.REFINE_ANSWER_PROMPT\\n        )\\n        \\n        return refined_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question, thought process, and initial answer, please refine and format the final answer. Ensure that the answer is concise, accurate, and directly addresses the question. If the initial answer seems incorrect based on the thought process, provide a corrected answer.\\n\\nFormat the final answer as a clear, concise statement without any additional explanation or reasoning.\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Add a ScEnsemble operator to generate multiple answers and select the best one. Modify the Custom operator to focus on answer formatting and conciseness.</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.round_3.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.answer_generate = operator.AnswerGenerate(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):\n            initial_response = await self.answer_generate(input=problem)\n            thought_process = initial_response['thought']\n            initial_answer = initial_response['answer']\n            solutions.append(initial_answer)\n\n        ensemble_result = await self.sc_ensemble(solutions=solutions)\n        best_answer = ensemble_result['response']\n        \n        refined_solution = await self.custom(\n            input=f\"Question: {problem}\\nBest answer: {best_answer}\",\n            instruction=prompt_custom.FORMAT_ANSWER_PROMPT\n        )\n        \n        return refined_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>FORMAT_ANSWER_PROMPT = \"\"\"\nGiven the question and the best answer, format the final answer to be concise, accurate, and directly addressing the question. Ensure the answer is a clear, brief statement without additional explanation or reasoning. If the answer is a name, profession, or short phrase, provide only that information without forming a complete sentence.\n\nFor example:\n- If the answer is a person's name, just provide the name.\n- If the answer is a profession, state only the profession.\n- If the answer is a short phrase, give only that phrase.\n\nDo not include any prefixes like \"The answer is\" or \"The profession is\". Just provide the answer itself.\n\"\"\"\n\nasync def __call__(self, problem: str):\n    \"\"\"\n    Implementation of the workflow\n    \"\"\"\n    solutions = []\n    for _ in range(3):\n        initial_response = await self.answer_generate(input=problem)\n        thought_process = initial_response['thought']\n        initial_answer = initial_response['answer']\n        solutions.append(initial_answer)\n\n    ensemble_result = await self.sc_ensemble(solutions=solutions)\n    best_answer = ensemble_result['response']\n\n    refined_solution = await self.custom(\n        input=f\"Question: {problem}\\nBest answer: {best_answer}\",\n        instruction=prompt_custom.FORMAT_ANSWER_PROMPT\n    )\n\n    return refined_solution['response'], self.llm.cost_manager.total_cost</prompt>", "tag": "HotpotQA", "domain": "llm_judge", "parent_round": 2, "child_round": 3, "parent_score": 0.4136257254097812, "child_score": 0.6239980607627666, "performance_gain": 0.21037233535298544}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve QA problems.\\nReferring to the given graph and prompt, which forms a basic example of a QA solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>\\nPrevious failed modifications:\\n  - Add a new Custom operator to perform numerical extraction and validation on the final answer. This will help address issues with incorrect numerical answers and ensure they are properly formatted. (Score: 0.6228758169934641)\\n  - Modify the custom method to include a numerical answer check and correction step. This will help address issues like the incorrect field goal count in the second log. (Score: 0.2562216095371586)\\n  - Modify the custom method to focus on answer formatting and add a new custom method for error checking and correction. (Score: 0.040381896006269284)\\n  - Add a new Custom operator to perform mathematical calculations and corrections on the final answer. This will help address the issue with incorrect numerical answers, such as the 63 vs 64 year difference in the example logs. (Score: 0.7251705029838021)\\n  - Add a new Custom operator to perform numerical extraction and formatting on the final answer. This will help address issues with answer formatting and ensure numerical answers are presented correctly. (Score: 0.7394117647058824)\\n  - Add a review step using the Custom operator to check and potentially refine the final answer before returning it. This can help improve accuracy and ensure the answer format meets the requirements. (Score: 0.7094965297695995)</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.7348039215686274</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_3.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.answer_generate = operator.AnswerGenerate(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):  # Generate 3 solutions\\n            step_by_step = await self.answer_generate(input=problem)\\n            solutions.append(step_by_step['answer'])\\n        \\n        ensemble_solution = await self.sc_ensemble(solutions=solutions)\\n        \\n        final_solution = await self.custom(input=f\\\"Question: {problem}\\\\nBest solution: {ensemble_solution['response']}\\\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\\n\\n        return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\\n\\n1. Ensure the answer is concise and directly addresses the question.\\n2. If the answer is a number, provide only the number without additional text.\\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\\n4. Remove any explanations or reasoning from the final answer.\\n\\nYour task is to extract or refine the most accurate answer based on the provided information.\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 4</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_4.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.answer_generate = operator.AnswerGenerate(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):  # Generate 3 solutions\n            step_by_step = await self.answer_generate(input=problem)\n            solution = await self.custom(input=f\"Question: {problem}\\nStep-by-step solution: {step_by_step['thought']}\\nInitial answer: {step_by_step['answer']}\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n            solutions.append(solution['response'])\n        \n        final_solution = await self.sc_ensemble(solutions=solutions)\n        return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>REFINE_ANSWER_PROMPT = \"\"\"\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\n\n1. Ensure the answer is concise and directly addresses the question.\n2. If the answer is a number, provide only the number without additional text.\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\n4. Remove any explanations or reasoning from the final answer.\n5. Double-check the calculations and logic in the step-by-step solution to ensure accuracy.\n6. If the answer involves counting or summing items, verify that all relevant items are included.\n\nYour task is to extract or refine the most accurate answer based on the provided information. Pay special attention to numerical answers and ensure they are correctly calculated and formatted.\n\n\"\"\"</prompt>", "tag": "DROP", "domain": "llm_judge", "parent_round": 3, "child_round": 4, "parent_score": 0.7348039215686274, "child_score": 0.7495098039215685, "performance_gain": 0.014705882352941124}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.6333333333333333</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_3.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        Custom operator to generate anything you want.\\n        But when you want to get standard code, you should use custom_code_generate operator.\\n        \\\"\\\"\\\"\\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=\\\"\\\")\\n        \\n        # Add a review step using the Custom operator\\n        review_result = await self.custom(input=f\\\"Problem: {problem}\\\\nGenerated Solution: {solution['response']}\\\", instruction=prompt_custom.REVIEW_PROMPT)\\n        \\n        if \\\"Improved Solution:\\\" in review_result['response']:\\n            final_solution = review_result['response'].split(\\\"Improved Solution:\\\")[1].strip()\\n        else:\\n            final_solution = solution['response']\\n        \\n        return final_solution, self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>REVIEW_PROMPT = \\\"\\\"\\\"\\nReview the following problem and the generated solution. If you find any issues or potential improvements, provide an improved solution. If the solution is already optimal, state that no improvements are needed.\\n\\nProblem: {input}\\n\\nYour response should be in the following format:\\nReview: [Your review comments]\\nImproved Solution: [The improved solution if any, or \\\"No improvements needed\\\" if the original solution is optimal]\\n\\nEnsure that your review is thorough and that any improved solution addresses the problem correctly and efficiently.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 4</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_4.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\n        \n        # Add a review step\n        review = await self.custom(input=f\"Problem: {problem}\\nGenerated solution: {solution['response']}\", instruction=prompt_custom.REVIEW_PROMPT)\n        \n        # Improve the solution based on the review\n        improved_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\"{prompt_custom.CODE_GENERATE_PROMPT}\\n\\nConsider this review: {review['response']}\")\n        \n        test_result = await self.test(problem=problem, solution=improved_solution['response'], entry_point=entry_point)\n        \n        if not test_result['result']:\n            analysis = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {improved_solution['response']}\\nTest result: {test_result['solution']}\", instruction=prompt_custom.ANALYZE_AND_IMPROVE_PROMPT)\n            final_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\"{prompt_custom.CODE_GENERATE_PROMPT}\\n\\nConsider this analysis: {analysis['response']}\")\n            return final_solution['response'], self.llm.cost_manager.total_cost\n        \n        return improved_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>CODE_GENERATE_PROMPT = \"\"\"\nGenerate a Python function that solves the given problem. Ensure the function signature matches the problem description. Include docstrings and comments to explain the logic. The solution should be efficient and handle edge cases. Pay special attention to the order of operations and ensure that the function evaluates the expression correctly.\n\"\"\"\n\nREVIEW_PROMPT = \"\"\"\nReview the generated solution and suggest improvements. Consider the following:\n1. Does the function correctly implement the order of operations?\n2. Are all required operators (+, -, *, //, **) handled properly?\n3. Is there proper error handling for cases like division by zero?\n4. Does the function handle the case where the operator list is empty?\n5. Is the code efficient and readable?\nProvide specific suggestions for improvement.\n\"\"\"\n\nANALYZE_AND_IMPROVE_PROMPT = \"\"\"\nAnalyze the failed solution and provide suggestions for improvement. Consider the following:\n1. Identify logical errors or misunderstandings of the problem.\n2. Check for edge cases that might not be handled correctly.\n3. Ensure the order of operations is correctly implemented.\n4. Suggest optimizations or alternative approaches if applicable.\n5. Provide specific code snippets or pseudocode to address the issues found.\n\"\"\"</prompt>", "tag": "HumanEval", "domain": "llm_judge", "parent_round": 3, "child_round": 4, "parent_score": 0.6333333333333333, "child_score": 0.9333333333333333, "performance_gain": 0.30000000000000004}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.5930232558139535</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_4.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\\n        \\n        # New step: Analyze and improve the solution before testing\\n        improved_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nGenerated solution: {solution['response']}\\\", instruction=prompt_custom.ANALYZE_IMPROVE_PROMPT)\\n        \\n        test_result = await self.test(problem=problem, solution=improved_solution['response'], entry_point=entry_point)\\n        \\n        if test_result['result']:\\n            return test_result['solution'], self.llm.cost_manager.total_cost\\n        else:\\n            # If the test fails, try to fix the solution\\n            fixed_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nFailed solution: {improved_solution['response']}\\\\nError: {test_result['solution']}\\\", instruction=prompt_custom.FIX_CODE_PROMPT)\\n            return fixed_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>CODE_GENERATE_PROMPT = \\\"\\\"\\\"\\nGenerate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity.\\n\\nProblem:\\n{problem}\\n\\nFunction signature:\\n{entry_point}\\n\\nGenerate the complete function below:\\n\\\"\\\"\\\"\\n\\nANALYZE_IMPROVE_PROMPT = \\\"\\\"\\\"\\nAnalyze the following Python function and suggest improvements for better performance, readability, and correctness. Consider edge cases, potential errors, and optimization opportunities. Provide an improved version of the function.\\n\\nProblem:\\n{input}\\n\\nProvide the improved function below:\\n\\\"\\\"\\\"\\n\\nFIX_CODE_PROMPT = \\\"\\\"\\\"\\nThe provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation.\\n\\nProblem:\\n{input}\\n\\nProvide the corrected function below:\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 5</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_5.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        solutions = []\n        for _ in range(3):  # Generate 3 solutions\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\n            solutions.append(solution['response'])\n        \n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        test_result = await self.test(problem=problem, solution=best_solution['response'], entry_point=entry_point)\n        \n        if test_result['result']:\n            return test_result['solution'], self.llm.cost_manager.total_cost\n        else:\n            fixed_solution = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {best_solution['response']}\\nError: {test_result['solution']}\", instruction=prompt_custom.FIX_CODE_PROMPT)\n            return fixed_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>CODE_GENERATE_PROMPT = \"\"\"\nGenerate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity.\n\nProblem:\n{problem}\n\nFunction signature:\n{entry_point}\n\nGenerate the complete function below:\n\"\"\"\n\nFIX_CODE_PROMPT = \"\"\"\nThe provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation.\n\nProblem:\n{input}\n\nProvide the corrected function below:\n\"\"\"</prompt>", "tag": "MBPP", "domain": "llm_judge", "parent_round": 4, "child_round": 5, "parent_score": 0.5930232558139535, "child_score": 0.8372093023255814, "performance_gain": 0.2441860465116279}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>Previous successful modifications:\\n  - Add a more comprehensive analysis step using the Custom operator before generating the improved solution. This will provide a more detailed breakdown of the problem and failed solution, leading to better improvements. (Score: 0.9266666666666667)\\n\\nPrevious failed modifications:\\n  - Add a self-review step using the Custom operator to analyze and improve the generated solution before testing it. This can help catch potential errors and optimize the code before running the test cases. (Score: 0.8666666666666666)\\n  - Add a review step using the Custom operator to analyze and improve the generated solution before testing it. This can help catch potential errors and optimize the code before running the test cases. (Score: 0.8533333333333333)</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.9</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_2.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        Custom operator to generate anything you want.\\n        But when you want to get standard code, you should use custom_code_generate operator.\\n        \\\"\\\"\\\"\\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\\n        test_result = await self.test(problem=problem, solution=solution['response'], entry_point=entry_point)\\n        \\n        if not test_result['result']:\\n            # If the test fails, use Custom to analyze and improve the solution\\n            analysis = await self.custom(input=f\\\"Problem: {problem}\\\\nFailed solution: {solution['response']}\\\\nTest result: {test_result['solution']}\\\", instruction=prompt_custom.ANALYZE_AND_IMPROVE_PROMPT)\\n            improved_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\\\"{prompt_custom.CODE_GENERATE_PROMPT}\\\\n\\\\nConsider this analysis: {analysis['response']}\\\")\\n            return improved_solution['response'], self.llm.cost_manager.total_cost\\n        \\n        return solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>CODE_GENERATE_PROMPT = \\\"\\\"\\\"\\nGenerate a Python function that solves the given problem. Ensure the function signature matches the problem description. Include docstrings and comments to explain the logic. The solution should be efficient and handle edge cases.\\n\\\"\\\"\\\"\\n\\nANALYZE_AND_IMPROVE_PROMPT = \\\"\\\"\\\"\\nAnalyze the failed solution and provide suggestions for improvement. Consider the following:\\n1. Identify logical errors or misunderstandings of the problem.\\n2. Check for edge cases that might not be handled correctly.\\n3. Suggest optimizations or alternative approaches if applicable.\\n4. Provide specific code snippets or pseudocode to address the issues found.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 3</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_3.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        \"\"\"\n        Implementation of the graph\n        Custom operator to generate anything you want.\n        But when you want to get standard code, you should use custom_code_generate operator.\n        \"\"\"\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=\"\")\n        \n        # Add a review step using the Custom operator\n        review_result = await self.custom(input=f\"Problem: {problem}\\nGenerated Solution: {solution['response']}\", instruction=prompt_custom.REVIEW_PROMPT)\n        \n        if \"Improved Solution:\" in review_result['response']:\n            final_solution = review_result['response'].split(\"Improved Solution:\")[1].strip()\n        else:\n            final_solution = solution['response']\n        \n        return final_solution, self.llm.cost_manager.total_cost\n</graph>\n<prompt>REVIEW_PROMPT = \"\"\"\nReview the following problem and the generated solution. If you find any issues or potential improvements, provide an improved solution. If the solution is already optimal, state that no improvements are needed.\n\nProblem: {input}\n\nYour response should be in the following format:\nReview: [Your review comments]\nImproved Solution: [The improved solution if any, or \"No improvements needed\" if the original solution is optimal]\n\nEnsure that your review is thorough and that any improved solution addresses the problem correctly and efficiently.\n\"\"\"</prompt>", "tag": "HumanEval", "domain": "llm_judge", "parent_round": 2, "child_round": 3, "parent_score": 0.9, "child_score": 0.7333333333333333, "performance_gain": -0.16666666666666674}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.86</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_14.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):\\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        # Add a verification step using the Programmer operator\\n        verification_result = await self.programmer(problem=problem, analysis=final_solution['response'])\\n        \\n        if verification_result['output']:\\n            return verification_result['output'], self.llm.cost_manager.total_cost\\n        else:\\n            return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>MATH_SOLVE_PROMPT = \\\"\\\"\\\"\\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps:\\n\\n1. Carefully read and understand the problem.\\n2. Identify the key information and variables.\\n3. Determine the appropriate mathematical concepts or formulas to use.\\n4. Solve the problem step by step, showing all your work.\\n5. Double-check your calculations and reasoning.\\n6. Perform any necessary unit conversions to ensure the final answer is in the correct units.\\n7. Provide a clear and concise final answer.\\n\\nRemember to format your answer as follows:\\n- Use LaTeX notation for mathematical expressions where appropriate.\\n- Clearly state your final answer at the end of your solution.\\n- Express numerical answers as precise values (avoid rounding unless specified).\\n- Ensure that your final answer is a single numerical value without any units or additional text.\\n- Do not include any explanatory text with your final answer, just the number itself.\\n\\nFor example, if the final answer is 42.5 hours, your response should end with just:\\n42.5\\n\\nHere's the problem to solve:\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 15</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_15.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(5):  # Generate 5 solutions\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\n            solutions.append(solution['response'])\n        \n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Add a verification step using the Programmer operator\n        verification = await self.programmer(problem=problem, analysis=final_solution['response'])\n        \n        # Double-check the final answer\n        double_check = await self.custom(input=problem + f\"\\nInitial solution: {final_solution['response']}\\nVerification result: {verification['output']}\", instruction=prompt_custom.DOUBLE_CHECK_PROMPT)\n        \n        return double_check['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>MATH_SOLVE_PROMPT = \"\"\"\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps carefully:\n\n1. Read and understand the problem thoroughly, ensuring you consider ALL given information.\n2. Identify all key information, variables, and relationships, including any discounts or special conditions.\n3. Determine the appropriate mathematical concepts, formulas, or equations to use.\n4. Solve the problem step-by-step, showing all your work clearly.\n5. Double-check your calculations and reasoning at each step.\n6. Provide a clear and concise final answer.\n7. Verify your solution by plugging it back into the original problem or using an alternative method if possible.\n8. Explicitly calculate the total cost, including any discounts or special conditions mentioned in the problem.\n\nFormat your answer as follows:\n- Use LaTeX notation for mathematical expressions where appropriate.\n- Show each step of your solution process clearly.\n- Clearly state your final answer at the end of your solution.\n- Express numerical answers as precise values (avoid rounding unless specified).\n- Ensure that your final answer is a single numerical value without any units or additional text.\n- Do not include any explanatory text with your final answer, just the number itself.\n\nFor example, if the final answer is 42.5, your response should end with just:\n42.5\n\nHere's the problem to solve:\n\n\"\"\"\n\nDOUBLE_CHECK_PROMPT = \"\"\"\nYou are a meticulous math checker. Your task is to review the given problem, the initial solution, and the verification result. Then, determine the most accurate final answer.\n\nFollow these steps:\n1. Carefully read the original problem, paying attention to all details and conditions.\n2. Review the initial solution and the verification result.\n3. If there are discrepancies, analyze both approaches to identify any errors or overlooked information.\n4. Recalculate the problem yourself, ensuring all conditions and discounts are properly applied.\n5. Provide the final, correct answer as a single numerical value without any units or additional text.\n\nRemember:\n- Consider ALL information given in the problem, including any discounts or special conditions.\n- Ensure that your calculations account for the entire problem, not just part of it.\n- Double-check your math to avoid simple calculation errors.\n- Your final answer should be a single number without any explanations.\n\nFor example, if the correct final answer is 123.0, your response should be just:\n123.0\n\nHere's the problem and previous results to review:\n\n\"\"\"</prompt>", "tag": "GSM8K", "domain": "llm_judge", "parent_round": 14, "child_round": 15, "parent_score": 0.86, "child_score": 0.89, "performance_gain": 0.030000000000000027}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>\\nPrevious failed modifications:\\n  - Add a step to generate multiple solutions using different prompts, then use the ScEnsemble operator to select the best solution. This will increase the chances of finding a correct solution by leveraging the ensemble approach. (Score: 0.9333333333333333)\\n  - Add a step to generate multiple solutions using the custom_code_generate operator, then use the ScEnsemble operator to select the best solution. This will increase the chances of finding a correct solution by leveraging the ensemble approach. (Score: 0.9266666666666667)</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.9666666666666667</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_14.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        Custom operator to generate anything you want.\\n        But when you want to get standard code, you should use custom_code_generate operator.\\n        \\\"\\\"\\\"\\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=\\\"Generate a Python function to solve the given problem.\\\")\\n        \\n        # Review and improve the generated solution\\n        reviewed_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nGenerated solution: {solution['response']}\\\", instruction=prompt_custom.REVIEW_SOLUTION_PROMPT)\\n        \\n        # Test the reviewed solution\\n        test_result = await self.test(problem=problem, solution=reviewed_solution['response'], entry_point=entry_point)\\n        \\n        if test_result['result']:\\n            return test_result['solution'], self.llm.cost_manager.total_cost\\n        else:\\n            # If the test fails, try to improve the solution\\n            improved_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nFailed solution: {reviewed_solution['response']}\\\\nError: {test_result['solution']}\\\", instruction=prompt_custom.IMPROVE_SOLUTION_PROMPT)\\n            return improved_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>REVIEW_SOLUTION_PROMPT = \\\"\\\"\\\"\\nReview the given problem and the generated solution. Analyze the code for correctness, efficiency, and adherence to best practices. Improve the solution if necessary.\\n\\nYour task:\\n1. Understand the problem statement.\\n2. Review the generated solution.\\n3. Check for logical errors, edge cases, and potential improvements.\\n4. Rewrite the solution if improvements are needed, or keep it as is if it's optimal.\\n5. Ensure the final solution is complete, correct, and efficient.\\n\\nProvide only the reviewed and potentially improved Python function as your response, without any additional explanations or comments.\\n\\\"\\\"\\\"\\n\\nIMPROVE_SOLUTION_PROMPT = \\\"\\\"\\\"\\nAnalyze the given problem and the failed solution. Identify the errors and improve the code to solve the problem correctly. Make sure to handle edge cases and follow best practices in Python programming.\\n\\nYour task:\\n1. Understand the problem statement.\\n2. Review the failed solution and the error message.\\n3. Identify the cause of the failure.\\n4. Rewrite the solution, addressing the identified issues.\\n5. Ensure the new solution is complete, correct, and efficient.\\n\\nProvide only the improved Python function as your response, without any additional explanations or comments.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 15</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_15.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\n        \n        # Add a review step\n        review = await self.custom(input=f\"Problem: {problem}\\nGenerated solution: {solution['response']}\", instruction=prompt_custom.REVIEW_PROMPT)\n        \n        # If review suggests improvements, apply them\n        if \"No improvements needed\" not in review['response']:\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\"{prompt_custom.CODE_GENERATE_PROMPT}\\n\\nConsider these improvements: {review['response']}\")\n        \n        test_result = await self.test(problem=problem, solution=solution['response'], entry_point=entry_point)\n        \n        if not test_result['result']:\n            # Comprehensive analysis of the problem and failed solution\n            analysis = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {solution['response']}\\nTest result: {test_result['solution']}\", instruction=prompt_custom.COMPREHENSIVE_ANALYSIS_PROMPT)\n            \n            # Generate improved solution based on the comprehensive analysis\n            improved_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\"{prompt_custom.CODE_GENERATE_PROMPT}\\n\\nConsider this analysis: {analysis['response']}\")\n            \n            # Test the improved solution\n            improved_test_result = await self.test(problem=problem, solution=improved_solution['response'], entry_point=entry_point)\n            \n            if improved_test_result['result']:\n                return improved_solution['response'], self.llm.cost_manager.total_cost\n            else:\n                # If the improved solution still fails, return the original solution\n                return solution['response'], self.llm.cost_manager.total_cost\n        \n        return solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>CODE_GENERATE_PROMPT = \"\"\"\nGenerate a Python function that solves the given problem. Ensure the function signature matches the problem description. Include docstrings and comments to explain the logic. The solution should be efficient and handle edge cases.\n\"\"\"\n\nREVIEW_PROMPT = \"\"\"\nReview the generated solution for the given problem. Check for:\n1. Correctness: Does the solution solve the problem as described?\n2. Efficiency: Is the solution optimized for performance?\n3. Readability: Is the code well-structured and easy to understand?\n4. Edge cases: Are all possible scenarios handled?\n5. Python best practices: Does the code follow PEP 8 and other Python conventions?\n\nIf improvements are needed, provide specific suggestions. If no improvements are needed, state \"No improvements needed\".\n\"\"\"\n\nCOMPREHENSIVE_ANALYSIS_PROMPT = \"\"\"\nPerform a comprehensive analysis of the problem and the failed solution. Consider the following aspects:\n\n1. Problem understanding: Identify any potential misinterpretations of the problem statement.\n2. Logical errors: Pinpoint any flaws in the solution's logic or algorithm.\n3. Edge cases: Determine if all possible input scenarios are properly handled.\n4. Efficiency: Evaluate the time and space complexity of the solution.\n5. Coding style: Assess the readability and adherence to Python best practices.\n6. Test case failures: Analyze why specific test cases are failing.\n7. Alternative approaches: Suggest different algorithms or data structures that might be more suitable.\n\nProvide a detailed breakdown of these aspects and suggest specific improvements for each identified issue.\n\"\"\"</prompt>", "tag": "HumanEval", "domain": "llm_judge", "parent_round": 14, "child_round": 15, "parent_score": 0.9666666666666667, "child_score": 0.9, "performance_gain": -0.06666666666666665}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve QA problems.\\nReferring to the given graph and prompt, which forms a basic example of a QA solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>\\nPrevious failed modifications:\\n  - Modify the custom operator to include a verification step that checks if the answer is a name, profession, or short phrase, and adjust the formatting accordingly. (Score: 0.6009556130144366)\\n  - Modify the custom operator to include a step for answer refinement and conciseness, focusing on extracting the most relevant information from the ensemble result. (Score: 0.6102520028990617)\\n  - Add a fact-checking step using the Custom operator to verify and potentially correct the initial answer before formatting. (Score: 0.5935227485643086)\\n  - Modify the custom operator to include a fact-checking and correction step before formatting the final answer. (Score: 0.6106678125795773)</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.6135746606334841</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.round_3.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.answer_generate = operator.AnswerGenerate(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):\\n            initial_response = await self.answer_generate(input=problem)\\n            thought_process = initial_response['thought']\\n            initial_answer = initial_response['answer']\\n            solutions.append(initial_answer)\\n\\n        ensemble_result = await self.sc_ensemble(solutions=solutions)\\n        best_answer = ensemble_result['response']\\n        \\n        refined_solution = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nBest answer: {best_answer}\\\",\\n            instruction=prompt_custom.FORMAT_ANSWER_PROMPT\\n        )\\n        \\n        return refined_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>FORMAT_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question and the best answer, format the final answer to be concise, accurate, and directly addressing the question. Ensure the answer is a clear, brief statement without additional explanation or reasoning. If the answer is a name, profession, or short phrase, provide only that information without forming a complete sentence.\\n\\nFor example:\\n- If the answer is a person's name, just provide the name.\\n- If the answer is a profession, state only the profession.\\n- If the answer is a short phrase, give only that phrase.\\n\\nDo not include any prefixes like \\\"The answer is\\\" or \\\"The profession is\\\". Just provide the answer itself.\\n\\\"\\\"\\\"\\n\\nasync def __call__(self, problem: str):\\n    \\\"\\\"\\\"\\n    Implementation of the workflow\\n    \\\"\\\"\\\"\\n    solutions = []\\n    for _ in range(3):\\n        initial_response = await self.answer_generate(input=problem)\\n        thought_process = initial_response['thought']\\n        initial_answer = initial_response['answer']\\n        solutions.append(initial_answer)\\n\\n    ensemble_result = await self.sc_ensemble(solutions=solutions)\\n    best_answer = ensemble_result['response']\\n\\n    refined_solution = await self.custom(\\n        input=f\\\"Question: {problem}\\\\nBest answer: {best_answer}\\\",\\n        instruction=prompt_custom.FORMAT_ANSWER_PROMPT\\n    )\\n\\n    return refined_solution['response'], self.llm.cost_manager.total_cost</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Add a fact-checking step using the Custom operator to verify and potentially correct the initial answer before formatting.</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.round_4.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.answer_generate = operator.AnswerGenerate(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):\n            initial_response = await self.answer_generate(input=problem)\n            thought_process = initial_response['thought']\n            initial_answer = initial_response['answer']\n            solutions.append(initial_answer)\n\n        ensemble_result = await self.sc_ensemble(solutions=solutions)\n        best_answer = ensemble_result['response']\n        \n        fact_checked = await self.custom(\n            input=f\"Question: {problem}\\nInitial answer: {best_answer}\",\n            instruction=prompt_custom.FACT_CHECK_PROMPT\n        )\n        \n        refined_solution = await self.custom(\n            input=f\"Question: {problem}\\nVerified answer: {fact_checked['response']}\",\n            instruction=prompt_custom.FORMAT_ANSWER_PROMPT\n        )\n        \n        return refined_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>FACT_CHECK_PROMPT = \"\"\"\nGiven the question and the initial answer, please verify the accuracy of the answer. If you find any inaccuracies or have additional relevant information, provide a corrected or more accurate answer. If the initial answer is correct and complete, simply restate it.\n\nFocus on:\n1. Correcting any factual errors\n2. Providing more specific information if the initial answer is too vague\n3. Ensuring the answer directly addresses the question asked\n\nDo not include any explanations or reasoning in your response. Provide only the verified or corrected answer.\n\"\"\"\n\nFORMAT_ANSWER_PROMPT = \"\"\"\nGiven the question and the verified answer, format the final answer to be concise, accurate, and directly addressing the question. Ensure the answer is a clear, brief statement without additional explanation or reasoning. If the answer is a name, profession, or short phrase, provide only that information without forming a complete sentence.\n\nFor example:\n- If the answer is a person's name, just provide the name.\n- If the answer is a profession, state only the profession.\n- If the answer is a short phrase, give only that phrase.\n\nDo not include any prefixes like \"The answer is\" or \"The profession is\". Just provide the answer itself.\n\nEnsure that the final answer is in the correct form (singular/plural, capitalization) to directly match the question.\n\"\"\"</prompt>", "tag": "HotpotQA", "domain": "llm_judge", "parent_round": 3, "child_round": 4, "parent_score": 0.6135746606334841, "child_score": 0.6063632978274922, "performance_gain": -0.007211362805991883}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.5813953488372093</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_4.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\\n        \\n        # New step: Analyze and improve the solution before testing\\n        improved_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nGenerated solution: {solution['response']}\\\", instruction=prompt_custom.ANALYZE_IMPROVE_PROMPT)\\n        \\n        test_result = await self.test(problem=problem, solution=improved_solution['response'], entry_point=entry_point)\\n        \\n        if test_result['result']:\\n            return test_result['solution'], self.llm.cost_manager.total_cost\\n        else:\\n            # If the test fails, try to fix the solution\\n            fixed_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nFailed solution: {improved_solution['response']}\\\\nError: {test_result['solution']}\\\", instruction=prompt_custom.FIX_CODE_PROMPT)\\n            return fixed_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>CODE_GENERATE_PROMPT = \\\"\\\"\\\"\\nGenerate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity.\\n\\nProblem:\\n{problem}\\n\\nFunction signature:\\n{entry_point}\\n\\nGenerate the complete function below:\\n\\\"\\\"\\\"\\n\\nANALYZE_IMPROVE_PROMPT = \\\"\\\"\\\"\\nAnalyze the following Python function and suggest improvements for better performance, readability, and correctness. Consider edge cases, potential errors, and optimization opportunities. Provide an improved version of the function.\\n\\nProblem:\\n{input}\\n\\nProvide the improved function below:\\n\\\"\\\"\\\"\\n\\nFIX_CODE_PROMPT = \\\"\\\"\\\"\\nThe provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation.\\n\\nProblem:\\n{input}\\n\\nProvide the corrected function below:\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 5</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_5.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        solutions = []\n        for _ in range(3):  # Generate 3 solutions\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\n            solutions.append(solution['response'])\n        \n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        test_result = await self.test(problem=problem, solution=best_solution['response'], entry_point=entry_point)\n        \n        if test_result['result']:\n            return test_result['solution'], self.llm.cost_manager.total_cost\n        else:\n            fixed_solution = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {best_solution['response']}\\nError: {test_result['solution']}\", instruction=prompt_custom.FIX_CODE_PROMPT)\n            return fixed_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>CODE_GENERATE_PROMPT = \"\"\"\nGenerate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity.\n\nProblem:\n{problem}\n\nFunction signature:\n{entry_point}\n\nGenerate the complete function below:\n\"\"\"\n\nFIX_CODE_PROMPT = \"\"\"\nThe provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation.\n\nProblem:\n{input}\n\nProvide the corrected function below:\n\"\"\"</prompt>", "tag": "MBPP", "domain": "llm_judge", "parent_round": 4, "child_round": 5, "parent_score": 0.5813953488372093, "child_score": 0.8372093023255814, "performance_gain": 0.2558139534883721}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve QA problems.\\nReferring to the given graph and prompt, which forms a basic example of a QA solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.7348039215686274</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_18.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.answer_generate = operator.AnswerGenerate(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):  # Generate 3 solutions\\n            step_by_step = await self.answer_generate(input=problem)\\n            solution = await self.custom(input=f\\\"Question: {problem}\\\\nStep-by-step solution: {step_by_step['thought']}\\\\nInitial answer: {step_by_step['answer']}\\\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions)\\n        verified_solution = await self.custom(input=f\\\"Question: {problem}\\\\nFinal answer: {final_solution['response']}\\\", instruction=prompt_custom.VERIFY_ANSWER_PROMPT)\\n        return verified_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\\n\\n1. Ensure the answer is concise and directly addresses the question.\\n2. If the answer is a number, provide only the number without additional text.\\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\\n4. Remove any explanations or reasoning from the final answer.\\n5. Double-check that the refined answer is consistent with the step-by-step solution and initial answer.\\n6. If the answer involves selecting between options, clearly state the chosen option.\\n\\nYour task is to extract or refine the most accurate answer based on the provided information.\\n\\\"\\\"\\\"\\n\\nVERIFY_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question and the final answer, please verify and refine the answer to ensure it meets the following criteria:\\n\\n1. The answer should be a single number or a short phrase, without any additional explanations.\\n2. If the answer is a percentage, remove the percentage sign and provide only the numerical value.\\n3. Ensure that the answer is properly formatted according to the question requirements.\\n4. If the answer should be a whole number, round it to the nearest integer.\\n5. Double-check that the answer directly addresses the question asked.\\n\\nYour task is to provide the verified and refined answer that meets these criteria. If the answer already meets all criteria, return it unchanged.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 19</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_19.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.answer_generate = operator.AnswerGenerate(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):  # Generate 3 solutions\n            step_by_step = await self.answer_generate(input=problem)\n            solution = await self.custom(input=f\"Question: {problem}\\nStep-by-step solution: {step_by_step['thought']}\\nInitial answer: {step_by_step['answer']}\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n            verified_solution = await self.custom(input=f\"Question: {problem}\\nStep-by-step solution: {step_by_step['thought']}\\nRefined answer: {solution['response']}\", instruction=prompt_custom.VERIFY_NUMERICAL_ANSWER_PROMPT)\n            solutions.append(verified_solution['response'])\n        \n        final_solution = await self.sc_ensemble(solutions=solutions)\n        return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>REFINE_ANSWER_PROMPT = \"\"\"\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\n\n1. Ensure the answer is concise and directly addresses the question.\n2. If the answer is a number, provide only the number without additional text.\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\n4. Remove any explanations or reasoning from the final answer.\n5. Double-check that the refined answer is consistent with the step-by-step solution and initial answer.\n6. If the answer involves selecting between options, clearly state the chosen option.\n\nYour task is to extract or refine the most accurate answer based on the provided information.\n\"\"\"\n\nVERIFY_NUMERICAL_ANSWER_PROMPT = \"\"\"\nGiven the question, step-by-step solution, and refined answer, please verify and correct the numerical answer if necessary. Follow these guidelines:\n\n1. Check if the answer is consistent with the question and step-by-step solution.\n2. Ensure the answer is a number or numbers separated by a vertical bar (|) if multiple answers are possible.\n3. If the answer is incorrect or inconsistent, recalculate based on the step-by-step solution.\n4. Remove any non-numeric characters or explanations, keeping only the numerical value(s).\n5. If the question asks for a difference or comparison between values, double-check the calculation.\n6. If no numerical answer is required, return the refined answer as is.\n\nYour task is to provide the most accurate numerical answer based on the given information and calculations.\n\"\"\"</prompt>", "tag": "DROP", "domain": "llm_judge", "parent_round": 18, "child_round": 19, "parent_score": 0.7348039215686274, "child_score": 0.6136941408312641, "performance_gain": -0.12110978073736334}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>\\nPrevious failed modifications:\\n  - Add the ScEnsemble operator to generate multiple solutions and select the best one. This will help in improving the overall quality of the generated code. (Score: 0.8400000000000001)</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.8666666666666667</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_6.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\\n        \\n        # Self-review step\\n        review = await self.custom(input=f\\\"Problem: {problem}\\\\nGenerated solution: {solution['response']}\\\", instruction=prompt_custom.SELF_REVIEW_PROMPT)\\n        \\n        # Improve the solution based on the review\\n        improved_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\\\"{prompt_custom.CODE_GENERATE_PROMPT}\\\\n\\\\nConsider this review: {review['response']}\\\")\\n        \\n        test_result = await self.test(problem=problem, solution=improved_solution['response'], entry_point=entry_point)\\n        \\n        if not test_result['result']:\\n            analysis = await self.custom(input=f\\\"Problem: {problem}\\\\nFailed solution: {improved_solution['response']}\\\\nTest result: {test_result['solution']}\\\", instruction=prompt_custom.ANALYZE_AND_IMPROVE_PROMPT)\\n            final_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\\\"{prompt_custom.CODE_GENERATE_PROMPT}\\\\n\\\\nConsider this analysis: {analysis['response']}\\\")\\n            return final_solution['response'], self.llm.cost_manager.total_cost\\n        \\n        return improved_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>CODE_GENERATE_PROMPT = \\\"\\\"\\\"\\nGenerate a Python function that solves the given problem. Ensure the function signature matches the problem description. Include docstrings and comments to explain the logic. The solution should be efficient and handle edge cases.\\n\\\"\\\"\\\"\\n\\nSELF_REVIEW_PROMPT = \\\"\\\"\\\"\\nReview the generated solution and provide feedback on its correctness, efficiency, and adherence to best practices. Consider the following:\\n1. Does the solution correctly implement the problem requirements?\\n2. Are there any potential edge cases that are not handled?\\n3. Can the code be optimized for better performance?\\n4. Does the code follow Python best practices and style guidelines?\\n5. Are there any logical errors or potential bugs?\\nProvide specific suggestions for improvements if necessary.\\n\\\"\\\"\\\"\\n\\nANALYZE_AND_IMPROVE_PROMPT = \\\"\\\"\\\"\\nAnalyze the failed solution and provide suggestions for improvement. Consider the following:\\n1. Identify logical errors or misunderstandings of the problem.\\n2. Check for edge cases that might not be handled correctly.\\n3. Suggest optimizations or alternative approaches if applicable.\\n4. Provide specific code snippets or pseudocode to address the issues found.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Add the ScEnsemble operator to generate multiple solutions and select the best one. This will help in improving the overall quality of the generated code.</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_7.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        # Generate multiple solutions\n        solutions = []\n        for _ in range(3):\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\n            solutions.append(solution['response'])\n        \n        # Use ScEnsemble to select the best solution\n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Self-review step\n        review = await self.custom(input=f\"Problem: {problem}\\nGenerated solution: {best_solution['response']}\", instruction=prompt_custom.SELF_REVIEW_PROMPT)\n        \n        # Improve the solution based on the review\n        improved_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\"{prompt_custom.CODE_GENERATE_PROMPT}\\n\\nConsider this review: {review['response']}\")\n        \n        test_result = await self.test(problem=problem, solution=improved_solution['response'], entry_point=entry_point)\n        \n        if not test_result['result']:\n            analysis = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {improved_solution['response']}\\nTest result: {test_result['solution']}\", instruction=prompt_custom.ANALYZE_AND_IMPROVE_PROMPT)\n            final_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\"{prompt_custom.CODE_GENERATE_PROMPT}\\n\\nConsider this analysis: {analysis['response']}\")\n            return final_solution['response'], self.llm.cost_manager.total_cost\n        \n        return improved_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>CODE_GENERATE_PROMPT = \"\"\"\nGenerate a Python function that solves the given problem. Ensure the function signature matches the problem description. Include docstrings and comments to explain the logic. The solution should be efficient and handle edge cases.\n\"\"\"\n\nSELF_REVIEW_PROMPT = \"\"\"\nReview the generated solution and provide feedback on its correctness, efficiency, and adherence to best practices. Consider the following:\n1. Does the solution correctly implement the problem requirements?\n2. Are there any potential edge cases that are not handled?\n3. Can the code be optimized for better performance?\n4. Does the code follow Python best practices and style guidelines?\n5. Are there any logical errors or potential bugs?\nProvide specific suggestions for improvements if necessary.\n\"\"\"\n\nANALYZE_AND_IMPROVE_PROMPT = \"\"\"\nAnalyze the failed solution and provide suggestions for improvement. Consider the following:\n1. Identify logical errors or misunderstandings of the problem.\n2. Check for edge cases that might not be handled correctly.\n3. Suggest optimizations or alternative approaches if applicable.\n4. Provide specific code snippets or pseudocode to address the issues found.\n\"\"\"</prompt>", "tag": "HumanEval", "domain": "llm_judge", "parent_round": 6, "child_round": 7, "parent_score": 0.8666666666666667, "child_score": 0.9, "performance_gain": 0.033333333333333326}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.89</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_12.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):\\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        ensemble_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        # Add a review step using the Programmer operator\\n        review_result = await self.programmer(problem=problem, analysis=ensemble_solution['response'])\\n        \\n        if review_result['output']:\\n            final_answer = review_result['output']\\n        else:\\n            final_answer = ensemble_solution['response']\\n        \\n        # Final verification step\\n        verification = await self.custom(input=f\\\"{problem}\\\\nProposed answer: {final_answer}\\\", instruction=prompt_custom.VERIFY_PROMPT)\\n        \\n        return verification['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>MATH_SOLVE_PROMPT = \\\"\\\"\\\"\\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps:\\n\\n1. Carefully read and understand the problem.\\n2. Identify the key information and variables.\\n3. Determine the appropriate mathematical concepts or formulas to use.\\n4. Solve the problem step by step, showing all your work.\\n5. Double-check your calculations and reasoning.\\n6. Provide a clear and concise final answer.\\n\\nRemember to format your answer as follows:\\n- Use LaTeX notation for mathematical expressions where appropriate.\\n- Clearly state your final answer at the end of your solution.\\n- Express numerical answers as precise values (avoid rounding unless specified).\\n- Ensure that your final answer is a single numerical value without any units or additional text.\\n- Do not include any explanatory text with your final answer, just the number itself.\\n\\nFor example, if the final answer is 42.5, your response should end with just:\\n42.5\\n\\nHere's the problem to solve:\\n\\n\\\"\\\"\\\"\\n\\nVERIFY_PROMPT = \\\"\\\"\\\"\\nYou are a meticulous math verifier. Your task is to verify the proposed answer to a given math problem. Follow these steps:\\n\\n1. Carefully read the original problem.\\n2. Review the proposed answer.\\n3. Independently solve the problem, showing your work step-by-step.\\n4. Compare your solution with the proposed answer.\\n5. If the proposed answer is correct, return it as is.\\n6. If the proposed answer is incorrect, provide the correct answer.\\n\\nRemember:\\n- Ensure your final answer is a single numerical value without units or additional text.\\n- Double-check all calculations for accuracy.\\n- If correcting the answer, use the same format as the original problem (i.e., same level of precision).\\n\\nHere's the problem and proposed answer to verify:\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 13</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_13.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(5):  # Generate 5 solutions\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\n            solutions.append(solution['response'])\n        \n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Add a verification step using the Programmer operator\n        verification = await self.programmer(problem=problem, analysis=final_solution['response'])\n        \n        if verification['output']:\n            return verification['output'], self.llm.cost_manager.total_cost\n        else:\n            return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>MATH_SOLVE_PROMPT = \"\"\"\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps carefully:\n\n1. Read and understand the problem thoroughly.\n2. Identify all key information, variables, and relationships.\n3. Determine the appropriate mathematical concepts, formulas, or equations to use.\n4. Solve the problem step-by-step, showing all your work clearly.\n5. Double-check your calculations and reasoning at each step.\n6. Provide a clear and concise final answer.\n7. Verify your solution by plugging it back into the original problem or using an alternative method if possible.\n\nFormat your answer as follows:\n- Use LaTeX notation for mathematical expressions where appropriate.\n- Show each step of your solution process clearly.\n- Clearly state your final answer at the end of your solution.\n- Express numerical answers as precise values (avoid rounding unless specified).\n- Ensure that your final answer is a single numerical value without any units or additional text.\n- Do not include any explanatory text with your final answer, just the number itself.\n\nFor example, if the final answer is 42.5, your response should end with just:\n42.5\n\nHere's the problem to solve:\n\n\"\"\"</prompt>", "tag": "GSM8K", "domain": "llm_judge", "parent_round": 12, "child_round": 13, "parent_score": 0.89, "child_score": 0.91, "performance_gain": 0.020000000000000018}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.7209302325581395</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_6.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        solutions = []\\n        for _ in range(3):  # Generate 3 solutions\\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        # Add code review step\\n        reviewed_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nSolution: {best_solution['response']}\\\", instruction=prompt_custom.CODE_REVIEW_PROMPT)\\n        \\n        test_result = await self.test(problem=problem, solution=reviewed_solution['response'], entry_point=entry_point)\\n        \\n        if test_result['result']:\\n            return test_result['solution'], self.llm.cost_manager.total_cost\\n        else:\\n            fixed_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nFailed solution: {reviewed_solution['response']}\\\\nError: {test_result['solution']}\\\", instruction=prompt_custom.FIX_CODE_PROMPT)\\n            return fixed_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>CODE_GENERATE_PROMPT = \\\"\\\"\\\"\\nGenerate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity.\\n\\nProblem:\\n{problem}\\n\\nFunction signature:\\n{entry_point}\\n\\nGenerate the complete function below:\\n\\\"\\\"\\\"\\n\\nCODE_REVIEW_PROMPT = \\\"\\\"\\\"\\nReview the following Python code for the given problem. Identify any potential issues, improve code quality, and optimize if necessary. Ensure the function name and signature remain unchanged. Provide the reviewed and improved code.\\n\\nProblem:\\n{input}\\n\\nProvide the reviewed and improved function below:\\n\\\"\\\"\\\"\\n\\nFIX_CODE_PROMPT = \\\"\\\"\\\"\\nThe provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation.\\n\\nProblem:\\n{input}\\n\\nProvide the corrected function below:\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 7</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_7.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        \"\"\"\n        Implementation of the graph\n        Custom operator to generate anything you want.\n        But when you want to get standard code, you should use custom_code_generate operator.\n        \"\"\"\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\n        \n        # New step: Review and improve the solution before testing\n        reviewed_solution = await self.custom(input=f\"Problem: {problem}\\nGenerated solution: {solution['response']}\", instruction=prompt_custom.REVIEW_PROMPT)\n        \n        test_result = await self.test(problem=problem, solution=reviewed_solution['response'], entry_point=entry_point)\n        \n        if test_result['result']:\n            return test_result['solution'], self.llm.cost_manager.total_cost\n        else:\n            # If the test fails, try to fix the solution\n            fixed_solution = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {reviewed_solution['response']}\\nError: {test_result['solution']}\", instruction=prompt_custom.FIX_CODE_PROMPT)\n            return fixed_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>CODE_GENERATE_PROMPT = \"\"\"\nGenerate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity.\n\nProblem:\n{problem}\n\nFunction signature:\n{entry_point}\n\nGenerate the complete function below:\n\"\"\"\n\nREVIEW_PROMPT = \"\"\"\nReview and improve the generated solution for the given problem. Check for:\n1. Correct implementation of the problem requirements\n2. Proper error handling and edge cases\n3. Code efficiency and optimization\n4. Adherence to Python best practices and PEP 8 style guide\n\nProblem:\n{input}\n\nProvide the reviewed and improved solution below:\n\"\"\"\n\nFIX_CODE_PROMPT = \"\"\"\nThe provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation.\n\nProblem:\n{input}\n\nProvide the corrected function below:\n\"\"\"</prompt>", "tag": "MBPP", "domain": "llm_judge", "parent_round": 6, "child_round": 7, "parent_score": 0.7209302325581395, "child_score": 0.5813953488372093, "performance_gain": -0.13953488372093015}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.8333333333333334</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_4.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\\n        \\n        # Add a review step\\n        review = await self.custom(input=f\\\"Problem: {problem}\\\\nGenerated solution: {solution['response']}\\\", instruction=prompt_custom.REVIEW_PROMPT)\\n        \\n        # Improve the solution based on the review\\n        improved_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\\\"{prompt_custom.CODE_GENERATE_PROMPT}\\\\n\\\\nConsider this review: {review['response']}\\\")\\n        \\n        test_result = await self.test(problem=problem, solution=improved_solution['response'], entry_point=entry_point)\\n        \\n        if not test_result['result']:\\n            analysis = await self.custom(input=f\\\"Problem: {problem}\\\\nFailed solution: {improved_solution['response']}\\\\nTest result: {test_result['solution']}\\\", instruction=prompt_custom.ANALYZE_AND_IMPROVE_PROMPT)\\n            final_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\\\"{prompt_custom.CODE_GENERATE_PROMPT}\\\\n\\\\nConsider this analysis: {analysis['response']}\\\")\\n            return final_solution['response'], self.llm.cost_manager.total_cost\\n        \\n        return improved_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>CODE_GENERATE_PROMPT = \\\"\\\"\\\"\\nGenerate a Python function that solves the given problem. Ensure the function signature matches the problem description. Include docstrings and comments to explain the logic. The solution should be efficient and handle edge cases. Pay special attention to the order of operations and ensure that the function evaluates the expression correctly.\\n\\\"\\\"\\\"\\n\\nREVIEW_PROMPT = \\\"\\\"\\\"\\nReview the generated solution and suggest improvements. Consider the following:\\n1. Does the function correctly implement the order of operations?\\n2. Are all required operators (+, -, *, //, **) handled properly?\\n3. Is there proper error handling for cases like division by zero?\\n4. Does the function handle the case where the operator list is empty?\\n5. Is the code efficient and readable?\\nProvide specific suggestions for improvement.\\n\\\"\\\"\\\"\\n\\nANALYZE_AND_IMPROVE_PROMPT = \\\"\\\"\\\"\\nAnalyze the failed solution and provide suggestions for improvement. Consider the following:\\n1. Identify logical errors or misunderstandings of the problem.\\n2. Check for edge cases that might not be handled correctly.\\n3. Ensure the order of operations is correctly implemented.\\n4. Suggest optimizations or alternative approaches if applicable.\\n5. Provide specific code snippets or pseudocode to address the issues found.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 5</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_5.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        \"\"\"\n        Implementation of the graph\n        Custom operator to generate anything you want.\n        But when you want to get standard code, you should use custom_code_generate operator.\n        \"\"\"\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=\"\")\n        test_result = await self.test(problem=problem, solution=solution['response'], entry_point=entry_point)\n        \n        if test_result['result']:\n            return test_result['solution'], self.llm.cost_manager.total_cost\n        else:\n            # If the test fails, try to generate a new solution\n            new_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.IMPROVE_CODE_PROMPT)\n            return new_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>IMPROVE_CODE_PROMPT = \"\"\"\nThe previous solution failed some test cases. Please analyze the problem carefully and provide an improved solution that addresses all edge cases and requirements. Ensure your code is efficient and follows best practices.\n\"\"\"</prompt>", "tag": "HumanEval", "domain": "llm_judge", "parent_round": 4, "child_round": 5, "parent_score": 0.8333333333333334, "child_score": 0.9666666666666667, "performance_gain": 0.1333333333333333}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>\\nPrevious failed modifications:\\n  - Add a step to generate multiple solutions using different prompts, then use the ScEnsemble operator to select the best solution. This will increase the chances of finding a correct solution by leveraging the ensemble approach. (Score: 0.9333333333333333)\\n  - Add a step to generate multiple solutions using the custom_code_generate operator, then use the ScEnsemble operator to select the best solution. This will increase the chances of finding a correct solution by leveraging the ensemble approach. (Score: 0.9266666666666667)</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.9666666666666667</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_14.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        Custom operator to generate anything you want.\\n        But when you want to get standard code, you should use custom_code_generate operator.\\n        \\\"\\\"\\\"\\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=\\\"Generate a Python function to solve the given problem.\\\")\\n        \\n        # Review and improve the generated solution\\n        reviewed_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nGenerated solution: {solution['response']}\\\", instruction=prompt_custom.REVIEW_SOLUTION_PROMPT)\\n        \\n        # Test the reviewed solution\\n        test_result = await self.test(problem=problem, solution=reviewed_solution['response'], entry_point=entry_point)\\n        \\n        if test_result['result']:\\n            return test_result['solution'], self.llm.cost_manager.total_cost\\n        else:\\n            # If the test fails, try to improve the solution\\n            improved_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nFailed solution: {reviewed_solution['response']}\\\\nError: {test_result['solution']}\\\", instruction=prompt_custom.IMPROVE_SOLUTION_PROMPT)\\n            return improved_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>REVIEW_SOLUTION_PROMPT = \\\"\\\"\\\"\\nReview the given problem and the generated solution. Analyze the code for correctness, efficiency, and adherence to best practices. Improve the solution if necessary.\\n\\nYour task:\\n1. Understand the problem statement.\\n2. Review the generated solution.\\n3. Check for logical errors, edge cases, and potential improvements.\\n4. Rewrite the solution if improvements are needed, or keep it as is if it's optimal.\\n5. Ensure the final solution is complete, correct, and efficient.\\n\\nProvide only the reviewed and potentially improved Python function as your response, without any additional explanations or comments.\\n\\\"\\\"\\\"\\n\\nIMPROVE_SOLUTION_PROMPT = \\\"\\\"\\\"\\nAnalyze the given problem and the failed solution. Identify the errors and improve the code to solve the problem correctly. Make sure to handle edge cases and follow best practices in Python programming.\\n\\nYour task:\\n1. Understand the problem statement.\\n2. Review the failed solution and the error message.\\n3. Identify the cause of the failure.\\n4. Rewrite the solution, addressing the identified issues.\\n5. Ensure the new solution is complete, correct, and efficient.\\n\\nProvide only the improved Python function as your response, without any additional explanations or comments.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 15</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_15.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\n        \n        # Add a review step\n        review = await self.custom(input=f\"Problem: {problem}\\nGenerated solution: {solution['response']}\", instruction=prompt_custom.REVIEW_PROMPT)\n        \n        # If review suggests improvements, apply them\n        if \"No improvements needed\" not in review['response']:\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\"{prompt_custom.CODE_GENERATE_PROMPT}\\n\\nConsider these improvements: {review['response']}\")\n        \n        test_result = await self.test(problem=problem, solution=solution['response'], entry_point=entry_point)\n        \n        if not test_result['result']:\n            # Comprehensive analysis of the problem and failed solution\n            analysis = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {solution['response']}\\nTest result: {test_result['solution']}\", instruction=prompt_custom.COMPREHENSIVE_ANALYSIS_PROMPT)\n            \n            # Generate improved solution based on the comprehensive analysis\n            improved_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\"{prompt_custom.CODE_GENERATE_PROMPT}\\n\\nConsider this analysis: {analysis['response']}\")\n            \n            # Test the improved solution\n            improved_test_result = await self.test(problem=problem, solution=improved_solution['response'], entry_point=entry_point)\n            \n            if improved_test_result['result']:\n                return improved_solution['response'], self.llm.cost_manager.total_cost\n            else:\n                # If the improved solution still fails, return the original solution\n                return solution['response'], self.llm.cost_manager.total_cost\n        \n        return solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>CODE_GENERATE_PROMPT = \"\"\"\nGenerate a Python function that solves the given problem. Ensure the function signature matches the problem description. Include docstrings and comments to explain the logic. The solution should be efficient and handle edge cases.\n\"\"\"\n\nREVIEW_PROMPT = \"\"\"\nReview the generated solution for the given problem. Check for:\n1. Correctness: Does the solution solve the problem as described?\n2. Efficiency: Is the solution optimized for performance?\n3. Readability: Is the code well-structured and easy to understand?\n4. Edge cases: Are all possible scenarios handled?\n5. Python best practices: Does the code follow PEP 8 and other Python conventions?\n\nIf improvements are needed, provide specific suggestions. If no improvements are needed, state \"No improvements needed\".\n\"\"\"\n\nCOMPREHENSIVE_ANALYSIS_PROMPT = \"\"\"\nPerform a comprehensive analysis of the problem and the failed solution. Consider the following aspects:\n\n1. Problem understanding: Identify any potential misinterpretations of the problem statement.\n2. Logical errors: Pinpoint any flaws in the solution's logic or algorithm.\n3. Edge cases: Determine if all possible input scenarios are properly handled.\n4. Efficiency: Evaluate the time and space complexity of the solution.\n5. Coding style: Assess the readability and adherence to Python best practices.\n6. Test case failures: Analyze why specific test cases are failing.\n7. Alternative approaches: Suggest different algorithms or data structures that might be more suitable.\n\nProvide a detailed breakdown of these aspects and suggest specific improvements for each identified issue.\n\"\"\"</prompt>", "tag": "HumanEval", "domain": "llm_judge", "parent_round": 14, "child_round": 15, "parent_score": 0.9666666666666667, "child_score": 0.9, "performance_gain": -0.06666666666666665}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.7906976744186046</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_18.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        solutions = []\\n        for _ in range(3):  # Generate 3 solutions\\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        # Generate additional test cases\\n        additional_tests = await self.custom(input=f\\\"Problem: {problem}\\\\nSolution: {best_solution['response']}\\\", instruction=prompt_custom.GENERATE_TESTS_PROMPT)\\n        \\n        # Combine original problem and additional tests\\n        enhanced_problem = f\\\"{problem}\\\\n\\\\nAdditional test cases:\\\\n{additional_tests['response']}\\\"\\n        \\n        test_result = await self.test(problem=enhanced_problem, solution=best_solution['response'], entry_point=entry_point)\\n        \\n        if test_result['result']:\\n            return test_result['solution'], self.llm.cost_manager.total_cost\\n        else:\\n            # If the test fails, try to fix the solution\\n            fixed_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nFailed solution: {best_solution['response']}\\\\nError: {test_result['solution']}\\\", instruction=prompt_custom.FIX_CODE_PROMPT)\\n            return fixed_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>CODE_GENERATE_PROMPT = \\\"\\\"\\\"\\nGenerate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity.\\n\\nProblem:\\n{problem}\\n\\nFunction signature:\\n{entry_point}\\n\\nGenerate the complete function below:\\n\\\"\\\"\\\"\\n\\nFIX_CODE_PROMPT = \\\"\\\"\\\"\\nThe provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation.\\n\\nProblem:\\n{input}\\n\\nProvide the corrected function below:\\n\\\"\\\"\\\"\\n\\nGENERATE_TESTS_PROMPT = \\\"\\\"\\\"\\nGiven the problem and a potential solution, generate additional test cases to thoroughly evaluate the function. Include edge cases and typical scenarios. Format the test cases as assert statements that can be directly added to a Python test function.\\n\\nProblem:\\n{input}\\n\\nGenerate 3-5 additional test cases as assert statements:\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 19</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_19.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        solutions = []\n        for _ in range(3):  # Generate 3 solutions\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\n            solutions.append(solution['response'])\n        \n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Add a review step\n        reviewed_solution = await self.custom(input=f\"Problem: {problem}\\nSolution: {best_solution['response']}\", instruction=prompt_custom.REVIEW_PROMPT)\n        \n        test_result = await self.test(problem=problem, solution=reviewed_solution['response'], entry_point=entry_point)\n        \n        if test_result['result']:\n            return test_result['solution'], self.llm.cost_manager.total_cost\n        else:\n            # If the test fails, try to fix the solution\n            fixed_solution = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {reviewed_solution['response']}\\nError: {test_result['solution']}\", instruction=prompt_custom.FIX_CODE_PROMPT)\n            return fixed_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>CODE_GENERATE_PROMPT = \"\"\"\nGenerate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity.\n\nProblem:\n{problem}\n\nFunction signature:\n{entry_point}\n\nGenerate the complete function below:\n\"\"\"\n\nREVIEW_PROMPT = \"\"\"\nReview the following solution for the given problem. Identify any potential issues, inefficiencies, or areas for improvement. Provide an improved version of the code if necessary.\n\nProblem:\n{input}\n\nProvide the reviewed and improved function below:\n\"\"\"\n\nFIX_CODE_PROMPT = \"\"\"\nThe provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation.\n\nProblem:\n{input}\n\nProvide the corrected function below:\n\"\"\"</prompt>", "tag": "MBPP", "domain": "llm_judge", "parent_round": 18, "child_round": 19, "parent_score": 0.7906976744186046, "child_score": 0.627906976744186, "performance_gain": -0.16279069767441856}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve QA problems.\\nReferring to the given graph and prompt, which forms a basic example of a QA solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.6374542124542124</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.round_16.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.answer_generate = operator.AnswerGenerate(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):\\n            initial_response = await self.answer_generate(input=problem)\\n            thought_process = initial_response['thought']\\n            initial_answer = initial_response['answer']\\n            solutions.append(initial_answer)\\n\\n        ensemble_result = await self.sc_ensemble(solutions=solutions)\\n        best_answer = ensemble_result['response']\\n        \\n        name_extracted_answer = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nBest answer: {best_answer}\\\",\\n            instruction=prompt_custom.NAME_EXTRACTION_PROMPT\\n        )\\n        \\n        identity_check_answer = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nName-extracted answer: {name_extracted_answer['response']}\\\",\\n            instruction=prompt_custom.IDENTITY_CHECK_PROMPT\\n        )\\n        \\n        profession_check_answer = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nIdentity-checked answer: {identity_check_answer['response']}\\\",\\n            instruction=prompt_custom.PROFESSION_CHECK_PROMPT\\n        )\\n        \\n        fact_checked_answer = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nProfession-checked answer: {profession_check_answer['response']}\\\",\\n            instruction=prompt_custom.FACT_CHECK_PROMPT\\n        )\\n        \\n        style_check_answer = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nFact-checked answer: {fact_checked_answer['response']}\\\",\\n            instruction=prompt_custom.STYLE_CHECK_PROMPT\\n        )\\n        \\n        additional_verification = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nStyle-checked answer: {style_check_answer['response']}\\\",\\n            instruction=prompt_custom.ADDITIONAL_VERIFICATION_PROMPT\\n        )\\n        \\n        refined_solution = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nDouble-verified answer: {additional_verification['response']}\\\",\\n            instruction=prompt_custom.FORMAT_ANSWER_PROMPT\\n        )\\n        \\n        return refined_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>FORMAT_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question and the double-verified answer, format the final answer to be extremely concise and directly addressing the question. Provide only the essential information without any explanation or additional context. For names, professions, or short phrases, give only that specific information.\\n\\nExamples:\\n- For a person's name: \\\"John Doe\\\"\\n- For a profession: \\\"Doctor\\\"\\n- For a short phrase: \\\"Once in a blue moon\\\"\\n\\nDo not include any prefixes or explanatory text. Provide only the answer itself.\\n\\\"\\\"\\\"\\n\\nNAME_EXTRACTION_PROMPT = \\\"\\\"\\\"\\nGiven the question and the best answer, focus on extracting and verifying any names mentioned. Pay special attention to:\\n\\n1. Full names (first name, middle name, last name)\\n2. Nicknames or aliases\\n3. Correct spelling of names\\n\\nIf the answer contains a name, ensure it is accurate and complete. If a name is incorrect or incomplete, provide the correct full name. If no name is present or needed, simply restate the answer.\\n\\nProvide your response in a concise manner, focusing solely on the corrected or verified answer without additional explanations.\\n\\\"\\\"\\\"\\n\\nIDENTITY_CHECK_PROMPT = \\\"\\\"\\\"\\nGiven the question and the name-extracted answer, perform a thorough identity check, especially for individuals who may have changed their names, use stage names, or have multiple identities. Consider:\\n\\n1. Birth names vs. stage names or pseudonyms\\n2. Name changes due to personal reasons (e.g., marriage, gender transition)\\n3. Professional names vs. legal names\\n\\nIf the answer involves a person's identity and there's a discrepancy or additional information about their name, provide the most accurate and relevant name based on the context of the question. If no changes are needed, restate the answer.\\n\\nProvide your response in a concise manner, focusing solely on the verified or corrected identity without additional explanations.\\n\\\"\\\"\\\"\\n\\nPROFESSION_CHECK_PROMPT = \\\"\\\"\\\"\\nGiven the question and the identity-checked answer, focus on verifying and specifying any professions mentioned. Pay special attention to:\\n\\n1. Accurate job titles or occupations\\n2. Specific roles within a broader field\\n3. Multiple professions if applicable\\n\\nIf the answer involves a profession, ensure it is accurate and as specific as possible. If a profession is mentioned but is too general, provide a more precise description. If multiple professions are relevant, list them all.\\n\\nProvide your response in a concise manner, focusing solely on the verified or corrected profession(s) without additional explanations.\\n\\\"\\\"\\\"\\n\\nFACT_CHECK_PROMPT = \\\"\\\"\\\"\\nGiven the question and the profession-checked answer, carefully analyze the information provided and perform a fact-check. If you find any inconsistencies or errors in the answer, provide a corrected version. If the answer appears accurate, simply restate it. Focus on verifying key facts, names, dates, and other critical information related to the question.\\n\\nYour task:\\n1. Analyze the question and the answer.\\n2. Identify any potential errors or inconsistencies.\\n3. If errors are found, provide a corrected answer.\\n4. If no errors are found, restate the answer.\\n\\nProvide your response in a concise manner, focusing solely on the corrected or verified answer without additional explanations.\\n\\\"\\\"\\\"\\n\\nSTYLE_CHECK_PROMPT = \\\"\\\"\\\"\\nReview the fact-checked answer, focusing specifically on architectural and historical style terms. Verify the accuracy of any mentioned styles, ensuring they are correctly identified and placed in the proper historical context. Pay special attention to:\\n\\n1. Architectural styles (e.g., Gothic, Baroque, Neoclassical)\\n2. Historical periods and their associated styles\\n3. Relationships between different styles (e.g., which style influenced or preceded another)\\n\\nIf you find any errors or misidentifications in the architectural or historical style terms, provide a corrected version. If the answer is accurate, simply restate it. Be concise and direct in your response, providing only the verified or corrected answer without explanations.\\n\\\"\\\"\\\"\\n\\nADDITIONAL_VERIFICATION_PROMPT = \\\"\\\"\\\"\\nPerform an additional verification on the previously style-checked answer. Focus on:\\n\\n1. Consistency with the question\\n2. Accuracy of specific details (names, dates, places, styles)\\n3. Completeness of the answer\\n4. Ensure the answer is a single word, number, or short phrase when appropriate\\n\\nIf any issues are found, provide a corrected version. If the answer is accurate and complete, restate it. Be concise and direct in your response, providing only the verified or corrected answer without explanations.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 17</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.round_17.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.answer_generate = operator.AnswerGenerate(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):\n            initial_response = await self.answer_generate(input=problem)\n            thought_process = initial_response['thought']\n            initial_answer = initial_response['answer']\n            solutions.append(initial_answer)\n\n        ensemble_result = await self.sc_ensemble(solutions=solutions)\n        best_answer = ensemble_result['response']\n        \n        missing_info_check = await self.custom(\n            input=f\"Question: {problem}\\nBest answer: {best_answer}\",\n            instruction=prompt_custom.MISSING_INFO_CHECK_PROMPT\n        )\n        \n        if \"No specific information\" in missing_info_check['response']:\n            inferred_answer = await self.custom(\n                input=f\"Question: {problem}\\nCurrent answer: {missing_info_check['response']}\",\n                instruction=prompt_custom.INFER_MISSING_INFO_PROMPT\n            )\n            best_answer = inferred_answer['response']\n        else:\n            best_answer = missing_info_check['response']\n        \n        name_extracted_answer = await self.custom(\n            input=f\"Question: {problem}\\nBest answer: {best_answer}\",\n            instruction=prompt_custom.NAME_EXTRACTION_PROMPT\n        )\n        \n        disambiguated_answer = await self.custom(\n            input=f\"Question: {problem}\\nName-extracted answer: {name_extracted_answer['response']}\",\n            instruction=prompt_custom.ENTITY_DISAMBIGUATION_PROMPT\n        )\n        \n        identity_check_answer = await self.custom(\n            input=f\"Question: {problem}\\nDisambiguated answer: {disambiguated_answer['response']}\",\n            instruction=prompt_custom.IDENTITY_CHECK_PROMPT\n        )\n        \n        fact_checked_answer = await self.custom(\n            input=f\"Question: {problem}\\nIdentity-checked answer: {identity_check_answer['response']}\",\n            instruction=prompt_custom.FACT_CHECK_PROMPT\n        )\n        \n        style_check_answer = await self.custom(\n            input=f\"Question: {problem}\\nFact-checked answer: {fact_checked_answer['response']}\",\n            instruction=prompt_custom.STYLE_CHECK_PROMPT\n        )\n        \n        additional_verification = await self.custom(\n            input=f\"Question: {problem}\\nStyle-checked answer: {style_check_answer['response']}\",\n            instruction=prompt_custom.ADDITIONAL_VERIFICATION_PROMPT\n        )\n        \n        refined_solution = await self.custom(\n            input=f\"Question: {problem}\\nDouble-verified answer: {additional_verification['response']}\",\n            instruction=prompt_custom.FORMAT_ANSWER_PROMPT\n        )\n        \n        return refined_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>FORMAT_ANSWER_PROMPT = \"\"\"\nGiven the question and the double-verified answer, format the final answer to be extremely concise and directly addressing the question. Provide only the essential information without any explanation or additional context. For names, professions, or short phrases, give only that specific information.\n\nExamples:\n- For a person's name: \"John Doe\"\n- For a profession: \"Doctor\"\n- For a short phrase: \"Once in a blue moon\"\n\nDo not include any prefixes or explanatory text. Provide only the answer itself.\n\"\"\"\n\nNAME_EXTRACTION_PROMPT = \"\"\"\nGiven the question and the best answer, focus on extracting and verifying any names mentioned. Pay special attention to:\n\n1. Full names (first name, middle name, last name)\n2. Nicknames or aliases\n3. Correct spelling of names\n\nIf the answer contains a name, ensure it is accurate and complete. If a name is incorrect or incomplete, provide the correct full name. If no name is present or needed, simply restate the answer.\n\nProvide your response in a concise manner, focusing solely on the corrected or verified answer without additional explanations.\n\"\"\"\n\nENTITY_DISAMBIGUATION_PROMPT = \"\"\"\nGiven the question and the name-extracted answer, perform entity disambiguation to ensure the correct identification of individuals, companies, or other entities mentioned. Consider:\n\n1. Different entities with similar names\n2. Context-specific identities (e.g., a person's role in a specific project)\n3. Common misconceptions or frequently confused entities\n\nIf there's any ambiguity or potential misidentification, clarify the entity's identity based on the context of the question. If no disambiguation is needed, restate the answer.\n\nProvide your response in a concise manner, focusing solely on the disambiguated or verified answer without additional explanations.\n\"\"\"\n\nIDENTITY_CHECK_PROMPT = \"\"\"\nGiven the question and the disambiguated answer, perform a thorough identity check, especially for individuals who may have changed their names, use stage names, or have multiple identities. Consider:\n\n1. Birth names vs. stage names or pseudonyms\n2. Name changes due to personal reasons (e.g., marriage, gender transition)\n3. Professional names vs. legal names\n\nIf the answer involves a person's identity and there's a discrepancy or additional information about their name, provide the most accurate and relevant name based on the context of the question. If no changes are needed, restate the answer.\n\nProvide your response in a concise manner, focusing solely on the verified or corrected identity without additional explanations.\n\"\"\"\n\nFACT_CHECK_PROMPT = \"\"\"\nGiven the question and the identity-checked answer, carefully analyze the information provided and perform a fact-check. If you find any inconsistencies or errors in the answer, provide a corrected version. If the answer appears accurate, simply restate it. Focus on verifying key facts, names, dates, and other critical information related to the question.\n\nYour task:\n1. Analyze the question and the answer.\n2. Identify any potential errors or inconsistencies.\n3. If errors are found, provide a corrected answer.\n4. If no errors are found, restate the answer.\n\nProvide your response in a concise manner, focusing solely on the corrected or verified answer without additional explanations.\n\"\"\"\n\nSTYLE_CHECK_PROMPT = \"\"\"\nReview the fact-checked answer, focusing specifically on architectural and historical style terms. Verify the accuracy of any mentioned styles, ensuring they are correctly identified and placed in the proper historical context. Pay special attention to:\n\n1. Architectural styles (e.g., Gothic, Baroque, Neoclassical)\n2. Historical periods and their associated styles\n3. Relationships between different styles (e.g., which style influenced or preceded another)\n\nIf you find any errors or misidentifications in the architectural or historical style terms, provide a corrected version. If the answer is accurate, simply restate it. Be concise and direct in your response, providing only the verified or corrected answer without explanations.\n\"\"\"\n\nADDITIONAL_VERIFICATION_PROMPT = \"\"\"\nPerform an additional verification on the previously style-checked answer. Focus on:\n\n1. Consistency with the question\n2. Accuracy of specific details (names, dates, places, styles)\n3. Completeness of the answer\n4. Ensure the answer is a single word, number, or short phrase when appropriate\n\nIf any issues are found, provide a corrected version. If the answer is accurate and complete, restate it. Be concise and direct in your response, providing only the verified or corrected answer without explanations.\n\"\"\"\n\nMISSING_INFO_CHECK_PROMPT = \"\"\"\nAnalyze the given answer in the context of the question. Determine if any specific information requested in the question is missing from the answer. If information is missing, clearly state what is missing. If all requested information is present, simply restate the answer.\n\nFocus on:\n1. Names of people, places, or things\n2. Dates or time periods\n3. Numerical values or quantities\n4. Specific facts or details directly related to the question\n\nProvide a concise response, either restating the answer if complete or explicitly mentioning the missing information.\n\"\"\"\n\nINFER_MISSING_INFO_PROMPT = \"\"\"\nGiven the question and the current answer which lacks specific information, attempt to infer or deduce the missing details based on the context of the question and any available information. Consider:\n\n1. Common knowledge related to the topic\n2. Logical deductions based on the question's context\n3. Typical patterns or relationships in similar scenarios\n\nIf a reasonable inference can be made, provide it as the answer. If no reliable inference is possible, state that the specific information cannot be determined based on the available context.\n\nProvide a concise response, focusing solely on the inferred information or the statement that it cannot be determined.\n\"\"\"</prompt>", "tag": "HotpotQA", "domain": "llm_judge", "parent_round": 16, "child_round": 17, "parent_score": 0.6374542124542124, "child_score": 0.6311624649859944, "performance_gain": -0.006291747468218034}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.5294117647058824</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.round_10.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        # Use Programmer to generate and execute Python code\\n        code_solution = await self.programmer(problem=problem)\\n        \\n        # Use Custom to refine and format the answer\\n        refined_solution = await self.custom(input=problem + f\\\"\\\\nCode output: {code_solution['output']}\\\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\\n        \\n        # Generate multiple solutions using Custom\\n        solutions = []\\n        for _ in range(3):\\n            solution = await self.custom(input=problem, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        # Generate a step-by-step solution\\n        step_by_step = await self.custom(input=problem, instruction=prompt_custom.STEP_BY_STEP_PROMPT)\\n        solutions.append(step_by_step['response'])\\n        \\n        # Use ScEnsemble to select the most consistent and detailed solution\\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the mathematical problem and the output from the code execution, please provide a well-formatted and detailed solution. Follow these guidelines:\\n\\n1. Begin with a clear statement of the problem.\\n2. Explain the approach and any formulas or concepts used.\\n3. Show step-by-step calculations, using LaTeX notation for mathematical expressions.\\n4. Interpret the code output and incorporate it into your explanation.\\n5. Provide a final answer, enclosed in \\\\boxed{} LaTeX notation.\\n6. Ensure all mathematical notation is in LaTeX format.\\n\\nYour response should be comprehensive, mathematically rigorous, and easy to follow.\\n\\\"\\\"\\\"\\n\\nGENERATE_SOLUTION_PROMPT = \\\"\\\"\\\"\\nPlease solve the given mathematical problem step by step. Follow these guidelines:\\n\\n1. State the problem clearly.\\n2. Outline the approach and any relevant formulas or concepts.\\n3. Provide detailed calculations, using LaTeX notation for mathematical expressions.\\n4. Explain each step of your reasoning.\\n5. Present the final answer enclosed in \\\\boxed{} LaTeX notation.\\n6. Ensure all mathematical notation is in LaTeX format.\\n\\nYour solution should be thorough, mathematically sound, and easy to understand.\\n\\\"\\\"\\\"\\n\\nSTEP_BY_STEP_PROMPT = \\\"\\\"\\\"\\nProvide a detailed, step-by-step solution to the given mathematical problem. Follow these guidelines:\\n\\n1. Clearly state the problem and identify the key information given.\\n2. Break down the solution into logical steps, numbering each step.\\n3. For each step:\\n   a. Explain the reasoning behind the step.\\n   b. Show any calculations or transformations, using LaTeX notation for mathematical expressions.\\n   c. Provide intermediate results.\\n4. Use appropriate mathematical notation, formulas, and theorems, explaining them when first introduced.\\n5. Include visual aids (e.g., diagrams, graphs) if they help clarify the solution, describing them in LaTeX format.\\n6. Conclude with the final answer, enclosed in \\\\boxed{} LaTeX notation.\\n7. Add a brief explanation of the significance of the result or any important observations.\\n\\nEnsure your solution is clear, concise, and mathematically rigorous, suitable for a student learning the concept.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 11</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.round_11.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        # Use Programmer to generate and execute Python code\n        code_solution = await self.programmer(problem=problem)\n        \n        # Use Custom to refine and format the answer\n        refined_solution = await self.custom(input=problem + f\"\\nCode output: {code_solution['output']}\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n        \n        # Generate multiple solutions using Custom\n        solutions = []\n        for _ in range(3):\n            solution = await self.custom(input=problem, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT)\n            solutions.append(solution['response'])\n        \n        # Generate a detailed step-by-step solution\n        detailed_solution = await self.custom(input=problem, instruction=prompt_custom.DETAILED_SOLUTION_PROMPT)\n        solutions.append(detailed_solution['response'])\n        \n        # Generate an explanation-focused solution\n        explanation_solution = await self.custom(input=problem, instruction=prompt_custom.EXPLANATION_SOLUTION_PROMPT)\n        solutions.append(explanation_solution['response'])\n        \n        # Use ScEnsemble to select the best solution\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>REFINE_ANSWER_PROMPT = \"\"\"\nGiven the mathematical problem and the output from the code execution, please provide a well-formatted and detailed solution. Follow these guidelines:\n\n1. Begin with a clear statement of the problem.\n2. Explain the approach and any formulas or concepts used.\n3. Show step-by-step calculations, using LaTeX notation for mathematical expressions.\n4. Interpret the code output and incorporate it into your explanation.\n5. Provide a final answer, enclosed in \\boxed{} LaTeX notation.\n6. Ensure all mathematical notation is in LaTeX format.\n\nYour response should be comprehensive, mathematically rigorous, and easy to follow.\n\"\"\"\n\nGENERATE_SOLUTION_PROMPT = \"\"\"\nPlease solve the given mathematical problem step by step. Follow these guidelines:\n\n1. State the problem clearly.\n2. Outline the approach and any relevant formulas or concepts.\n3. Provide detailed calculations, using LaTeX notation for mathematical expressions.\n4. Explain each step of your reasoning.\n5. Present the final answer enclosed in \\boxed{} LaTeX notation.\n6. Ensure all mathematical notation is in LaTeX format.\n\nYour solution should be thorough, mathematically sound, and easy to understand.\n\"\"\"\n\nDETAILED_SOLUTION_PROMPT = \"\"\"\nProvide a comprehensive, step-by-step solution to the given mathematical problem. Your response should include:\n\n1. A clear restatement of the problem.\n2. An explanation of the mathematical concepts and formulas involved.\n3. A detailed, logical progression of steps to solve the problem.\n4. Clear explanations for each step, including the reasoning behind it.\n5. All mathematical expressions and equations in LaTeX format.\n6. Visual aids or diagrams if applicable (described in text).\n7. A final answer clearly marked and enclosed in \\boxed{} LaTeX notation.\n8. A brief explanation of the significance of the answer in the context of the original problem.\n\nAim for clarity, accuracy, and thoroughness in your solution.\n\"\"\"\n\nEXPLANATION_SOLUTION_PROMPT = \"\"\"\nProvide a solution to the given mathematical problem with a focus on explanations and understanding. Your response should include:\n\n1. A clear restatement of the problem.\n2. An in-depth explanation of the key mathematical concepts and principles involved.\n3. A step-by-step solution, emphasizing the reasoning behind each step.\n4. Clarification of any potential misconceptions or common errors related to the problem.\n5. All mathematical expressions and equations in LaTeX format.\n6. Analogies or real-world examples to illustrate the concepts, if applicable.\n7. A final answer clearly marked and enclosed in \\boxed{} LaTeX notation.\n8. A discussion on how this problem relates to broader mathematical topics or applications.\n\nYour goal is to not only solve the problem but also to enhance the reader's understanding of the underlying mathematical principles.\n\"\"\"</prompt>", "tag": "MATH", "domain": "llm_judge", "parent_round": 10, "child_round": 11, "parent_score": 0.5294117647058824, "child_score": 0.5378151260504201, "performance_gain": 0.008403361344537785}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve QA problems.\\nReferring to the given graph and prompt, which forms a basic example of a QA solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.7186274509803922</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_20.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.answer_generate = operator.AnswerGenerate(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):\\n            step_by_step = await self.answer_generate(input=problem)\\n            solution = await self.custom(input=f\\\"Question: {problem}\\\\nStep-by-step solution: {step_by_step['thought']}\\\\nInitial answer: {step_by_step['answer']}\\\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions)\\n        return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\\n\\n1. Ensure the answer is concise and directly addresses the question.\\n2. If the answer is a number, provide only the number without additional text.\\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\\n4. Remove any explanations or reasoning from the final answer.\\n5. Double-check the calculation and reasoning to ensure accuracy.\\n6. If the answer involves a range or multiple possibilities, include all valid options.\\n\\nYour task is to extract or refine the most accurate answer based on the provided information.\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 21</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_21.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.answer_generate = operator.AnswerGenerate(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):  # Generate 3 solutions\n            step_by_step = await self.answer_generate(input=problem)\n            refined_solution = await self.custom(input=f\"Question: {problem}\\nStep-by-step solution: {step_by_step['thought']}\\nInitial answer: {step_by_step['answer']}\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n            verified_solution = await self.custom(input=f\"Question: {problem}\\nRefined answer: {refined_solution['response']}\", instruction=prompt_custom.VERIFY_NUMERICAL_ANSWER_PROMPT)\n            solutions.append(verified_solution['response'])\n        \n        final_solution = await self.sc_ensemble(solutions=solutions)\n        return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>REFINE_ANSWER_PROMPT = \"\"\"\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\n\n1. Ensure the answer is concise and directly addresses the question.\n2. If the answer is a number, provide only the number without additional text.\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\n4. Remove any explanations or reasoning from the final answer.\n5. Double-check that the refined answer is consistent with the step-by-step solution and initial answer.\n6. If the answer involves selecting between options, clearly state the chosen option.\n\nYour task is to extract or refine the most accurate answer based on the provided information.\n\"\"\"\n\nVERIFY_NUMERICAL_ANSWER_PROMPT = \"\"\"\nGiven the question and the refined answer, please verify and correct the numerical answer if necessary. Follow these guidelines:\n\n1. Ensure the answer is a number or a set of numbers separated by a vertical bar (|).\n2. Remove any units, percentage signs, or additional text from the answer.\n3. If the answer should be a decimal, ensure it is properly formatted (e.g., 1.2 instead of 1.2%).\n4. If the answer involves a calculation, double-check the math to ensure accuracy.\n5. If the answer is correct and properly formatted, return it as is.\n6. If the answer needs correction, provide the corrected numerical answer.\n\nYour task is to verify and, if necessary, correct the numerical answer to ensure accuracy and proper formatting.\n\"\"\"</prompt>", "tag": "DROP", "domain": "llm_judge", "parent_round": 20, "child_round": 21, "parent_score": 0.7186274509803922, "child_score": 0.08460534248860409, "performance_gain": -0.6340221084917881}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.0</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.round_12.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        # Use Programmer to generate and execute Python code\\n        code_solution = await self.programmer(problem=problem)\\n        \\n        # Use Custom to refine and format the answer\\n        refined_solution = await self.custom(input=problem + f\\\"\\\\nCode output: {code_solution['output']}\\\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\\n        \\n        # Generate multiple solutions using Custom\\n        solutions = []\\n        for approach in ['algebraic', 'geometric', 'analytical']:\\n            solution = await self.custom(input=problem, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT.format(approach=approach))\\n            solutions.append(solution['response'])\\n        \\n        # Generate a detailed step-by-step solution\\n        detailed_solution = await self.custom(input=problem, instruction=prompt_custom.DETAILED_SOLUTION_PROMPT)\\n        solutions.append(detailed_solution['response'])\\n        \\n        # Use ScEnsemble to select the best solution\\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the mathematical problem and the output from the code execution, please provide a well-formatted and detailed solution. Follow these guidelines:\\n\\n1. Begin with a clear statement of the problem.\\n2. Explain the approach and any formulas or concepts used.\\n3. Show step-by-step calculations, using LaTeX notation for mathematical expressions.\\n4. Interpret the code output and incorporate it into your explanation.\\n5. Provide a final answer, enclosed in \\\\boxed{} LaTeX notation.\\n6. Ensure all mathematical notation is in LaTeX format.\\n\\nYour response should be comprehensive, mathematically rigorous, and easy to follow.\\n\\\"\\\"\\\"\\n\\nGENERATE_SOLUTION_PROMPT = \\\"\\\"\\\"\\nPlease solve the given mathematical problem using a {approach} approach. Follow these guidelines:\\n\\n1. State the problem clearly.\\n2. Outline the {approach} approach and any relevant formulas or concepts.\\n3. Provide detailed calculations, using LaTeX notation for mathematical expressions.\\n4. Explain each step of your reasoning.\\n5. Present the final answer enclosed in \\\\boxed{} LaTeX notation.\\n6. Ensure all mathematical notation is in LaTeX format.\\n\\nYour solution should be thorough, mathematically sound, and easy to understand.\\n\\\"\\\"\\\"\\n\\nDETAILED_SOLUTION_PROMPT = \\\"\\\"\\\"\\nProvide a comprehensive, step-by-step solution to the given mathematical problem. Your response should include:\\n\\n1. A clear restatement of the problem.\\n2. An explanation of the mathematical concepts and formulas involved.\\n3. A detailed, logical progression of steps to solve the problem.\\n4. Clear explanations for each step, including the reasoning behind it.\\n5. All mathematical expressions and equations in LaTeX format.\\n6. Visual aids or diagrams if applicable (described in text).\\n7. A final answer clearly marked and enclosed in \\\\boxed{} LaTeX notation.\\n8. A brief explanation of the significance of the answer in the context of the original problem.\\n\\nAim for clarity, accuracy, and thoroughness in your solution.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 13</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.round_13.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        # Use Programmer to generate and execute Python code\n        code_solution = await self.programmer(problem=problem)\n        \n        # Use Custom to generate a detailed step-by-step solution\n        detailed_solution = await self.custom(input=problem + f\"\\nCode output: {code_solution['output']}\", instruction=prompt_custom.DETAILED_SOLUTION_PROMPT)\n        \n        # Use Custom to refine and format the final answer\n        refined_solution = await self.custom(input=detailed_solution['response'], instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n        \n        # Generate multiple solutions using Custom\n        solutions = []\n        for _ in range(3):\n            solution = await self.custom(input=problem, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT)\n            solutions.append(solution['response'])\n        \n        # Use ScEnsemble to select the most consistent solution\n        final_solution = await self.sc_ensemble(solutions=solutions + [refined_solution['response']], problem=problem)\n        \n        return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>DETAILED_SOLUTION_PROMPT = \"\"\"\nPlease provide a detailed step-by-step solution for the given mathematical problem. Follow these guidelines:\n\n1. State the problem clearly.\n2. List all given information and identify what needs to be found.\n3. Outline the approach and any relevant formulas or concepts.\n4. Show all calculations in detail, using LaTeX notation for mathematical expressions.\n5. Explain each step of your reasoning.\n6. Interpret the code output (if provided) and incorporate it into your explanation.\n7. Present the final answer, enclosing it in \\boxed{} LaTeX notation.\n8. Ensure all mathematical notation is in LaTeX format.\n\nYour solution should be comprehensive, mathematically rigorous, and easy to follow.\n\"\"\"\n\nREFINE_ANSWER_PROMPT = \"\"\"\nGiven the detailed solution, please refine and format the answer. Follow these guidelines:\n\n1. Summarize the key steps of the solution process.\n2. Ensure all mathematical expressions are in correct LaTeX notation.\n3. Present the final answer clearly, enclosed in \\boxed{} LaTeX notation.\n4. If there are multiple possible answers, list all of them separated by commas within the \\boxed{}.\n5. Check for any logical inconsistencies or calculation errors.\n6. Simplify expressions where possible without losing accuracy.\n\nYour refined answer should be concise yet complete, mathematically accurate, and well-formatted.\n\"\"\"\n\nGENERATE_SOLUTION_PROMPT = \"\"\"\nPlease solve the given mathematical problem step by step. Follow these guidelines:\n\n1. State the problem clearly.\n2. Outline the approach and any relevant formulas or concepts.\n3. Provide detailed calculations, using LaTeX notation for mathematical expressions.\n4. Explain each step of your reasoning.\n5. Present the final answer enclosed in \\boxed{} LaTeX notation.\n6. Ensure all mathematical notation is in LaTeX format.\n\nYour solution should be thorough, mathematically sound, and easy to understand.\n\"\"\"</prompt>", "tag": "MATH", "domain": "llm_judge", "parent_round": 12, "child_round": 13, "parent_score": 0.0, "child_score": 0.5378151260504201, "performance_gain": 0.5378151260504201}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.87</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_15.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(5):  # Generate 5 solutions\\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        # Add a verification step using the Programmer operator\\n        verification = await self.programmer(problem=problem, analysis=final_solution['response'])\\n        \\n        # Double-check the final answer\\n        double_check = await self.custom(input=problem + f\\\"\\\\nInitial solution: {final_solution['response']}\\\\nVerification result: {verification['output']}\\\", instruction=prompt_custom.DOUBLE_CHECK_PROMPT)\\n        \\n        return double_check['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>MATH_SOLVE_PROMPT = \\\"\\\"\\\"\\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps carefully:\\n\\n1. Read and understand the problem thoroughly, ensuring you consider ALL given information.\\n2. Identify all key information, variables, and relationships, including any discounts or special conditions.\\n3. Determine the appropriate mathematical concepts, formulas, or equations to use.\\n4. Solve the problem step-by-step, showing all your work clearly.\\n5. Double-check your calculations and reasoning at each step.\\n6. Provide a clear and concise final answer.\\n7. Verify your solution by plugging it back into the original problem or using an alternative method if possible.\\n8. Explicitly calculate the total cost, including any discounts or special conditions mentioned in the problem.\\n\\nFormat your answer as follows:\\n- Use LaTeX notation for mathematical expressions where appropriate.\\n- Show each step of your solution process clearly.\\n- Clearly state your final answer at the end of your solution.\\n- Express numerical answers as precise values (avoid rounding unless specified).\\n- Ensure that your final answer is a single numerical value without any units or additional text.\\n- Do not include any explanatory text with your final answer, just the number itself.\\n\\nFor example, if the final answer is 42.5, your response should end with just:\\n42.5\\n\\nHere's the problem to solve:\\n\\n\\\"\\\"\\\"\\n\\nDOUBLE_CHECK_PROMPT = \\\"\\\"\\\"\\nYou are a meticulous math checker. Your task is to review the given problem, the initial solution, and the verification result. Then, determine the most accurate final answer.\\n\\nFollow these steps:\\n1. Carefully read the original problem, paying attention to all details and conditions.\\n2. Review the initial solution and the verification result.\\n3. If there are discrepancies, analyze both approaches to identify any errors or overlooked information.\\n4. Recalculate the problem yourself, ensuring all conditions and discounts are properly applied.\\n5. Provide the final, correct answer as a single numerical value without any units or additional text.\\n\\nRemember:\\n- Consider ALL information given in the problem, including any discounts or special conditions.\\n- Ensure that your calculations account for the entire problem, not just part of it.\\n- Double-check your math to avoid simple calculation errors.\\n- Your final answer should be a single number without any explanations.\\n\\nFor example, if the correct final answer is 123.0, your response should be just:\\n123.0\\n\\nHere's the problem and previous results to review:\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 16</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_16.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(5):  # Generate 5 solutions\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\n            solutions.append(solution['response'])\n        \n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Add a verification step using the Programmer operator\n        verification = await self.programmer(problem=problem, analysis=final_solution['response'])\n        \n        # Double-check the final answer with a focus on total cost calculation\n        double_check = await self.custom(input=problem + f\"\\nPrevious solution: {verification['output']}\", instruction=prompt_custom.DOUBLE_CHECK_PROMPT)\n        \n        if double_check['response'] != verification['output']:\n            return double_check['response'], self.llm.cost_manager.total_cost\n        else:\n            return verification['output'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>MATH_SOLVE_PROMPT = \"\"\"\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps carefully:\n\n1. Read and understand the problem thoroughly.\n2. Identify all key information, variables, and relationships.\n3. Determine the appropriate mathematical concepts, formulas, or equations to use.\n4. Solve the problem step-by-step, showing all your work clearly.\n5. Double-check your calculations and reasoning at each step.\n6. Provide a clear and concise final answer.\n7. Verify your solution by plugging it back into the original problem or using an alternative method if possible.\n\nFormat your answer as follows:\n- Use LaTeX notation for mathematical expressions where appropriate.\n- Show each step of your solution process clearly.\n- Clearly state your final answer at the end of your solution.\n- Express numerical answers as precise values (avoid rounding unless specified).\n- Ensure that your final answer is a single numerical value without any units or additional text.\n- Do not include any explanatory text with your final answer, just the number itself.\n\nFor example, if the final answer is 42.5, your response should end with just:\n42.5\n\nHere's the problem to solve:\n\n\"\"\"\n\nDOUBLE_CHECK_PROMPT = \"\"\"\nYou are a meticulous math problem solver. Your task is to double-check the solution to a given problem, focusing on total cost calculation and considering all given information, including discounts and multiple time periods if applicable.\n\n1. Carefully read the original problem.\n2. Review the previous solution provided.\n3. Pay special attention to:\n   - Total cost calculations\n   - Discounts or percentage-based calculations\n   - Multiple time periods or quantities\n   - Any information that might have been overlooked\n\n4. If you find any errors or discrepancies, recalculate the solution step-by-step.\n5. If the previous solution is correct, confirm it.\n\nProvide your final answer as a single numerical value without any units or additional text. For example:\n\n342.0\n\nHere's the original problem and the previous solution:\n\n\"\"\"</prompt>", "tag": "GSM8K", "domain": "llm_judge", "parent_round": 15, "child_round": 16, "parent_score": 0.87, "child_score": 0.89, "performance_gain": 0.020000000000000018}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>\\nPrevious failed modifications:\\n  - Add a step to generate multiple solutions using different prompts, then use the ScEnsemble operator to select the best solution. This will increase the chances of finding a correct solution by leveraging the ensemble approach. (Score: 0.9333333333333333)\\n  - Add a step to generate multiple solutions using the custom_code_generate operator, then use the ScEnsemble operator to select the best solution. This will increase the chances of finding a correct solution by leveraging the ensemble approach. (Score: 0.9266666666666667)</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.9</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_14.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        Custom operator to generate anything you want.\\n        But when you want to get standard code, you should use custom_code_generate operator.\\n        \\\"\\\"\\\"\\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=\\\"Generate a Python function to solve the given problem.\\\")\\n        \\n        # Review and improve the generated solution\\n        reviewed_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nGenerated solution: {solution['response']}\\\", instruction=prompt_custom.REVIEW_SOLUTION_PROMPT)\\n        \\n        # Test the reviewed solution\\n        test_result = await self.test(problem=problem, solution=reviewed_solution['response'], entry_point=entry_point)\\n        \\n        if test_result['result']:\\n            return test_result['solution'], self.llm.cost_manager.total_cost\\n        else:\\n            # If the test fails, try to improve the solution\\n            improved_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nFailed solution: {reviewed_solution['response']}\\\\nError: {test_result['solution']}\\\", instruction=prompt_custom.IMPROVE_SOLUTION_PROMPT)\\n            return improved_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>REVIEW_SOLUTION_PROMPT = \\\"\\\"\\\"\\nReview the given problem and the generated solution. Analyze the code for correctness, efficiency, and adherence to best practices. Improve the solution if necessary.\\n\\nYour task:\\n1. Understand the problem statement.\\n2. Review the generated solution.\\n3. Check for logical errors, edge cases, and potential improvements.\\n4. Rewrite the solution if improvements are needed, or keep it as is if it's optimal.\\n5. Ensure the final solution is complete, correct, and efficient.\\n\\nProvide only the reviewed and potentially improved Python function as your response, without any additional explanations or comments.\\n\\\"\\\"\\\"\\n\\nIMPROVE_SOLUTION_PROMPT = \\\"\\\"\\\"\\nAnalyze the given problem and the failed solution. Identify the errors and improve the code to solve the problem correctly. Make sure to handle edge cases and follow best practices in Python programming.\\n\\nYour task:\\n1. Understand the problem statement.\\n2. Review the failed solution and the error message.\\n3. Identify the cause of the failure.\\n4. Rewrite the solution, addressing the identified issues.\\n5. Ensure the new solution is complete, correct, and efficient.\\n\\nProvide only the improved Python function as your response, without any additional explanations or comments.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 15</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_15.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\n        \n        # Add a review step\n        review = await self.custom(input=f\"Problem: {problem}\\nGenerated solution: {solution['response']}\", instruction=prompt_custom.REVIEW_PROMPT)\n        \n        # If review suggests improvements, apply them\n        if \"No improvements needed\" not in review['response']:\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\"{prompt_custom.CODE_GENERATE_PROMPT}\\n\\nConsider these improvements: {review['response']}\")\n        \n        test_result = await self.test(problem=problem, solution=solution['response'], entry_point=entry_point)\n        \n        if not test_result['result']:\n            # Comprehensive analysis of the problem and failed solution\n            analysis = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {solution['response']}\\nTest result: {test_result['solution']}\", instruction=prompt_custom.COMPREHENSIVE_ANALYSIS_PROMPT)\n            \n            # Generate improved solution based on the comprehensive analysis\n            improved_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\"{prompt_custom.CODE_GENERATE_PROMPT}\\n\\nConsider this analysis: {analysis['response']}\")\n            \n            # Test the improved solution\n            improved_test_result = await self.test(problem=problem, solution=improved_solution['response'], entry_point=entry_point)\n            \n            if improved_test_result['result']:\n                return improved_solution['response'], self.llm.cost_manager.total_cost\n            else:\n                # If the improved solution still fails, return the original solution\n                return solution['response'], self.llm.cost_manager.total_cost\n        \n        return solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>CODE_GENERATE_PROMPT = \"\"\"\nGenerate a Python function that solves the given problem. Ensure the function signature matches the problem description. Include docstrings and comments to explain the logic. The solution should be efficient and handle edge cases.\n\"\"\"\n\nREVIEW_PROMPT = \"\"\"\nReview the generated solution for the given problem. Check for:\n1. Correctness: Does the solution solve the problem as described?\n2. Efficiency: Is the solution optimized for performance?\n3. Readability: Is the code well-structured and easy to understand?\n4. Edge cases: Are all possible scenarios handled?\n5. Python best practices: Does the code follow PEP 8 and other Python conventions?\n\nIf improvements are needed, provide specific suggestions. If no improvements are needed, state \"No improvements needed\".\n\"\"\"\n\nCOMPREHENSIVE_ANALYSIS_PROMPT = \"\"\"\nPerform a comprehensive analysis of the problem and the failed solution. Consider the following aspects:\n\n1. Problem understanding: Identify any potential misinterpretations of the problem statement.\n2. Logical errors: Pinpoint any flaws in the solution's logic or algorithm.\n3. Edge cases: Determine if all possible input scenarios are properly handled.\n4. Efficiency: Evaluate the time and space complexity of the solution.\n5. Coding style: Assess the readability and adherence to Python best practices.\n6. Test case failures: Analyze why specific test cases are failing.\n7. Alternative approaches: Suggest different algorithms or data structures that might be more suitable.\n\nProvide a detailed breakdown of these aspects and suggest specific improvements for each identified issue.\n\"\"\"</prompt>", "tag": "HumanEval", "domain": "llm_judge", "parent_round": 14, "child_round": 15, "parent_score": 0.9, "child_score": 0.9, "performance_gain": 0.0}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>Previous successful modifications:\\n  - Add a more comprehensive analysis step using the Custom operator before generating the improved solution. This will provide a more detailed breakdown of the problem and failed solution, leading to better improvements. (Score: 0.9266666666666667)\\n\\nPrevious failed modifications:\\n  - Add a self-review step using the Custom operator to analyze and improve the generated solution before testing it. This can help catch potential errors and optimize the code before running the test cases. (Score: 0.8666666666666666)\\n  - Add a review step using the Custom operator to analyze and improve the generated solution before testing it. This can help catch potential errors and optimize the code before running the test cases. (Score: 0.8533333333333333)</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.9</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_2.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        Custom operator to generate anything you want.\\n        But when you want to get standard code, you should use custom_code_generate operator.\\n        \\\"\\\"\\\"\\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\\n        test_result = await self.test(problem=problem, solution=solution['response'], entry_point=entry_point)\\n        \\n        if not test_result['result']:\\n            # If the test fails, use Custom to analyze and improve the solution\\n            analysis = await self.custom(input=f\\\"Problem: {problem}\\\\nFailed solution: {solution['response']}\\\\nTest result: {test_result['solution']}\\\", instruction=prompt_custom.ANALYZE_AND_IMPROVE_PROMPT)\\n            improved_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\\\"{prompt_custom.CODE_GENERATE_PROMPT}\\\\n\\\\nConsider this analysis: {analysis['response']}\\\")\\n            return improved_solution['response'], self.llm.cost_manager.total_cost\\n        \\n        return solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>CODE_GENERATE_PROMPT = \\\"\\\"\\\"\\nGenerate a Python function that solves the given problem. Ensure the function signature matches the problem description. Include docstrings and comments to explain the logic. The solution should be efficient and handle edge cases.\\n\\\"\\\"\\\"\\n\\nANALYZE_AND_IMPROVE_PROMPT = \\\"\\\"\\\"\\nAnalyze the failed solution and provide suggestions for improvement. Consider the following:\\n1. Identify logical errors or misunderstandings of the problem.\\n2. Check for edge cases that might not be handled correctly.\\n3. Suggest optimizations or alternative approaches if applicable.\\n4. Provide specific code snippets or pseudocode to address the issues found.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 3</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_3.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        \"\"\"\n        Implementation of the graph\n        Custom operator to generate anything you want.\n        But when you want to get standard code, you should use custom_code_generate operator.\n        \"\"\"\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=\"\")\n        \n        # Add a review step using the Custom operator\n        review_result = await self.custom(input=f\"Problem: {problem}\\nGenerated Solution: {solution['response']}\", instruction=prompt_custom.REVIEW_PROMPT)\n        \n        if \"Improved Solution:\" in review_result['response']:\n            final_solution = review_result['response'].split(\"Improved Solution:\")[1].strip()\n        else:\n            final_solution = solution['response']\n        \n        return final_solution, self.llm.cost_manager.total_cost\n</graph>\n<prompt>REVIEW_PROMPT = \"\"\"\nReview the following problem and the generated solution. If you find any issues or potential improvements, provide an improved solution. If the solution is already optimal, state that no improvements are needed.\n\nProblem: {input}\n\nYour response should be in the following format:\nReview: [Your review comments]\nImproved Solution: [The improved solution if any, or \"No improvements needed\" if the original solution is optimal]\n\nEnsure that your review is thorough and that any improved solution addresses the problem correctly and efficiently.\n\"\"\"</prompt>", "tag": "HumanEval", "domain": "llm_judge", "parent_round": 2, "child_round": 3, "parent_score": 0.9, "child_score": 0.7333333333333333, "performance_gain": -0.16666666666666674}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.8255813953488372</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_13.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        # Generate test cases\\n        test_cases = await self.custom(input=problem, instruction=prompt_custom.GENERATE_TEST_CASES_PROMPT)\\n        \\n        solutions = []\\n        for _ in range(3):  # Generate 3 solutions\\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT + f\\\"\\\\nTest cases to consider:\\\\n{test_cases['response']}\\\")\\n            solutions.append(solution['response'])\\n        \\n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        test_result = await self.test(problem=problem, solution=best_solution['response'], entry_point=entry_point)\\n        \\n        if test_result['result']:\\n            return test_result['solution'], self.llm.cost_manager.total_cost\\n        else:\\n            fixed_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nFailed solution: {best_solution['response']}\\\\nError: {test_result['solution']}\\\\nTest cases: {test_cases['response']}\\\", instruction=prompt_custom.FIX_CODE_PROMPT)\\n            return fixed_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>CODE_GENERATE_PROMPT = \\\"\\\"\\\"\\nGenerate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity. Consider the provided test cases when implementing the solution.\\n\\nProblem:\\n{problem}\\n\\nFunction signature:\\n{entry_point}\\n\\nGenerate the complete function below:\\n\\\"\\\"\\\"\\n\\nFIX_CODE_PROMPT = \\\"\\\"\\\"\\nThe provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation. Consider the provided test cases when fixing the code.\\n\\nProblem:\\n{input}\\n\\nProvide the corrected function below:\\n\\\"\\\"\\\"\\n\\nGENERATE_TEST_CASES_PROMPT = \\\"\\\"\\\"\\nGenerate a set of diverse test cases for the given problem. Include edge cases, typical cases, and any special scenarios that should be considered. Format the test cases as Python assert statements.\\n\\nProblem:\\n{input}\\n\\nGenerate test cases below:\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 14</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_14.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        \"\"\"\n        Implementation of the graph\n        Custom operator to generate anything you want.\n        But when you want to get standard code, you should use custom_code_generate operator.\n        \"\"\"\n        solutions = []\n        for _ in range(3):  # Generate 3 solutions\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\n            solutions.append(solution['response'])\n        \n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        test_result = await self.test(problem=problem, solution=best_solution['response'], entry_point=entry_point)\n        \n        if test_result['result']:\n            return test_result['solution'], self.llm.cost_manager.total_cost\n        else:\n            # If the test fails, try to fix the solution\n            fixed_solution = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {best_solution['response']}\\nError: {test_result['solution']}\", instruction=prompt_custom.FIX_CODE_PROMPT)\n            return fixed_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>CODE_GENERATE_PROMPT = \"\"\"\nGenerate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity.\n\nProblem:\n{problem}\n\nFunction signature:\n{entry_point}\n\nGenerate the complete function below:\n\"\"\"\n\nFIX_CODE_PROMPT = \"\"\"\nThe provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation.\n\nProblem:\n{input}\n\nProvide the corrected function below:\n\"\"\"</prompt>", "tag": "MBPP", "domain": "llm_judge", "parent_round": 13, "child_round": 14, "parent_score": 0.8255813953488372, "child_score": 0.8488372093023255, "performance_gain": 0.023255813953488302}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.7674418604651163</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_16.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        solutions = []\\n        for _ in range(3):  # Generate 3 solutions\\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        # Add code review step\\n        reviewed_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nSolution: {best_solution['response']}\\\", instruction=prompt_custom.CODE_REVIEW_PROMPT)\\n        \\n        test_result = await self.test(problem=problem, solution=reviewed_solution['response'], entry_point=entry_point)\\n        \\n        if test_result['result']:\\n            return test_result['solution'], self.llm.cost_manager.total_cost\\n        else:\\n            # If the test fails, try to fix the solution\\n            fixed_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nFailed solution: {reviewed_solution['response']}\\\\nError: {test_result['solution']}\\\", instruction=prompt_custom.FIX_CODE_PROMPT)\\n            return fixed_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>CODE_GENERATE_PROMPT = \\\"\\\"\\\"\\nGenerate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity.\\n\\nProblem:\\n{problem}\\n\\nFunction signature:\\n{entry_point}\\n\\nGenerate the complete function below:\\n\\\"\\\"\\\"\\n\\nCODE_REVIEW_PROMPT = \\\"\\\"\\\"\\nReview and improve the given Python code solution. Ensure it follows best practices, is efficient, and correctly solves the problem. Make any necessary improvements while maintaining the original function name and signature.\\n\\nProblem:\\n{input}\\n\\nProvide the improved function below:\\n\\\"\\\"\\\"\\n\\nFIX_CODE_PROMPT = \\\"\\\"\\\"\\nThe provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation.\\n\\nProblem:\\n{input}\\n\\nProvide the corrected function below:\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 17</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_17.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        \"\"\"\n        Implementation of the graph\n        Custom operator to generate anything you want.\n        But when you want to get standard code, you should use custom_code_generate operator.\n        \"\"\"\n        solutions = []\n        for _ in range(3):  # Generate 3 solutions\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\n            solutions.append(solution['response'])\n        \n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        test_result = await self.test(problem=problem, solution=best_solution['response'], entry_point=entry_point)\n        \n        if test_result['result']:\n            return test_result['solution'], self.llm.cost_manager.total_cost\n        else:\n            # If the test fails, try to fix the solution\n            fixed_solution = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {best_solution['response']}\\nError: {test_result['solution']}\", instruction=prompt_custom.FIX_CODE_PROMPT)\n            return fixed_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>CODE_GENERATE_PROMPT = \"\"\"\nGenerate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity.\n\nProblem:\n{problem}\n\nFunction signature:\n{entry_point}\n\nGenerate the complete function below:\n\"\"\"\n\nFIX_CODE_PROMPT = \"\"\"\nThe provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation.\n\nProblem:\n{input}\n\nProvide the corrected function below:\n\"\"\"</prompt>", "tag": "MBPP", "domain": "llm_judge", "parent_round": 16, "child_round": 17, "parent_score": 0.7674418604651163, "child_score": 0.8488372093023255, "performance_gain": 0.08139534883720922}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.5378151260504201</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.round_10.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        # Use Programmer to generate and execute Python code\\n        code_solution = await self.programmer(problem=problem)\\n        \\n        # Use Custom to refine and format the answer\\n        refined_solution = await self.custom(input=problem + f\\\"\\\\nCode output: {code_solution['output']}\\\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\\n        \\n        # Generate multiple solutions using Custom\\n        solutions = []\\n        for _ in range(3):\\n            solution = await self.custom(input=problem, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        # Generate a step-by-step solution\\n        step_by_step = await self.custom(input=problem, instruction=prompt_custom.STEP_BY_STEP_PROMPT)\\n        solutions.append(step_by_step['response'])\\n        \\n        # Use ScEnsemble to select the most consistent and detailed solution\\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the mathematical problem and the output from the code execution, please provide a well-formatted and detailed solution. Follow these guidelines:\\n\\n1. Begin with a clear statement of the problem.\\n2. Explain the approach and any formulas or concepts used.\\n3. Show step-by-step calculations, using LaTeX notation for mathematical expressions.\\n4. Interpret the code output and incorporate it into your explanation.\\n5. Provide a final answer, enclosed in \\\\boxed{} LaTeX notation.\\n6. Ensure all mathematical notation is in LaTeX format.\\n\\nYour response should be comprehensive, mathematically rigorous, and easy to follow.\\n\\\"\\\"\\\"\\n\\nGENERATE_SOLUTION_PROMPT = \\\"\\\"\\\"\\nPlease solve the given mathematical problem step by step. Follow these guidelines:\\n\\n1. State the problem clearly.\\n2. Outline the approach and any relevant formulas or concepts.\\n3. Provide detailed calculations, using LaTeX notation for mathematical expressions.\\n4. Explain each step of your reasoning.\\n5. Present the final answer enclosed in \\\\boxed{} LaTeX notation.\\n6. Ensure all mathematical notation is in LaTeX format.\\n\\nYour solution should be thorough, mathematically sound, and easy to understand.\\n\\\"\\\"\\\"\\n\\nSTEP_BY_STEP_PROMPT = \\\"\\\"\\\"\\nProvide a detailed, step-by-step solution to the given mathematical problem. Follow these guidelines:\\n\\n1. Clearly state the problem and identify the key information given.\\n2. Break down the solution into logical steps, numbering each step.\\n3. For each step:\\n   a. Explain the reasoning behind the step.\\n   b. Show any calculations or transformations, using LaTeX notation for mathematical expressions.\\n   c. Provide intermediate results.\\n4. Use appropriate mathematical notation, formulas, and theorems, explaining them when first introduced.\\n5. Include visual aids (e.g., diagrams, graphs) if they help clarify the solution, describing them in LaTeX format.\\n6. Conclude with the final answer, enclosed in \\\\boxed{} LaTeX notation.\\n7. Add a brief explanation of the significance of the result or any important observations.\\n\\nEnsure your solution is clear, concise, and mathematically rigorous, suitable for a student learning the concept.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 11</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.round_11.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        # Use Programmer to generate and execute Python code\n        code_solution = await self.programmer(problem=problem)\n        \n        # Use Custom to refine and format the answer\n        refined_solution = await self.custom(input=problem + f\"\\nCode output: {code_solution['output']}\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n        \n        # Generate multiple solutions using Custom\n        solutions = []\n        for _ in range(3):\n            solution = await self.custom(input=problem, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT)\n            solutions.append(solution['response'])\n        \n        # Generate a detailed step-by-step solution\n        detailed_solution = await self.custom(input=problem, instruction=prompt_custom.DETAILED_SOLUTION_PROMPT)\n        solutions.append(detailed_solution['response'])\n        \n        # Generate an explanation-focused solution\n        explanation_solution = await self.custom(input=problem, instruction=prompt_custom.EXPLANATION_SOLUTION_PROMPT)\n        solutions.append(explanation_solution['response'])\n        \n        # Use ScEnsemble to select the best solution\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>REFINE_ANSWER_PROMPT = \"\"\"\nGiven the mathematical problem and the output from the code execution, please provide a well-formatted and detailed solution. Follow these guidelines:\n\n1. Begin with a clear statement of the problem.\n2. Explain the approach and any formulas or concepts used.\n3. Show step-by-step calculations, using LaTeX notation for mathematical expressions.\n4. Interpret the code output and incorporate it into your explanation.\n5. Provide a final answer, enclosed in \\boxed{} LaTeX notation.\n6. Ensure all mathematical notation is in LaTeX format.\n\nYour response should be comprehensive, mathematically rigorous, and easy to follow.\n\"\"\"\n\nGENERATE_SOLUTION_PROMPT = \"\"\"\nPlease solve the given mathematical problem step by step. Follow these guidelines:\n\n1. State the problem clearly.\n2. Outline the approach and any relevant formulas or concepts.\n3. Provide detailed calculations, using LaTeX notation for mathematical expressions.\n4. Explain each step of your reasoning.\n5. Present the final answer enclosed in \\boxed{} LaTeX notation.\n6. Ensure all mathematical notation is in LaTeX format.\n\nYour solution should be thorough, mathematically sound, and easy to understand.\n\"\"\"\n\nDETAILED_SOLUTION_PROMPT = \"\"\"\nProvide a comprehensive, step-by-step solution to the given mathematical problem. Your response should include:\n\n1. A clear restatement of the problem.\n2. An explanation of the mathematical concepts and formulas involved.\n3. A detailed, logical progression of steps to solve the problem.\n4. Clear explanations for each step, including the reasoning behind it.\n5. All mathematical expressions and equations in LaTeX format.\n6. Visual aids or diagrams if applicable (described in text).\n7. A final answer clearly marked and enclosed in \\boxed{} LaTeX notation.\n8. A brief explanation of the significance of the answer in the context of the original problem.\n\nAim for clarity, accuracy, and thoroughness in your solution.\n\"\"\"\n\nEXPLANATION_SOLUTION_PROMPT = \"\"\"\nProvide a solution to the given mathematical problem with a focus on explanations and understanding. Your response should include:\n\n1. A clear restatement of the problem.\n2. An in-depth explanation of the key mathematical concepts and principles involved.\n3. A step-by-step solution, emphasizing the reasoning behind each step.\n4. Clarification of any potential misconceptions or common errors related to the problem.\n5. All mathematical expressions and equations in LaTeX format.\n6. Analogies or real-world examples to illustrate the concepts, if applicable.\n7. A final answer clearly marked and enclosed in \\boxed{} LaTeX notation.\n8. A discussion on how this problem relates to broader mathematical topics or applications.\n\nYour goal is to not only solve the problem but also to enhance the reader's understanding of the underlying mathematical principles.\n\"\"\"</prompt>", "tag": "MATH", "domain": "llm_judge", "parent_round": 10, "child_round": 11, "parent_score": 0.5378151260504201, "child_score": 0.5378151260504201, "performance_gain": 0.0}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.8488372093023255</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_15.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        solutions = []\\n        for _ in range(3):\\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        test_result = await self.test(problem=problem, solution=best_solution['response'], entry_point=entry_point)\\n        \\n        if test_result['result']:\\n            return test_result['solution'], self.llm.cost_manager.total_cost\\n        else:\\n            fixed_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nFailed solution: {best_solution['response']}\\\\nError: {test_result['solution']}\\\", instruction=prompt_custom.FIX_CODE_PROMPT)\\n            return fixed_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>CODE_GENERATE_PROMPT = \\\"\\\"\\\"\\nGenerate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity.\\n\\nProblem:\\n{problem}\\n\\nFunction signature:\\n{entry_point}\\n\\nGenerate the complete function below:\\n\\\"\\\"\\\"\\n\\nFIX_CODE_PROMPT = \\\"\\\"\\\"\\nThe provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation.\\n\\nProblem:\\n{input}\\n\\nProvide the corrected function below:\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 16</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_16.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        solutions = []\n        for _ in range(3):  # Generate 3 solutions\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\n            solutions.append(solution['response'])\n        \n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Add code review step\n        reviewed_solution = await self.custom(input=f\"Problem: {problem}\\nSolution: {best_solution['response']}\", instruction=prompt_custom.CODE_REVIEW_PROMPT)\n        \n        test_result = await self.test(problem=problem, solution=reviewed_solution['response'], entry_point=entry_point)\n        \n        if test_result['result']:\n            return test_result['solution'], self.llm.cost_manager.total_cost\n        else:\n            # If the test fails, try to fix the solution\n            fixed_solution = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {reviewed_solution['response']}\\nError: {test_result['solution']}\", instruction=prompt_custom.FIX_CODE_PROMPT)\n            return fixed_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>CODE_GENERATE_PROMPT = \"\"\"\nGenerate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity.\n\nProblem:\n{problem}\n\nFunction signature:\n{entry_point}\n\nGenerate the complete function below:\n\"\"\"\n\nCODE_REVIEW_PROMPT = \"\"\"\nReview and improve the given Python code solution. Ensure it follows best practices, is efficient, and correctly solves the problem. Make any necessary improvements while maintaining the original function name and signature.\n\nProblem:\n{input}\n\nProvide the improved function below:\n\"\"\"\n\nFIX_CODE_PROMPT = \"\"\"\nThe provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation.\n\nProblem:\n{input}\n\nProvide the corrected function below:\n\"\"\"</prompt>", "tag": "MBPP", "domain": "llm_judge", "parent_round": 15, "child_round": 16, "parent_score": 0.8488372093023255, "child_score": 0.8023255813953488, "performance_gain": -0.046511627906976716}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve QA problems.\\nReferring to the given graph and prompt, which forms a basic example of a QA solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>Previous successful modifications:\\n  - Add a new custom operator for profession verification to address the issue with identifying professions accurately, as seen in the \\\"John Lanchester and Alan Dean Foster\\\" error. This will be placed after the identity check step and before the fact check step. (Score: 0.6326012712777418)\\n  - Add a new custom operator for entity disambiguation to address the issue with misidentifying names and entities, as seen in the \\\"Steven Spielberg\\\" error. This will be placed after the name extraction step and before the identity check. (Score: 0.6201203698262521)</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.6155738052796876</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.round_14.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.answer_generate = operator.AnswerGenerate(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):\\n            initial_response = await self.answer_generate(input=problem)\\n            thought_process = initial_response['thought']\\n            initial_answer = initial_response['answer']\\n            solutions.append(initial_answer)\\n\\n        ensemble_result = await self.sc_ensemble(solutions=solutions)\\n        best_answer = ensemble_result['response']\\n        \\n        name_extracted_answer = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nBest answer: {best_answer}\\\",\\n            instruction=prompt_custom.NAME_EXTRACTION_PROMPT\\n        )\\n        \\n        identity_check_answer = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nName-extracted answer: {name_extracted_answer['response']}\\\",\\n            instruction=prompt_custom.IDENTITY_CHECK_PROMPT\\n        )\\n        \\n        fact_checked_answer = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nIdentity-checked answer: {identity_check_answer['response']}\\\",\\n            instruction=prompt_custom.FACT_CHECK_PROMPT\\n        )\\n        \\n        style_check_answer = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nFact-checked answer: {fact_checked_answer['response']}\\\",\\n            instruction=prompt_custom.STYLE_CHECK_PROMPT\\n        )\\n        \\n        additional_verification = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nStyle-checked answer: {style_check_answer['response']}\\\",\\n            instruction=prompt_custom.ADDITIONAL_VERIFICATION_PROMPT\\n        )\\n        \\n        refined_solution = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nDouble-verified answer: {additional_verification['response']}\\\",\\n            instruction=prompt_custom.FORMAT_ANSWER_PROMPT\\n        )\\n        \\n        return refined_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>FORMAT_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question and the double-verified answer, format the final answer to be extremely concise and directly addressing the question. Provide only the essential information without any explanation or additional context. For names, professions, or short phrases, give only that specific information.\\n\\nExamples:\\n- For a person's name: \\\"John Doe\\\"\\n- For a profession: \\\"Doctor\\\"\\n- For a short phrase: \\\"Once in a blue moon\\\"\\n\\nDo not include any prefixes or explanatory text. Provide only the answer itself.\\n\\\"\\\"\\\"\\n\\nNAME_EXTRACTION_PROMPT = \\\"\\\"\\\"\\nGiven the question and the best answer, focus on extracting and verifying any names mentioned. Pay special attention to:\\n\\n1. Full names (first name, middle name, last name)\\n2. Nicknames or aliases\\n3. Correct spelling of names\\n\\nIf the answer contains a name, ensure it is accurate and complete. If a name is incorrect or incomplete, provide the correct full name. If no name is present or needed, simply restate the answer.\\n\\nProvide your response in a concise manner, focusing solely on the corrected or verified answer without additional explanations.\\n\\\"\\\"\\\"\\n\\nIDENTITY_CHECK_PROMPT = \\\"\\\"\\\"\\nGiven the question and the name-extracted answer, perform a thorough identity check, especially for individuals who may have changed their names, use stage names, or have multiple identities. Consider:\\n\\n1. Birth names vs. stage names or pseudonyms\\n2. Name changes due to personal reasons (e.g., marriage, gender transition)\\n3. Professional names vs. legal names\\n\\nIf the answer involves a person's identity and there's a discrepancy or additional information about their name, provide the most accurate and relevant name based on the context of the question. If no changes are needed, restate the answer.\\n\\nProvide your response in a concise manner, focusing solely on the verified or corrected identity without additional explanations.\\n\\\"\\\"\\\"\\n\\nFACT_CHECK_PROMPT = \\\"\\\"\\\"\\nGiven the question and the identity-checked answer, carefully analyze the information provided and perform a fact-check. If you find any inconsistencies or errors in the answer, provide a corrected version. If the answer appears accurate, simply restate it. Focus on verifying key facts, names, dates, and other critical information related to the question.\\n\\nYour task:\\n1. Analyze the question and the answer.\\n2. Identify any potential errors or inconsistencies.\\n3. If errors are found, provide a corrected answer.\\n4. If no errors are found, restate the answer.\\n\\nProvide your response in a concise manner, focusing solely on the corrected or verified answer without additional explanations.\\n\\\"\\\"\\\"\\n\\nSTYLE_CHECK_PROMPT = \\\"\\\"\\\"\\nReview the fact-checked answer, focusing specifically on architectural and historical style terms. Verify the accuracy of any mentioned styles, ensuring they are correctly identified and placed in the proper historical context. Pay special attention to:\\n\\n1. Architectural styles (e.g., Gothic, Baroque, Neoclassical)\\n2. Historical periods and their associated styles\\n3. Relationships between different styles (e.g., which style influenced or preceded another)\\n\\nIf you find any errors or misidentifications in the architectural or historical style terms, provide a corrected version. If the answer is accurate, simply restate it. Be concise and direct in your response, providing only the verified or corrected answer without explanations.\\n\\\"\\\"\\\"\\n\\nADDITIONAL_VERIFICATION_PROMPT = \\\"\\\"\\\"\\nPerform an additional verification on the previously style-checked answer. Focus on:\\n\\n1. Consistency with the question\\n2. Accuracy of specific details (names, dates, places, styles)\\n3. Completeness of the answer\\n4. Ensure the answer is a single word, number, or short phrase when appropriate\\n\\nIf any issues are found, provide a corrected version. If the answer is accurate and complete, restate it. Be concise and direct in your response, providing only the verified or corrected answer without explanations.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Add a new custom operator for entity disambiguation to address the issue with misidentifying names and entities, as seen in the \"Steven Spielberg\" error. This will be placed after the name extraction step and before the identity check.</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.round_15.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.answer_generate = operator.AnswerGenerate(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):\n            initial_response = await self.answer_generate(input=problem)\n            thought_process = initial_response['thought']\n            initial_answer = initial_response['answer']\n            solutions.append(initial_answer)\n\n        ensemble_result = await self.sc_ensemble(solutions=solutions)\n        best_answer = ensemble_result['response']\n        \n        name_extracted_answer = await self.custom(\n            input=f\"Question: {problem}\\nBest answer: {best_answer}\",\n            instruction=prompt_custom.NAME_EXTRACTION_PROMPT\n        )\n        \n        disambiguated_answer = await self.custom(\n            input=f\"Question: {problem}\\nName-extracted answer: {name_extracted_answer['response']}\",\n            instruction=prompt_custom.ENTITY_DISAMBIGUATION_PROMPT\n        )\n        \n        identity_check_answer = await self.custom(\n            input=f\"Question: {problem}\\nDisambiguated answer: {disambiguated_answer['response']}\",\n            instruction=prompt_custom.IDENTITY_CHECK_PROMPT\n        )\n        \n        fact_checked_answer = await self.custom(\n            input=f\"Question: {problem}\\nIdentity-checked answer: {identity_check_answer['response']}\",\n            instruction=prompt_custom.FACT_CHECK_PROMPT\n        )\n        \n        style_check_answer = await self.custom(\n            input=f\"Question: {problem}\\nFact-checked answer: {fact_checked_answer['response']}\",\n            instruction=prompt_custom.STYLE_CHECK_PROMPT\n        )\n        \n        additional_verification = await self.custom(\n            input=f\"Question: {problem}\\nStyle-checked answer: {style_check_answer['response']}\",\n            instruction=prompt_custom.ADDITIONAL_VERIFICATION_PROMPT\n        )\n        \n        refined_solution = await self.custom(\n            input=f\"Question: {problem}\\nDouble-verified answer: {additional_verification['response']}\",\n            instruction=prompt_custom.FORMAT_ANSWER_PROMPT\n        )\n        \n        return refined_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>FORMAT_ANSWER_PROMPT = \"\"\"\nGiven the question and the double-verified answer, format the final answer to be extremely concise and directly addressing the question. Provide only the essential information without any explanation or additional context. For names, professions, or short phrases, give only that specific information.\n\nExamples:\n- For a person's name: \"John Doe\"\n- For a profession: \"Doctor\"\n- For a short phrase: \"Once in a blue moon\"\n\nDo not include any prefixes or explanatory text. Provide only the answer itself.\n\"\"\"\n\nNAME_EXTRACTION_PROMPT = \"\"\"\nGiven the question and the best answer, focus on extracting and verifying any names mentioned. Pay special attention to:\n\n1. Full names (first name, middle name, last name)\n2. Nicknames or aliases\n3. Correct spelling of names\n\nIf the answer contains a name, ensure it is accurate and complete. If a name is incorrect or incomplete, provide the correct full name. If no name is present or needed, simply restate the answer.\n\nProvide your response in a concise manner, focusing solely on the corrected or verified answer without additional explanations.\n\"\"\"\n\nENTITY_DISAMBIGUATION_PROMPT = \"\"\"\nGiven the question and the name-extracted answer, perform entity disambiguation to ensure the correct identification of individuals, companies, or other entities mentioned. Consider:\n\n1. Different entities with similar names\n2. Context-specific identities (e.g., a person's role in a specific project)\n3. Common misconceptions or frequently confused entities\n\nIf there's any ambiguity or potential misidentification, clarify the entity's identity based on the context of the question. If no disambiguation is needed, restate the answer.\n\nProvide your response in a concise manner, focusing solely on the disambiguated or verified answer without additional explanations.\n\"\"\"\n\nIDENTITY_CHECK_PROMPT = \"\"\"\nGiven the question and the disambiguated answer, perform a thorough identity check, especially for individuals who may have changed their names, use stage names, or have multiple identities. Consider:\n\n1. Birth names vs. stage names or pseudonyms\n2. Name changes due to personal reasons (e.g., marriage, gender transition)\n3. Professional names vs. legal names\n\nIf the answer involves a person's identity and there's a discrepancy or additional information about their name, provide the most accurate and relevant name based on the context of the question. If no changes are needed, restate the answer.\n\nProvide your response in a concise manner, focusing solely on the verified or corrected identity without additional explanations.\n\"\"\"\n\nFACT_CHECK_PROMPT = \"\"\"\nGiven the question and the identity-checked answer, carefully analyze the information provided and perform a fact-check. If you find any inconsistencies or errors in the answer, provide a corrected version. If the answer appears accurate, simply restate it. Focus on verifying key facts, names, dates, and other critical information related to the question.\n\nYour task:\n1. Analyze the question and the answer.\n2. Identify any potential errors or inconsistencies.\n3. If errors are found, provide a corrected answer.\n4. If no errors are found, restate the answer.\n\nProvide your response in a concise manner, focusing solely on the corrected or verified answer without additional explanations.\n\"\"\"\n\nSTYLE_CHECK_PROMPT = \"\"\"\nReview the fact-checked answer, focusing specifically on architectural and historical style terms. Verify the accuracy of any mentioned styles, ensuring they are correctly identified and placed in the proper historical context. Pay special attention to:\n\n1. Architectural styles (e.g., Gothic, Baroque, Neoclassical)\n2. Historical periods and their associated styles\n3. Relationships between different styles (e.g., which style influenced or preceded another)\n\nIf you find any errors or misidentifications in the architectural or historical style terms, provide a corrected version. If the answer is accurate, simply restate it. Be concise and direct in your response, providing only the verified or corrected answer without explanations.\n\"\"\"\n\nADDITIONAL_VERIFICATION_PROMPT = \"\"\"\nPerform an additional verification on the previously style-checked answer. Focus on:\n\n1. Consistency with the question\n2. Accuracy of specific details (names, dates, places, styles)\n3. Completeness of the answer\n4. Ensure the answer is a single word, number, or short phrase when appropriate\n\nIf any issues are found, provide a corrected version. If the answer is accurate and complete, restate it. Be concise and direct in your response, providing only the verified or corrected answer without explanations.\n\"\"\"</prompt>", "tag": "HotpotQA", "domain": "llm_judge", "parent_round": 14, "child_round": 15, "parent_score": 0.6155738052796876, "child_score": 0.6300312432665374, "performance_gain": 0.01445743798684973}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve QA problems.\\nReferring to the given graph and prompt, which forms a basic example of a QA solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.6416666666666666</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_15.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.answer_generate = operator.AnswerGenerate(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):  # Generate 3 solutions\\n            step_by_step = await self.answer_generate(input=problem)\\n            solution = await self.custom(input=f\\\"Question: {problem}\\\\nStep-by-step solution: {step_by_step['thought']}\\\\nInitial answer: {step_by_step['answer']}\\\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions)\\n        \\n        # Add a final verification step\\n        verified_solution = await self.custom(input=f\\\"Question: {problem}\\\\nProposed answer: {final_solution['response']}\\\", instruction=prompt_custom.VERIFY_ANSWER_PROMPT)\\n        \\n        return verified_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\\n\\n1. Ensure the answer is concise and directly addresses the question.\\n2. If the answer is a number, provide only the number without additional text.\\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\\n4. Remove any explanations or reasoning from the final answer.\\n5. Double-check that the refined answer is consistent with the step-by-step solution and initial answer.\\n6. If the answer involves selecting between options, clearly state the chosen option.\\n\\nYour task is to extract or refine the most accurate answer based on the provided information.\\n\\\"\\\"\\\"\\n\\nVERIFY_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the original question and the proposed answer, please verify and, if necessary, correct the answer. Follow these guidelines:\\n\\n1. Ensure the answer directly addresses the question asked.\\n2. If the answer should be a number, make sure it's provided as a number without additional text.\\n3. If multiple correct answers are possible, they should be separated by a vertical bar (|).\\n4. The answer should not include any explanations or reasoning.\\n5. If the question asks for a percentage, ensure the answer is in the correct percentage format (e.g., 74.60 instead of 0.746).\\n6. If the answer involves selecting between options, make sure the chosen option is clearly stated.\\n7. If the answer is correct and properly formatted, return it as is. If not, provide the corrected version.\\n\\nYour task is to ensure the final answer is accurate, properly formatted, and consistent with the question requirements.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 16</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_16.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.answer_generate = operator.AnswerGenerate(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):  # Generate 3 solutions\n            step_by_step = await self.answer_generate(input=problem)\n            solutions.append(step_by_step['answer'])\n        \n        ensemble_solution = await self.sc_ensemble(solutions=solutions)\n        \n        refined_solution = await self.custom(input=f\"Question: {problem}\\nBest solution: {ensemble_solution['response']}\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n        \n        final_solution = await self.custom(input=f\"Question: {problem}\\nRefined answer: {refined_solution['response']}\", instruction=prompt_custom.EXTRACT_VALIDATE_PROMPT)\n\n        return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>REFINE_ANSWER_PROMPT = \"\"\"\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\n\n1. Ensure the answer is concise and directly addresses the question.\n2. If the answer is a number, provide only the number without additional text.\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\n4. Remove any explanations or reasoning from the final answer.\n\nYour task is to extract or refine the most accurate answer based on the provided information.\n\"\"\"\n\nEXTRACT_VALIDATE_PROMPT = \"\"\"\nGiven the question and the refined answer, please extract and validate the numerical answer. Follow these guidelines:\n\n1. Extract only the numerical value from the refined answer.\n2. Ensure the extracted number is relevant to the question asked.\n3. If the answer is a decimal, maintain the original decimal places.\n4. If the answer is a whole number, do not add decimal places.\n5. If no valid numerical answer can be extracted, respond with \"Unable to extract a valid numerical answer.\"\n\nProvide only the extracted and validated numerical answer without any additional text or explanations.\n\"\"\"</prompt>", "tag": "DROP", "domain": "llm_judge", "parent_round": 15, "child_round": 16, "parent_score": 0.6416666666666666, "child_score": 0.6405228758169935, "performance_gain": -0.0011437908496730875}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve QA problems.\\nReferring to the given graph and prompt, which forms a basic example of a QA solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.5076680672268906</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_14.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.answer_generate = operator.AnswerGenerate(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        step_by_step = await self.answer_generate(input=problem)\\n        solution = await self.custom(input=problem + f\\\"\\\\nStep-by-step thought: {step_by_step['thought']}\\\\nInitial answer: {step_by_step['answer']}\\\", instruction=prompt_custom.REFINE_PROMPT)\\n        return solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_PROMPT = \\\"\\\"\\\"\\nGiven the problem, step-by-step thought process, and initial answer, please refine and format the final answer. Ensure that:\\n1. The answer is concise and directly addresses the question.\\n2. Only include numerical values or short phrases as required by the question.\\n3. Do not include explanations or additional context unless specifically asked.\\n4. If the answer involves multiple items, separate them with a vertical bar (|).\\n\\nProblem: {input}\\n\\nProvide the refined answer:\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 15</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_15.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.answer_generate = operator.AnswerGenerate(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):  # Generate 3 solutions\n            step_by_step = await self.answer_generate(input=problem)\n            solution = await self.custom(input=f\"Question: {problem}\\nStep-by-step solution: {step_by_step['thought']}\\nInitial answer: {step_by_step['answer']}\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n            solutions.append(solution['response'])\n        \n        final_solution = await self.sc_ensemble(solutions=solutions)\n        \n        # Add a final verification step\n        verified_solution = await self.custom(input=f\"Question: {problem}\\nProposed answer: {final_solution['response']}\", instruction=prompt_custom.VERIFY_ANSWER_PROMPT)\n        \n        return verified_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>REFINE_ANSWER_PROMPT = \"\"\"\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\n\n1. Ensure the answer is concise and directly addresses the question.\n2. If the answer is a number, provide only the number without additional text.\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\n4. Remove any explanations or reasoning from the final answer.\n5. Double-check that the refined answer is consistent with the step-by-step solution and initial answer.\n6. If the answer involves selecting between options, clearly state the chosen option.\n\nYour task is to extract or refine the most accurate answer based on the provided information.\n\"\"\"\n\nVERIFY_ANSWER_PROMPT = \"\"\"\nGiven the original question and the proposed answer, please verify and, if necessary, correct the answer. Follow these guidelines:\n\n1. Ensure the answer directly addresses the question asked.\n2. If the answer should be a number, make sure it's provided as a number without additional text.\n3. If multiple correct answers are possible, they should be separated by a vertical bar (|).\n4. The answer should not include any explanations or reasoning.\n5. If the question asks for a percentage, ensure the answer is in the correct percentage format (e.g., 74.60 instead of 0.746).\n6. If the answer involves selecting between options, make sure the chosen option is clearly stated.\n7. If the answer is correct and properly formatted, return it as is. If not, provide the corrected version.\n\nYour task is to ensure the final answer is accurate, properly formatted, and consistent with the question requirements.\n\"\"\"</prompt>", "tag": "DROP", "domain": "llm_judge", "parent_round": 14, "child_round": 15, "parent_score": 0.5076680672268906, "child_score": 0.6784313725490196, "performance_gain": 0.17076330532212902}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.88</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_21.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(5):  # Generate 5 solutions\\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        # Add a verification step using the Programmer operator\\n        verification = await self.programmer(problem=problem, analysis=final_solution['response'])\\n        \\n        if verification['output']:\\n            final_answer = verification['output']\\n        else:\\n            final_answer = final_solution['response']\\n\\n        # Final check to ensure the answer is a single number\\n        try:\\n            final_answer = float(final_answer)\\n        except ValueError:\\n            final_answer = float(final_answer.split()[-1])\\n\\n        return str(final_answer), self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>MATH_SOLVE_PROMPT = \\\"\\\"\\\"\\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps carefully:\\n\\n1. Read and understand the problem thoroughly, paying special attention to time-based calculations and total cost considerations including any discounts.\\n2. Identify all key information, variables, and relationships, especially those related to time periods and pricing.\\n3. Determine the appropriate mathematical concepts, formulas, or equations to use, including time conversion if necessary.\\n4. Solve the problem step-by-step, showing all your work clearly.\\n5. For problems involving time:\\n   - Convert all time periods to the same unit (e.g., minutes or hours)\\n   - Calculate the total time period carefully\\n6. For problems involving costs:\\n   - Include all mentioned costs and discounts\\n   - Calculate the total cost, factoring in any discounts or special pricing\\n7. Double-check your calculations and reasoning at each step.\\n8. Provide a clear and concise final answer.\\n9. Verify your solution by plugging it back into the original problem or using an alternative method if possible.\\n\\nFormat your answer as follows:\\n- Use LaTeX notation for mathematical expressions where appropriate.\\n- Show each step of your solution process clearly.\\n- Clearly state your final answer at the end of your solution.\\n- Express numerical answers as precise values (avoid rounding unless specified).\\n- Ensure that your final answer is a single numerical value without any units or additional text.\\n- Do not include any explanatory text with your final answer, just the number itself.\\n\\nFor example, if the final answer is 42.5, your response should end with just:\\n42.5\\n\\nHere's the problem to solve:\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 22</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_22.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\n            solutions.append(solution['response'])\n        \n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Add a verification step using the Programmer operator\n        review_result = await self.programmer(problem=problem, analysis=final_solution['response'])\n        \n        # Add a final review step using the Custom operator\n        final_review = await self.custom(input=f\"Problem: {problem}\\nCalculated answer: {review_result['output']}\", instruction=prompt_custom.FINAL_REVIEW_PROMPT)\n        \n        return final_review['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>MATH_SOLVE_PROMPT = \"\"\"\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps:\n\n1. Carefully read and understand the problem.\n2. Identify the key information and variables.\n3. Determine the appropriate mathematical concepts or formulas to use.\n4. Pay special attention to time-based calculations and unit conversions.\n5. Solve the problem step by step, showing all your work.\n6. Double-check your calculations and reasoning.\n7. Provide a clear and concise final answer.\n\nRemember to format your answer as follows:\n- Use LaTeX notation for mathematical expressions where appropriate.\n- Clearly state your final answer at the end of your solution.\n- Express numerical answers as precise values (avoid rounding unless specified).\n- Ensure that your final answer is a single numerical value without any units or additional text.\n- Do not include any explanatory text with your final answer, just the number itself.\n\nFor example, if the final answer is 42.5, your response should end with just:\n42.5\n\nHere's the problem to solve:\n\n\"\"\"\n\nFINAL_REVIEW_PROMPT = \"\"\"\nReview the given problem and the calculated answer. Ensure that the answer is correct and properly formatted. The final output should be a single numerical value without any units or additional text. If the calculated answer is correct and properly formatted, return it as is. If it needs adjustment, make the necessary changes and return the corrected value.\n\nProblem: {problem}\nCalculated answer: {calculated_answer}\n\nYour task:\n1. Verify the correctness of the calculation.\n2. Check if the answer is a single numerical value without units or additional text.\n3. If needed, adjust the answer to meet the required format.\n4. Return only the final numerical value.\n\nFinal answer:\n\"\"\"</prompt>", "tag": "GSM8K", "domain": "llm_judge", "parent_round": 21, "child_round": 22, "parent_score": 0.88, "child_score": 0.9, "performance_gain": 0.020000000000000018}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve QA problems.\\nReferring to the given graph and prompt, which forms a basic example of a QA solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.7348039215686274</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_18.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.answer_generate = operator.AnswerGenerate(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):  # Generate 3 solutions\\n            step_by_step = await self.answer_generate(input=problem)\\n            solution = await self.custom(input=f\\\"Question: {problem}\\\\nStep-by-step solution: {step_by_step['thought']}\\\\nInitial answer: {step_by_step['answer']}\\\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions)\\n        verified_solution = await self.custom(input=f\\\"Question: {problem}\\\\nFinal answer: {final_solution['response']}\\\", instruction=prompt_custom.VERIFY_ANSWER_PROMPT)\\n        return verified_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\\n\\n1. Ensure the answer is concise and directly addresses the question.\\n2. If the answer is a number, provide only the number without additional text.\\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\\n4. Remove any explanations or reasoning from the final answer.\\n5. Double-check that the refined answer is consistent with the step-by-step solution and initial answer.\\n6. If the answer involves selecting between options, clearly state the chosen option.\\n\\nYour task is to extract or refine the most accurate answer based on the provided information.\\n\\\"\\\"\\\"\\n\\nVERIFY_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question and the final answer, please verify and refine the answer to ensure it meets the following criteria:\\n\\n1. The answer should be a single number or a short phrase, without any additional explanations.\\n2. If the answer is a percentage, remove the percentage sign and provide only the numerical value.\\n3. Ensure that the answer is properly formatted according to the question requirements.\\n4. If the answer should be a whole number, round it to the nearest integer.\\n5. Double-check that the answer directly addresses the question asked.\\n\\nYour task is to provide the verified and refined answer that meets these criteria. If the answer already meets all criteria, return it unchanged.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 19</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_19.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.answer_generate = operator.AnswerGenerate(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):  # Generate 3 solutions\n            step_by_step = await self.answer_generate(input=problem)\n            solution = await self.custom(input=f\"Question: {problem}\\nStep-by-step solution: {step_by_step['thought']}\\nInitial answer: {step_by_step['answer']}\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n            verified_solution = await self.custom(input=f\"Question: {problem}\\nStep-by-step solution: {step_by_step['thought']}\\nRefined answer: {solution['response']}\", instruction=prompt_custom.VERIFY_NUMERICAL_ANSWER_PROMPT)\n            solutions.append(verified_solution['response'])\n        \n        final_solution = await self.sc_ensemble(solutions=solutions)\n        return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>REFINE_ANSWER_PROMPT = \"\"\"\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\n\n1. Ensure the answer is concise and directly addresses the question.\n2. If the answer is a number, provide only the number without additional text.\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\n4. Remove any explanations or reasoning from the final answer.\n5. Double-check that the refined answer is consistent with the step-by-step solution and initial answer.\n6. If the answer involves selecting between options, clearly state the chosen option.\n\nYour task is to extract or refine the most accurate answer based on the provided information.\n\"\"\"\n\nVERIFY_NUMERICAL_ANSWER_PROMPT = \"\"\"\nGiven the question, step-by-step solution, and refined answer, please verify and correct the numerical answer if necessary. Follow these guidelines:\n\n1. Check if the answer is consistent with the question and step-by-step solution.\n2. Ensure the answer is a number or numbers separated by a vertical bar (|) if multiple answers are possible.\n3. If the answer is incorrect or inconsistent, recalculate based on the step-by-step solution.\n4. Remove any non-numeric characters or explanations, keeping only the numerical value(s).\n5. If the question asks for a difference or comparison between values, double-check the calculation.\n6. If no numerical answer is required, return the refined answer as is.\n\nYour task is to provide the most accurate numerical answer based on the given information and calculations.\n\"\"\"</prompt>", "tag": "DROP", "domain": "llm_judge", "parent_round": 18, "child_round": 19, "parent_score": 0.7348039215686274, "child_score": 0.6136941408312641, "performance_gain": -0.12110978073736334}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.88</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_17.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(5):  # Generate 5 solutions\\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        # Add a verification step using the Programmer operator\\n        verification = await self.programmer(problem=problem, analysis=final_solution['response'])\\n        \\n        if verification['output']:\\n            final_answer = verification['output']\\n        else:\\n            final_answer = final_solution['response']\\n        \\n        # Final check to ensure the answer is a single numerical value\\n        try:\\n            final_answer = float(final_answer)\\n        except ValueError:\\n            final_answer = float(final_solution['response'])\\n        \\n        return str(final_answer), self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>MATH_SOLVE_PROMPT = \\\"\\\"\\\"\\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps carefully:\\n\\n1. Read and understand the problem thoroughly, paying close attention to ALL given information.\\n2. Identify all key information, variables, and relationships, including any discounts or time-related factors.\\n3. Determine the appropriate mathematical concepts, formulas, or equations to use.\\n4. Solve the problem step-by-step, showing all your work clearly.\\n5. Double-check your calculations and reasoning at each step.\\n6. If the problem involves multiple time periods or discounts, ensure these are correctly applied in your calculations.\\n7. Calculate the total cost or final answer, considering ALL factors mentioned in the problem.\\n8. Provide a clear and concise final answer.\\n9. Verify your solution by plugging it back into the original problem or using an alternative method if possible.\\n\\nFormat your answer as follows:\\n- Use LaTeX notation for mathematical expressions where appropriate.\\n- Show each step of your solution process clearly.\\n- Clearly state your final answer at the end of your solution.\\n- Express numerical answers as precise values (avoid rounding unless specified).\\n- Ensure that your final answer is a single numerical value without any units or additional text.\\n- Do not include any explanatory text with your final answer, just the number itself.\\n\\nFor example, if the final answer is 42.5, your response should end with just:\\n42.5\\n\\nHere's the problem to solve:\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 18</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_18.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\n            solutions.append(solution['response'])\n        \n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Add a verification step using the Programmer operator\n        verification_prompt = f\"Verify the following solution, focusing on unit conversions and complex calculations:\\n\\nProblem: {problem}\\n\\nSolution: {final_solution['response']}\\n\\nProvide the correct numerical answer as a single value without units.\"\n        verification_result = await self.programmer(problem=verification_prompt)\n        \n        if verification_result['output']:\n            return verification_result['output'], self.llm.cost_manager.total_cost\n        else:\n            return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>MATH_SOLVE_PROMPT = \"\"\"\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps:\n\n1. Carefully read and understand the problem.\n2. Identify the key information and variables.\n3. Determine the appropriate mathematical concepts or formulas to use.\n4. Solve the problem step by step, showing all your work.\n5. Pay special attention to unit conversions (e.g., inches to feet, minutes to hours).\n6. For time-based problems, convert all time units to a single unit (preferably hours or minutes).\n7. For problems involving money, ensure all calculations are in the same currency unit.\n8. Double-check your calculations and reasoning, especially for unit conversions and complex calculations.\n9. Provide a clear and concise final answer.\n\nRemember to format your answer as follows:\n- Use LaTeX notation for mathematical expressions where appropriate.\n- Clearly state your final answer at the end of your solution.\n- Express numerical answers as precise values (avoid rounding unless specified).\n- Ensure that your final answer is a single numerical value without any units or additional text.\n- Do not include any explanatory text with your final answer, just the number itself.\n\nFor example, if the final answer is 42.5 hours, your response should end with just:\n42.5\n\nHere's the problem to solve:\n\n\"\"\"</prompt>", "tag": "GSM8K", "domain": "llm_judge", "parent_round": 17, "child_round": 18, "parent_score": 0.88, "child_score": 0.9, "performance_gain": 0.020000000000000018}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.9333333333333333</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_18.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        Custom operator to generate anything you want.\\n        But when you want to get standard code, you should use custom_code_generate operator.\\n        \\\"\\\"\\\"\\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=\\\"\\\")\\n        \\n        # Add a review step\\n        review_result = await self.custom(input=f\\\"Problem: {problem}\\\\nGenerated Solution: {solution['response']}\\\", instruction=prompt_custom.REVIEW_PROMPT)\\n        \\n        if \\\"Improvements needed\\\" in review_result['response']:\\n            improved_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=review_result['response'])\\n            return improved_solution['response'], self.llm.cost_manager.total_cost\\n        else:\\n            return solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>REVIEW_PROMPT = \\\"\\\"\\\"\\nReview the following generated solution for the given problem. If the solution is correct and optimal, respond with 'No improvements needed'. If there are any issues or potential improvements, describe them in detail.\\n\\nProblem: {problem}\\n\\nGenerated Solution:\\n{solution}\\n\\nYour review:\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 19</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_19.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=\"\")\n        \n        # Add a review step\n        review_result = await self.custom(input=f\"Problem: {problem}\\nSolution: {solution['response']}\", instruction=prompt_custom.REVIEW_CODE_PROMPT)\n        \n        if \"No issues found\" not in review_result['response']:\n            # If issues are found, generate a new solution\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.IMPROVE_CODE_PROMPT + f\"\\nReview feedback: {review_result['response']}\")\n        \n        test_result = await self.test(problem=problem, solution=solution['response'], entry_point=entry_point)\n        \n        if test_result['result']:\n            return test_result['solution'], self.llm.cost_manager.total_cost\n        else:\n            # If the test fails, try to generate a new solution\n            new_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.IMPROVE_CODE_PROMPT)\n            return new_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>IMPROVE_CODE_PROMPT = \"\"\"\nThe previous solution failed some test cases. Please analyze the problem carefully and provide an improved solution that addresses all edge cases and requirements. Ensure your code is efficient and follows best practices.\n\"\"\"\n\nREVIEW_CODE_PROMPT = \"\"\"\nPlease review the following code solution and identify any potential issues, edge cases, or improvements that could be made. If no issues are found, respond with \"No issues found\". Otherwise, provide a brief description of the issues and suggestions for improvement.\n\"\"\"</prompt>", "tag": "HumanEval", "domain": "llm_judge", "parent_round": 18, "child_round": 19, "parent_score": 0.9333333333333333, "child_score": 0.9666666666666667, "performance_gain": 0.033333333333333326}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>\\nPrevious failed modifications:\\n  - Add the ScEnsemble operator to generate multiple solutions and select the best one. This will help in improving the overall quality of the generated code. (Score: 0.8400000000000001)</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.8666666666666667</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_6.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\\n        \\n        # Self-review step\\n        review = await self.custom(input=f\\\"Problem: {problem}\\\\nGenerated solution: {solution['response']}\\\", instruction=prompt_custom.SELF_REVIEW_PROMPT)\\n        \\n        # Improve the solution based on the review\\n        improved_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\\\"{prompt_custom.CODE_GENERATE_PROMPT}\\\\n\\\\nConsider this review: {review['response']}\\\")\\n        \\n        test_result = await self.test(problem=problem, solution=improved_solution['response'], entry_point=entry_point)\\n        \\n        if not test_result['result']:\\n            analysis = await self.custom(input=f\\\"Problem: {problem}\\\\nFailed solution: {improved_solution['response']}\\\\nTest result: {test_result['solution']}\\\", instruction=prompt_custom.ANALYZE_AND_IMPROVE_PROMPT)\\n            final_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\\\"{prompt_custom.CODE_GENERATE_PROMPT}\\\\n\\\\nConsider this analysis: {analysis['response']}\\\")\\n            return final_solution['response'], self.llm.cost_manager.total_cost\\n        \\n        return improved_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>CODE_GENERATE_PROMPT = \\\"\\\"\\\"\\nGenerate a Python function that solves the given problem. Ensure the function signature matches the problem description. Include docstrings and comments to explain the logic. The solution should be efficient and handle edge cases.\\n\\\"\\\"\\\"\\n\\nSELF_REVIEW_PROMPT = \\\"\\\"\\\"\\nReview the generated solution and provide feedback on its correctness, efficiency, and adherence to best practices. Consider the following:\\n1. Does the solution correctly implement the problem requirements?\\n2. Are there any potential edge cases that are not handled?\\n3. Can the code be optimized for better performance?\\n4. Does the code follow Python best practices and style guidelines?\\n5. Are there any logical errors or potential bugs?\\nProvide specific suggestions for improvements if necessary.\\n\\\"\\\"\\\"\\n\\nANALYZE_AND_IMPROVE_PROMPT = \\\"\\\"\\\"\\nAnalyze the failed solution and provide suggestions for improvement. Consider the following:\\n1. Identify logical errors or misunderstandings of the problem.\\n2. Check for edge cases that might not be handled correctly.\\n3. Suggest optimizations or alternative approaches if applicable.\\n4. Provide specific code snippets or pseudocode to address the issues found.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Add the ScEnsemble operator to generate multiple solutions and select the best one. This will help in improving the overall quality of the generated code.</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_7.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        # Generate multiple solutions\n        solutions = []\n        for _ in range(3):\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\n            solutions.append(solution['response'])\n        \n        # Use ScEnsemble to select the best solution\n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Self-review step\n        review = await self.custom(input=f\"Problem: {problem}\\nGenerated solution: {best_solution['response']}\", instruction=prompt_custom.SELF_REVIEW_PROMPT)\n        \n        # Improve the solution based on the review\n        improved_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\"{prompt_custom.CODE_GENERATE_PROMPT}\\n\\nConsider this review: {review['response']}\")\n        \n        test_result = await self.test(problem=problem, solution=improved_solution['response'], entry_point=entry_point)\n        \n        if not test_result['result']:\n            analysis = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {improved_solution['response']}\\nTest result: {test_result['solution']}\", instruction=prompt_custom.ANALYZE_AND_IMPROVE_PROMPT)\n            final_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\"{prompt_custom.CODE_GENERATE_PROMPT}\\n\\nConsider this analysis: {analysis['response']}\")\n            return final_solution['response'], self.llm.cost_manager.total_cost\n        \n        return improved_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>CODE_GENERATE_PROMPT = \"\"\"\nGenerate a Python function that solves the given problem. Ensure the function signature matches the problem description. Include docstrings and comments to explain the logic. The solution should be efficient and handle edge cases.\n\"\"\"\n\nSELF_REVIEW_PROMPT = \"\"\"\nReview the generated solution and provide feedback on its correctness, efficiency, and adherence to best practices. Consider the following:\n1. Does the solution correctly implement the problem requirements?\n2. Are there any potential edge cases that are not handled?\n3. Can the code be optimized for better performance?\n4. Does the code follow Python best practices and style guidelines?\n5. Are there any logical errors or potential bugs?\nProvide specific suggestions for improvements if necessary.\n\"\"\"\n\nANALYZE_AND_IMPROVE_PROMPT = \"\"\"\nAnalyze the failed solution and provide suggestions for improvement. Consider the following:\n1. Identify logical errors or misunderstandings of the problem.\n2. Check for edge cases that might not be handled correctly.\n3. Suggest optimizations or alternative approaches if applicable.\n4. Provide specific code snippets or pseudocode to address the issues found.\n\"\"\"</prompt>", "tag": "HumanEval", "domain": "llm_judge", "parent_round": 6, "child_round": 7, "parent_score": 0.8666666666666667, "child_score": 0.9, "performance_gain": 0.033333333333333326}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>Previous successful modifications:\\n  - Add a verification step using the Programmer operator to double-check the final answer and potentially correct any errors. This will be implemented after the sc_ensemble step. (Score: 0.906)</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.88</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_10.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(5):  # Generate 5 solutions\\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        # Add a verification step using the Programmer operator\\n        verification = await self.programmer(problem=problem, analysis=final_solution['response'])\\n        \\n        if verification['output']:\\n            return verification['output'], self.llm.cost_manager.total_cost\\n        else:\\n            return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>MATH_SOLVE_PROMPT = \\\"\\\"\\\"\\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps carefully:\\n\\n1. Read and understand the problem thoroughly.\\n2. Identify all key information, variables, and relationships.\\n3. Determine the appropriate mathematical concepts, formulas, or equations to use.\\n4. Solve the problem step-by-step, showing all your work clearly.\\n5. Double-check your calculations and reasoning at each step.\\n6. Provide a clear and concise final answer.\\n7. Verify your solution by plugging it back into the original problem or using an alternative method if possible.\\n\\nFormat your answer as follows:\\n- Use LaTeX notation for mathematical expressions where appropriate.\\n- Show each step of your solution process clearly.\\n- Clearly state your final answer at the end of your solution.\\n- Express numerical answers as precise values (avoid rounding unless specified).\\n- Ensure that your final answer is a single numerical value without any units or additional text.\\n- Do not include any explanatory text with your final answer, just the number itself.\\n\\nFor example, if the final answer is 42.5, your response should end with just:\\n42.5\\n\\nHere's the problem to solve:\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 11</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_11.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\n            solutions.append(solution['response'])\n        \n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Use the Programmer operator for final verification\n        verification = await self.programmer(problem=problem, analysis=final_solution['response'])\n        \n        if verification['output']:\n            return verification['output'], self.llm.cost_manager.total_cost\n        else:\n            return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>MATH_SOLVE_PROMPT = \"\"\"\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps:\n\n1. Carefully read and understand the problem.\n2. Identify the key information and variables.\n3. Determine the appropriate mathematical concepts or formulas to use.\n4. Solve the problem step by step, showing all your work.\n5. Perform any necessary unit conversions (e.g., feet to inches, dollars to cents).\n6. Double-check your calculations and reasoning.\n7. Provide a clear and concise final answer.\n\nRemember to format your answer as follows:\n- Use LaTeX notation for mathematical expressions where appropriate.\n- Clearly state your final answer at the end of your solution.\n- Express numerical answers as precise values (avoid rounding unless specified).\n- Ensure that your final answer is a single numerical value without any units or additional text.\n- Do not include any explanatory text with your final answer, just the number itself.\n\nFor example, if the final answer is 42.5 dollars, your response should end with just:\n42.5\n\nHere's the problem to solve:\n\n\"\"\"</prompt>", "tag": "GSM8K", "domain": "llm_judge", "parent_round": 10, "child_round": 11, "parent_score": 0.88, "child_score": 0.87, "performance_gain": -0.010000000000000009}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.88</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_15.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(5):  # Generate 5 solutions\\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        # Add a verification step using the Programmer operator\\n        verification = await self.programmer(problem=problem, analysis=final_solution['response'])\\n        \\n        # Double-check the final answer\\n        double_check = await self.custom(input=problem + f\\\"\\\\nInitial solution: {final_solution['response']}\\\\nVerification result: {verification['output']}\\\", instruction=prompt_custom.DOUBLE_CHECK_PROMPT)\\n        \\n        return double_check['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>MATH_SOLVE_PROMPT = \\\"\\\"\\\"\\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps carefully:\\n\\n1. Read and understand the problem thoroughly, ensuring you consider ALL given information.\\n2. Identify all key information, variables, and relationships, including any discounts or special conditions.\\n3. Determine the appropriate mathematical concepts, formulas, or equations to use.\\n4. Solve the problem step-by-step, showing all your work clearly.\\n5. Double-check your calculations and reasoning at each step.\\n6. Provide a clear and concise final answer.\\n7. Verify your solution by plugging it back into the original problem or using an alternative method if possible.\\n8. Explicitly calculate the total cost, including any discounts or special conditions mentioned in the problem.\\n\\nFormat your answer as follows:\\n- Use LaTeX notation for mathematical expressions where appropriate.\\n- Show each step of your solution process clearly.\\n- Clearly state your final answer at the end of your solution.\\n- Express numerical answers as precise values (avoid rounding unless specified).\\n- Ensure that your final answer is a single numerical value without any units or additional text.\\n- Do not include any explanatory text with your final answer, just the number itself.\\n\\nFor example, if the final answer is 42.5, your response should end with just:\\n42.5\\n\\nHere's the problem to solve:\\n\\n\\\"\\\"\\\"\\n\\nDOUBLE_CHECK_PROMPT = \\\"\\\"\\\"\\nYou are a meticulous math checker. Your task is to review the given problem, the initial solution, and the verification result. Then, determine the most accurate final answer.\\n\\nFollow these steps:\\n1. Carefully read the original problem, paying attention to all details and conditions.\\n2. Review the initial solution and the verification result.\\n3. If there are discrepancies, analyze both approaches to identify any errors or overlooked information.\\n4. Recalculate the problem yourself, ensuring all conditions and discounts are properly applied.\\n5. Provide the final, correct answer as a single numerical value without any units or additional text.\\n\\nRemember:\\n- Consider ALL information given in the problem, including any discounts or special conditions.\\n- Ensure that your calculations account for the entire problem, not just part of it.\\n- Double-check your math to avoid simple calculation errors.\\n- Your final answer should be a single number without any explanations.\\n\\nFor example, if the correct final answer is 123.0, your response should be just:\\n123.0\\n\\nHere's the problem and previous results to review:\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 16</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_16.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(5):  # Generate 5 solutions\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\n            solutions.append(solution['response'])\n        \n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Add a verification step using the Programmer operator\n        verification = await self.programmer(problem=problem, analysis=final_solution['response'])\n        \n        # Double-check the final answer with a focus on total cost calculation\n        double_check = await self.custom(input=problem + f\"\\nPrevious solution: {verification['output']}\", instruction=prompt_custom.DOUBLE_CHECK_PROMPT)\n        \n        if double_check['response'] != verification['output']:\n            return double_check['response'], self.llm.cost_manager.total_cost\n        else:\n            return verification['output'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>MATH_SOLVE_PROMPT = \"\"\"\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps carefully:\n\n1. Read and understand the problem thoroughly.\n2. Identify all key information, variables, and relationships.\n3. Determine the appropriate mathematical concepts, formulas, or equations to use.\n4. Solve the problem step-by-step, showing all your work clearly.\n5. Double-check your calculations and reasoning at each step.\n6. Provide a clear and concise final answer.\n7. Verify your solution by plugging it back into the original problem or using an alternative method if possible.\n\nFormat your answer as follows:\n- Use LaTeX notation for mathematical expressions where appropriate.\n- Show each step of your solution process clearly.\n- Clearly state your final answer at the end of your solution.\n- Express numerical answers as precise values (avoid rounding unless specified).\n- Ensure that your final answer is a single numerical value without any units or additional text.\n- Do not include any explanatory text with your final answer, just the number itself.\n\nFor example, if the final answer is 42.5, your response should end with just:\n42.5\n\nHere's the problem to solve:\n\n\"\"\"\n\nDOUBLE_CHECK_PROMPT = \"\"\"\nYou are a meticulous math problem solver. Your task is to double-check the solution to a given problem, focusing on total cost calculation and considering all given information, including discounts and multiple time periods if applicable.\n\n1. Carefully read the original problem.\n2. Review the previous solution provided.\n3. Pay special attention to:\n   - Total cost calculations\n   - Discounts or percentage-based calculations\n   - Multiple time periods or quantities\n   - Any information that might have been overlooked\n\n4. If you find any errors or discrepancies, recalculate the solution step-by-step.\n5. If the previous solution is correct, confirm it.\n\nProvide your final answer as a single numerical value without any units or additional text. For example:\n\n342.0\n\nHere's the original problem and the previous solution:\n\n\"\"\"</prompt>", "tag": "GSM8K", "domain": "llm_judge", "parent_round": 15, "child_round": 16, "parent_score": 0.88, "child_score": 0.89, "performance_gain": 0.010000000000000009}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.0</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.round_17.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        # Use Programmer to generate and execute Python code\\n        code_solution = await self.programmer(problem=problem)\\n        \\n        # Use Custom to refine and format the answer\\n        refined_solution = await self.custom(input=problem + f\\\"\\\\nCode output: {code_solution['output']}\\\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\\n        \\n        # Generate a detailed step-by-step solution using Custom\\n        detailed_solution = await self.custom(input=problem, instruction=prompt_custom.DETAILED_SOLUTION_PROMPT)\\n        \\n        # Generate multiple solutions using Custom with different approaches\\n        solutions = [\\n            refined_solution['response'],\\n            detailed_solution['response']\\n        ]\\n        for approach in ['algebraic', 'geometric', 'analytical']:\\n            solution = await self.custom(input=problem, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT.format(approach=approach))\\n            solutions.append(solution['response'])\\n        \\n        # Use ScEnsemble to select the best solution\\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the mathematical problem and the output from the code execution, please provide a well-formatted and detailed solution. Follow these guidelines:\\n\\n1. Begin with a clear statement of the problem.\\n2. Explain the approach and any formulas or concepts used.\\n3. Show step-by-step calculations, using LaTeX notation for mathematical expressions.\\n4. Interpret the code output and incorporate it into your explanation.\\n5. Provide a final answer, enclosed in \\\\boxed{} LaTeX notation.\\n6. Ensure all mathematical notation is in LaTeX format.\\n\\nYour response should be comprehensive, mathematically rigorous, and easy to follow.\\n\\\"\\\"\\\"\\n\\nGENERATE_SOLUTION_PROMPT = \\\"\\\"\\\"\\nPlease solve the given mathematical problem using a {approach} approach. Follow these guidelines:\\n\\n1. State the problem clearly.\\n2. Outline the {approach} approach and any relevant formulas or concepts.\\n3. Provide detailed calculations, using LaTeX notation for mathematical expressions.\\n4. Explain each step of your reasoning.\\n5. Present the final answer enclosed in \\\\boxed{} LaTeX notation.\\n6. Ensure all mathematical notation is in LaTeX format.\\n\\nYour solution should be thorough, mathematically sound, and easy to understand.\\n\\\"\\\"\\\"\\n\\nDETAILED_SOLUTION_PROMPT = \\\"\\\"\\\"\\nProvide a comprehensive, step-by-step solution to the given mathematical problem. Your response should include:\\n\\n1. A clear restatement of the problem.\\n2. An explanation of the mathematical concepts and theorems involved.\\n3. A detailed, logical progression of steps leading to the solution.\\n4. Clear explanations for each step, including the reasoning behind it.\\n5. All mathematical expressions and equations in LaTeX format.\\n6. Visual aids or diagrams if applicable (described in text).\\n7. A final answer clearly marked and enclosed in \\\\boxed{} LaTeX notation.\\n8. A brief explanation of the significance of the result, if relevant.\\n\\nEnsure your solution is rigorous, easy to follow, and educational for someone learning the concept.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 18</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.round_18.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        # Use Programmer to generate and execute Python code\n        code_solution = await self.programmer(problem=problem)\n        \n        # Use Custom to generate a detailed step-by-step solution\n        detailed_solution = await self.custom(input=problem + f\"\\nCode output: {code_solution['output']}\", instruction=prompt_custom.DETAILED_SOLUTION_PROMPT)\n        \n        # Use Custom to review and refine the solution\n        refined_solution = await self.custom(input=problem + f\"\\nDetailed solution: {detailed_solution['response']}\", instruction=prompt_custom.REVIEW_AND_REFINE_PROMPT)\n        \n        # Generate multiple solutions using Custom\n        solutions = []\n        for _ in range(3):\n            solution = await self.custom(input=problem, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT)\n            solutions.append(solution['response'])\n        \n        # Add refined_solution to the list of solutions\n        solutions.append(refined_solution['response'])\n        \n        # Use ScEnsemble to select the best solution\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>DETAILED_SOLUTION_PROMPT = \"\"\"\nGiven the mathematical problem and the output from the code execution, please provide a comprehensive and detailed step-by-step solution. Follow these guidelines:\n\n1. Begin with a clear statement of the problem.\n2. Explain the approach and any formulas or concepts used.\n3. Show step-by-step calculations, using LaTeX notation for mathematical expressions.\n4. Interpret the code output and incorporate it into your explanation.\n5. Provide intermediate results and explanations for each step.\n6. Ensure all mathematical notation is in LaTeX format.\n7. Conclude with a final answer, enclosed in \\boxed{} LaTeX notation.\n\nYour response should be thorough, mathematically rigorous, and easy to follow, suitable for a student learning the concept.\n\"\"\"\n\nREVIEW_AND_REFINE_PROMPT = \"\"\"\nPlease review and refine the given detailed solution for the mathematical problem. Follow these guidelines:\n\n1. Check for mathematical accuracy and correctness.\n2. Ensure all steps are logically connected and well-explained.\n3. Verify that all LaTeX notation is correctly used and formatted.\n4. Add any missing steps or explanations that could improve clarity.\n5. Simplify overly complex explanations if possible.\n6. Ensure the final answer is correct and properly enclosed in \\boxed{} LaTeX notation.\n7. If any errors are found, correct them and explain the correction.\n\nProvide the refined solution, maintaining the step-by-step format and mathematical rigor of the original.\n\"\"\"\n\nGENERATE_SOLUTION_PROMPT = \"\"\"\nPlease solve the given mathematical problem step by step. Follow these guidelines:\n\n1. State the problem clearly.\n2. Outline the approach and any relevant formulas or concepts.\n3. Provide detailed calculations, using LaTeX notation for mathematical expressions.\n4. Explain each step of your reasoning.\n5. Present the final answer enclosed in \\boxed{} LaTeX notation.\n6. Ensure all mathematical notation is in LaTeX format.\n\nYour solution should be thorough, mathematically sound, and easy to understand.\n\"\"\"</prompt>", "tag": "MATH", "domain": "llm_judge", "parent_round": 17, "child_round": 18, "parent_score": 0.0, "child_score": 0.5378151260504201, "performance_gain": 0.5378151260504201}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>\\nPrevious failed modifications:\\n  - Add a review step using the Custom operator to evaluate and improve the best solution before testing. (Score: 0.5930232558139534)\\n  - Add a new Custom operator to generate test cases before the final test step. This will help ensure the solution is tested more thoroughly before submission. (Score: 0.7930232558139536)\\n  - Add a code review step using the Custom operator to evaluate and improve the best solution before testing. (Score: 0.786046511627907)</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.8255813953488372</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_14.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        Custom operator to generate anything you want.\\n        But when you want to get standard code, you should use custom_code_generate operator.\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):  # Generate 3 solutions\\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        test_result = await self.test(problem=problem, solution=best_solution['response'], entry_point=entry_point)\\n        \\n        if test_result['result']:\\n            return test_result['solution'], self.llm.cost_manager.total_cost\\n        else:\\n            # If the test fails, try to fix the solution\\n            fixed_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nFailed solution: {best_solution['response']}\\\\nError: {test_result['solution']}\\\", instruction=prompt_custom.FIX_CODE_PROMPT)\\n            return fixed_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>CODE_GENERATE_PROMPT = \\\"\\\"\\\"\\nGenerate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity.\\n\\nProblem:\\n{problem}\\n\\nFunction signature:\\n{entry_point}\\n\\nGenerate the complete function below:\\n\\\"\\\"\\\"\\n\\nFIX_CODE_PROMPT = \\\"\\\"\\\"\\nThe provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation.\\n\\nProblem:\\n{input}\\n\\nProvide the corrected function below:\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 15</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_15.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        solutions = []\n        for _ in range(3):\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\n            solutions.append(solution['response'])\n        \n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        test_result = await self.test(problem=problem, solution=best_solution['response'], entry_point=entry_point)\n        \n        if test_result['result']:\n            return test_result['solution'], self.llm.cost_manager.total_cost\n        else:\n            fixed_solution = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {best_solution['response']}\\nError: {test_result['solution']}\", instruction=prompt_custom.FIX_CODE_PROMPT)\n            return fixed_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>CODE_GENERATE_PROMPT = \"\"\"\nGenerate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity.\n\nProblem:\n{problem}\n\nFunction signature:\n{entry_point}\n\nGenerate the complete function below:\n\"\"\"\n\nFIX_CODE_PROMPT = \"\"\"\nThe provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation.\n\nProblem:\n{input}\n\nProvide the corrected function below:\n\"\"\"</prompt>", "tag": "MBPP", "domain": "llm_judge", "parent_round": 14, "child_round": 15, "parent_score": 0.8255813953488372, "child_score": 0.8488372093023255, "performance_gain": 0.023255813953488302}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.9333333333333333</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_19.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=\\\"\\\")\\n        \\n        # Add a review step\\n        review_result = await self.custom(input=f\\\"Problem: {problem}\\\\nSolution: {solution['response']}\\\", instruction=prompt_custom.REVIEW_CODE_PROMPT)\\n        \\n        if \\\"No issues found\\\" not in review_result['response']:\\n            # If issues are found, generate a new solution\\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.IMPROVE_CODE_PROMPT + f\\\"\\\\nReview feedback: {review_result['response']}\\\")\\n        \\n        test_result = await self.test(problem=problem, solution=solution['response'], entry_point=entry_point)\\n        \\n        if test_result['result']:\\n            return test_result['solution'], self.llm.cost_manager.total_cost\\n        else:\\n            # If the test fails, try to generate a new solution\\n            new_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.IMPROVE_CODE_PROMPT)\\n            return new_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>IMPROVE_CODE_PROMPT = \\\"\\\"\\\"\\nThe previous solution failed some test cases. Please analyze the problem carefully and provide an improved solution that addresses all edge cases and requirements. Ensure your code is efficient and follows best practices.\\n\\\"\\\"\\\"\\n\\nREVIEW_CODE_PROMPT = \\\"\\\"\\\"\\nPlease review the following code solution and identify any potential issues, edge cases, or improvements that could be made. If no issues are found, respond with \\\"No issues found\\\". Otherwise, provide a brief description of the issues and suggestions for improvement.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 20</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_20.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        # Generate multiple solutions\n        solutions = []\n        for _ in range(3):\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT)\n            solutions.append(solution['response'])\n\n        # Use ScEnsemble to select the best solution\n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Review and improve the selected solution\n        reviewed_solution = await self.custom(input=f\"Problem: {problem}\\nGenerated solution: {best_solution['response']}\", instruction=prompt_custom.REVIEW_SOLUTION_PROMPT)\n        \n        # Test the reviewed solution\n        test_result = await self.test(problem=problem, solution=reviewed_solution['response'], entry_point=entry_point)\n        \n        if test_result['result']:\n            return test_result['solution'], self.llm.cost_manager.total_cost\n        else:\n            # If the test fails, try to improve the solution\n            improved_solution = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {reviewed_solution['response']}\\nError: {test_result['solution']}\", instruction=prompt_custom.IMPROVE_SOLUTION_PROMPT)\n            return improved_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>GENERATE_SOLUTION_PROMPT = \"\"\"\nGenerate a Python function to solve the given problem. Ensure the solution is complete, correct, and efficient.\n\nYour task:\n1. Understand the problem statement.\n2. Implement a Python function that solves the problem.\n3. Consider edge cases and potential optimizations.\n4. Provide only the Python function as your response, without any additional explanations or comments.\n\"\"\"\n\nREVIEW_SOLUTION_PROMPT = \"\"\"\nReview the given problem and the generated solution. Analyze the code for correctness, efficiency, and adherence to best practices. Improve the solution if necessary.\n\nYour task:\n1. Understand the problem statement.\n2. Review the generated solution.\n3. Check for logical errors, edge cases, and potential improvements.\n4. Rewrite the solution if improvements are needed, or keep it as is if it's optimal.\n5. Ensure the final solution is complete, correct, and efficient.\n\nProvide only the reviewed and potentially improved Python function as your response, without any additional explanations or comments.\n\"\"\"\n\nIMPROVE_SOLUTION_PROMPT = \"\"\"\nAnalyze the given problem and the failed solution. Identify the errors and improve the code to solve the problem correctly. Make sure to handle edge cases and follow best practices in Python programming.\n\nYour task:\n1. Understand the problem statement.\n2. Review the failed solution and the error message.\n3. Identify the cause of the failure.\n4. Rewrite the solution, addressing the identified issues.\n5. Ensure the new solution is complete, correct, and efficient.\n\nProvide only the improved Python function as your response, without any additional explanations or comments.\n\"\"\"</prompt>", "tag": "HumanEval", "domain": "llm_judge", "parent_round": 19, "child_round": 20, "parent_score": 0.9333333333333333, "child_score": 0.9333333333333333, "performance_gain": 0.0}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.89</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_17.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(5):  # Generate 5 solutions\\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        # Add a verification step using the Programmer operator\\n        verification = await self.programmer(problem=problem, analysis=final_solution['response'])\\n        \\n        if verification['output']:\\n            final_answer = verification['output']\\n        else:\\n            final_answer = final_solution['response']\\n        \\n        # Final check to ensure the answer is a single numerical value\\n        try:\\n            final_answer = float(final_answer)\\n        except ValueError:\\n            final_answer = float(final_solution['response'])\\n        \\n        return str(final_answer), self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>MATH_SOLVE_PROMPT = \\\"\\\"\\\"\\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps carefully:\\n\\n1. Read and understand the problem thoroughly, paying close attention to ALL given information.\\n2. Identify all key information, variables, and relationships, including any discounts or time-related factors.\\n3. Determine the appropriate mathematical concepts, formulas, or equations to use.\\n4. Solve the problem step-by-step, showing all your work clearly.\\n5. Double-check your calculations and reasoning at each step.\\n6. If the problem involves multiple time periods or discounts, ensure these are correctly applied in your calculations.\\n7. Calculate the total cost or final answer, considering ALL factors mentioned in the problem.\\n8. Provide a clear and concise final answer.\\n9. Verify your solution by plugging it back into the original problem or using an alternative method if possible.\\n\\nFormat your answer as follows:\\n- Use LaTeX notation for mathematical expressions where appropriate.\\n- Show each step of your solution process clearly.\\n- Clearly state your final answer at the end of your solution.\\n- Express numerical answers as precise values (avoid rounding unless specified).\\n- Ensure that your final answer is a single numerical value without any units or additional text.\\n- Do not include any explanatory text with your final answer, just the number itself.\\n\\nFor example, if the final answer is 42.5, your response should end with just:\\n42.5\\n\\nHere's the problem to solve:\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 18</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_18.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\n            solutions.append(solution['response'])\n        \n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Add a verification step using the Programmer operator\n        verification_prompt = f\"Verify the following solution, focusing on unit conversions and complex calculations:\\n\\nProblem: {problem}\\n\\nSolution: {final_solution['response']}\\n\\nProvide the correct numerical answer as a single value without units.\"\n        verification_result = await self.programmer(problem=verification_prompt)\n        \n        if verification_result['output']:\n            return verification_result['output'], self.llm.cost_manager.total_cost\n        else:\n            return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>MATH_SOLVE_PROMPT = \"\"\"\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps:\n\n1. Carefully read and understand the problem.\n2. Identify the key information and variables.\n3. Determine the appropriate mathematical concepts or formulas to use.\n4. Solve the problem step by step, showing all your work.\n5. Pay special attention to unit conversions (e.g., inches to feet, minutes to hours).\n6. For time-based problems, convert all time units to a single unit (preferably hours or minutes).\n7. For problems involving money, ensure all calculations are in the same currency unit.\n8. Double-check your calculations and reasoning, especially for unit conversions and complex calculations.\n9. Provide a clear and concise final answer.\n\nRemember to format your answer as follows:\n- Use LaTeX notation for mathematical expressions where appropriate.\n- Clearly state your final answer at the end of your solution.\n- Express numerical answers as precise values (avoid rounding unless specified).\n- Ensure that your final answer is a single numerical value without any units or additional text.\n- Do not include any explanatory text with your final answer, just the number itself.\n\nFor example, if the final answer is 42.5 hours, your response should end with just:\n42.5\n\nHere's the problem to solve:\n\n\"\"\"</prompt>", "tag": "GSM8K", "domain": "llm_judge", "parent_round": 17, "child_round": 18, "parent_score": 0.89, "child_score": 0.9, "performance_gain": 0.010000000000000009}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.7790697674418605</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_18.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        solutions = []\\n        for _ in range(3):  # Generate 3 solutions\\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        # Generate additional test cases\\n        additional_tests = await self.custom(input=f\\\"Problem: {problem}\\\\nSolution: {best_solution['response']}\\\", instruction=prompt_custom.GENERATE_TESTS_PROMPT)\\n        \\n        # Combine original problem and additional tests\\n        enhanced_problem = f\\\"{problem}\\\\n\\\\nAdditional test cases:\\\\n{additional_tests['response']}\\\"\\n        \\n        test_result = await self.test(problem=enhanced_problem, solution=best_solution['response'], entry_point=entry_point)\\n        \\n        if test_result['result']:\\n            return test_result['solution'], self.llm.cost_manager.total_cost\\n        else:\\n            # If the test fails, try to fix the solution\\n            fixed_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nFailed solution: {best_solution['response']}\\\\nError: {test_result['solution']}\\\", instruction=prompt_custom.FIX_CODE_PROMPT)\\n            return fixed_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>CODE_GENERATE_PROMPT = \\\"\\\"\\\"\\nGenerate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity.\\n\\nProblem:\\n{problem}\\n\\nFunction signature:\\n{entry_point}\\n\\nGenerate the complete function below:\\n\\\"\\\"\\\"\\n\\nFIX_CODE_PROMPT = \\\"\\\"\\\"\\nThe provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation.\\n\\nProblem:\\n{input}\\n\\nProvide the corrected function below:\\n\\\"\\\"\\\"\\n\\nGENERATE_TESTS_PROMPT = \\\"\\\"\\\"\\nGiven the problem and a potential solution, generate additional test cases to thoroughly evaluate the function. Include edge cases and typical scenarios. Format the test cases as assert statements that can be directly added to a Python test function.\\n\\nProblem:\\n{input}\\n\\nGenerate 3-5 additional test cases as assert statements:\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 19</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_19.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        solutions = []\n        for _ in range(3):  # Generate 3 solutions\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\n            solutions.append(solution['response'])\n        \n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Add a review step\n        reviewed_solution = await self.custom(input=f\"Problem: {problem}\\nSolution: {best_solution['response']}\", instruction=prompt_custom.REVIEW_PROMPT)\n        \n        test_result = await self.test(problem=problem, solution=reviewed_solution['response'], entry_point=entry_point)\n        \n        if test_result['result']:\n            return test_result['solution'], self.llm.cost_manager.total_cost\n        else:\n            # If the test fails, try to fix the solution\n            fixed_solution = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {reviewed_solution['response']}\\nError: {test_result['solution']}\", instruction=prompt_custom.FIX_CODE_PROMPT)\n            return fixed_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>CODE_GENERATE_PROMPT = \"\"\"\nGenerate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity.\n\nProblem:\n{problem}\n\nFunction signature:\n{entry_point}\n\nGenerate the complete function below:\n\"\"\"\n\nREVIEW_PROMPT = \"\"\"\nReview the following solution for the given problem. Identify any potential issues, inefficiencies, or areas for improvement. Provide an improved version of the code if necessary.\n\nProblem:\n{input}\n\nProvide the reviewed and improved function below:\n\"\"\"\n\nFIX_CODE_PROMPT = \"\"\"\nThe provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation.\n\nProblem:\n{input}\n\nProvide the corrected function below:\n\"\"\"</prompt>", "tag": "MBPP", "domain": "llm_judge", "parent_round": 18, "child_round": 19, "parent_score": 0.7790697674418605, "child_score": 0.627906976744186, "performance_gain": -0.15116279069767447}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>Previous successful modifications:\\n  - Add a ScEnsemble operator to improve the reliability of the final answer by generating multiple solutions and selecting the most consistent one. (Score: 0.5277310924369747)\\n\\nPrevious failed modifications:\\n  - Add a ScEnsemble operator to improve the reliability of the final answer by generating multiple solutions and selecting the most consistent one. (Score: 0.4722689075630252)\\n  - Add a ScEnsemble operator to improve the reliability of the final answer by generating multiple solutions and selecting the most consistent one. (Score: 0.5243697478991597)</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.5210084033613446</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.round_2.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        # Use Programmer to generate and execute Python code\\n        code_solution = await self.programmer(problem=problem)\\n        \\n        # Use Custom to refine and format the final answer\\n        solution = await self.custom(input=problem + f\\\"\\\\nCode output: {code_solution['output']}\\\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\\n        \\n        return solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the mathematical problem and the output from the code execution, please provide a well-formatted and detailed solution. Follow these guidelines:\\n\\n1. Begin with a clear statement of the problem.\\n2. Explain the approach and any formulas or concepts used.\\n3. Show step-by-step calculations, using LaTeX notation for mathematical expressions.\\n4. Interpret the code output and incorporate it into your explanation.\\n5. Provide a final answer, enclosed in \\\\boxed{} LaTeX notation.\\n6. Ensure all mathematical notation is in LaTeX format.\\n\\nYour response should be comprehensive, mathematically rigorous, and easy to follow.\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Add a ScEnsemble operator to improve the reliability of the final answer by generating multiple solutions and selecting the most consistent one.</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.round_3.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        # Use Programmer to generate and execute Python code\n        code_solution = await self.programmer(problem=problem)\n        \n        # Use Custom to refine and format the answer\n        refined_solution = await self.custom(input=problem + f\"\\nCode output: {code_solution['output']}\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n        \n        # Generate multiple solutions using Custom\n        solutions = []\n        for _ in range(3):\n            solution = await self.custom(input=problem, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT)\n            solutions.append(solution['response'])\n        \n        # Use ScEnsemble to select the most consistent solution\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>REFINE_ANSWER_PROMPT = \"\"\"\nGiven the mathematical problem and the output from the code execution, please provide a well-formatted and detailed solution. Follow these guidelines:\n\n1. Begin with a clear statement of the problem.\n2. Explain the approach and any formulas or concepts used.\n3. Show step-by-step calculations, using LaTeX notation for mathematical expressions.\n4. Interpret the code output and incorporate it into your explanation.\n5. Provide a final answer, enclosed in \\boxed{} LaTeX notation.\n6. Ensure all mathematical notation is in LaTeX format.\n\nYour response should be comprehensive, mathematically rigorous, and easy to follow.\n\"\"\"\n\nGENERATE_SOLUTION_PROMPT = \"\"\"\nPlease solve the given mathematical problem step by step. Follow these guidelines:\n\n1. State the problem clearly.\n2. Outline the approach and any relevant formulas or concepts.\n3. Provide detailed calculations, using LaTeX notation for mathematical expressions.\n4. Explain each step of your reasoning.\n5. Present the final answer enclosed in \\boxed{} LaTeX notation.\n6. Ensure all mathematical notation is in LaTeX format.\n\nYour solution should be thorough, mathematically sound, and easy to understand.\n\"\"\"</prompt>", "tag": "MATH", "domain": "llm_judge", "parent_round": 2, "child_round": 3, "parent_score": 0.5210084033613446, "child_score": 0.5546218487394958, "performance_gain": 0.03361344537815125}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve QA problems.\\nReferring to the given graph and prompt, which forms a basic example of a QA solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.25276515327907906</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_11.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.answer_generate = operator.AnswerGenerate(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):  # Generate 3 solutions\\n            step_by_step = await self.answer_generate(input=problem)\\n            solutions.append(step_by_step['answer'])\\n        \\n        ensemble_solution = await self.sc_ensemble(solutions=solutions)\\n        \\n        refined_solution = await self.custom(input=f\\\"Question: {problem}\\\\nBest solution: {ensemble_solution['response']}\\\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\\n        \\n        final_solution = await self.custom(input=f\\\"Question: {problem}\\\\nRefined answer: {refined_solution['response']}\\\", instruction=prompt_custom.CHECK_NUMERICAL_ANSWER_PROMPT)\\n\\n        return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\\n\\n1. Ensure the answer is concise and directly addresses the question.\\n2. If the answer is a number, provide only the number without additional text.\\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\\n4. Remove any explanations or reasoning from the final answer.\\n\\nYour task is to extract or refine the most accurate answer based on the provided information.\\n\\\"\\\"\\\"\\n\\nCHECK_NUMERICAL_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question and the refined answer, please perform a numerical check and correction if necessary. Follow these steps:\\n\\n1. Identify if the answer is numerical.\\n2. If it is numerical, carefully review the question and the given answer to ensure its accuracy.\\n3. If you find any discrepancies or errors in the numerical answer, provide the correct numerical answer.\\n4. If the answer is correct or not numerical, return the original answer without changes.\\n5. Ensure the final answer follows the format guidelines: numbers only, no additional text, and use vertical bars (|) for multiple possible answers.\\n\\nYour task is to verify and correct numerical answers while maintaining the correct answer format.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 12</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_12.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.answer_generate = operator.AnswerGenerate(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):  # Generate 3 solutions\n            step_by_step = await self.answer_generate(input=problem)\n            solutions.append(step_by_step['answer'])\n        \n        ensemble_solution = await self.sc_ensemble(solutions=solutions)\n        \n        refined_solution = await self.custom(input=f\"Question: {problem}\\nBest solution: {ensemble_solution['response']}\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n        \n        final_solution = await self.custom(input=f\"Answer: {refined_solution['response']}\", instruction=prompt_custom.FORMAT_NUMERIC_ANSWER_PROMPT)\n\n        return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>REFINE_ANSWER_PROMPT = \"\"\"\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\n\n1. Ensure the answer is concise and directly addresses the question.\n2. If the answer is a number, provide only the number without additional text.\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\n4. Remove any explanations or reasoning from the final answer.\n\nYour task is to extract or refine the most accurate answer based on the provided information.\n\"\"\"\n\nFORMAT_NUMERIC_ANSWER_PROMPT = \"\"\"\nGiven an answer, please format it according to these rules:\n\n1. If the answer contains a single number:\n   - Remove any additional text or symbols (like %, $, etc.)\n   - Present the number without commas\n   - If it's a whole number, remove any decimal places\n   - If it's a decimal, keep up to two decimal places\n\n2. If the answer contains multiple numbers separated by '|':\n   - Apply the above rules to each number\n   - Keep the '|' separator between numbers\n\n3. If the answer doesn't contain any numbers, return it as is.\n\nExamples:\n\"74.60%\" should become \"74.60\"\n\"3 | 20 | 32\" should remain \"3 | 20 | 32\"\n\"$1,234,567.89\" should become \"1234567.89\"\n\"42 years old\" should become \"42\"\n\nYour task is to format the given answer according to these rules.\n\"\"\"</prompt>", "tag": "DROP", "domain": "llm_judge", "parent_round": 11, "child_round": 12, "parent_score": 0.25276515327907906, "child_score": 0.7544117647058823, "performance_gain": 0.5016466114268032}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve QA problems.\\nReferring to the given graph and prompt, which forms a basic example of a QA solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>\\nPrevious failed modifications:\\n  - Add a new custom operator to check for missing information and attempt to infer or research it based on the context of the question. (Score: 0.609809128779717)\\n  - Modify the FORMAT_ANSWER_PROMPT to ensure more specific and concise answers, particularly for location-based questions. Add a new custom operator to refine location-based answers. (Score: 0.5912117457705692)\\n  - Add a new custom operator to perform a detailed context analysis and cross-reference check, focusing on identifying and correcting potential mismatches between the question and the answer. (Score: 0.6186813186813187)</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.6197371256194785</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.round_15.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.answer_generate = operator.AnswerGenerate(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):\\n            initial_response = await self.answer_generate(input=problem)\\n            thought_process = initial_response['thought']\\n            initial_answer = initial_response['answer']\\n            solutions.append(initial_answer)\\n\\n        ensemble_result = await self.sc_ensemble(solutions=solutions)\\n        best_answer = ensemble_result['response']\\n        \\n        name_extracted_answer = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nBest answer: {best_answer}\\\",\\n            instruction=prompt_custom.NAME_EXTRACTION_PROMPT\\n        )\\n        \\n        disambiguated_answer = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nName-extracted answer: {name_extracted_answer['response']}\\\",\\n            instruction=prompt_custom.ENTITY_DISAMBIGUATION_PROMPT\\n        )\\n        \\n        identity_check_answer = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nDisambiguated answer: {disambiguated_answer['response']}\\\",\\n            instruction=prompt_custom.IDENTITY_CHECK_PROMPT\\n        )\\n        \\n        fact_checked_answer = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nIdentity-checked answer: {identity_check_answer['response']}\\\",\\n            instruction=prompt_custom.FACT_CHECK_PROMPT\\n        )\\n        \\n        style_check_answer = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nFact-checked answer: {fact_checked_answer['response']}\\\",\\n            instruction=prompt_custom.STYLE_CHECK_PROMPT\\n        )\\n        \\n        additional_verification = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nStyle-checked answer: {style_check_answer['response']}\\\",\\n            instruction=prompt_custom.ADDITIONAL_VERIFICATION_PROMPT\\n        )\\n        \\n        refined_solution = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nDouble-verified answer: {additional_verification['response']}\\\",\\n            instruction=prompt_custom.FORMAT_ANSWER_PROMPT\\n        )\\n        \\n        return refined_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>FORMAT_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question and the double-verified answer, format the final answer to be extremely concise and directly addressing the question. Provide only the essential information without any explanation or additional context. For names, professions, or short phrases, give only that specific information.\\n\\nExamples:\\n- For a person's name: \\\"John Doe\\\"\\n- For a profession: \\\"Doctor\\\"\\n- For a short phrase: \\\"Once in a blue moon\\\"\\n\\nDo not include any prefixes or explanatory text. Provide only the answer itself.\\n\\\"\\\"\\\"\\n\\nNAME_EXTRACTION_PROMPT = \\\"\\\"\\\"\\nGiven the question and the best answer, focus on extracting and verifying any names mentioned. Pay special attention to:\\n\\n1. Full names (first name, middle name, last name)\\n2. Nicknames or aliases\\n3. Correct spelling of names\\n\\nIf the answer contains a name, ensure it is accurate and complete. If a name is incorrect or incomplete, provide the correct full name. If no name is present or needed, simply restate the answer.\\n\\nProvide your response in a concise manner, focusing solely on the corrected or verified answer without additional explanations.\\n\\\"\\\"\\\"\\n\\nENTITY_DISAMBIGUATION_PROMPT = \\\"\\\"\\\"\\nGiven the question and the name-extracted answer, perform entity disambiguation to ensure the correct identification of individuals, companies, or other entities mentioned. Consider:\\n\\n1. Different entities with similar names\\n2. Context-specific identities (e.g., a person's role in a specific project)\\n3. Common misconceptions or frequently confused entities\\n\\nIf there's any ambiguity or potential misidentification, clarify the entity's identity based on the context of the question. If no disambiguation is needed, restate the answer.\\n\\nProvide your response in a concise manner, focusing solely on the disambiguated or verified answer without additional explanations.\\n\\\"\\\"\\\"\\n\\nIDENTITY_CHECK_PROMPT = \\\"\\\"\\\"\\nGiven the question and the disambiguated answer, perform a thorough identity check, especially for individuals who may have changed their names, use stage names, or have multiple identities. Consider:\\n\\n1. Birth names vs. stage names or pseudonyms\\n2. Name changes due to personal reasons (e.g., marriage, gender transition)\\n3. Professional names vs. legal names\\n\\nIf the answer involves a person's identity and there's a discrepancy or additional information about their name, provide the most accurate and relevant name based on the context of the question. If no changes are needed, restate the answer.\\n\\nProvide your response in a concise manner, focusing solely on the verified or corrected identity without additional explanations.\\n\\\"\\\"\\\"\\n\\nFACT_CHECK_PROMPT = \\\"\\\"\\\"\\nGiven the question and the identity-checked answer, carefully analyze the information provided and perform a fact-check. If you find any inconsistencies or errors in the answer, provide a corrected version. If the answer appears accurate, simply restate it. Focus on verifying key facts, names, dates, and other critical information related to the question.\\n\\nYour task:\\n1. Analyze the question and the answer.\\n2. Identify any potential errors or inconsistencies.\\n3. If errors are found, provide a corrected answer.\\n4. If no errors are found, restate the answer.\\n\\nProvide your response in a concise manner, focusing solely on the corrected or verified answer without additional explanations.\\n\\\"\\\"\\\"\\n\\nSTYLE_CHECK_PROMPT = \\\"\\\"\\\"\\nReview the fact-checked answer, focusing specifically on architectural and historical style terms. Verify the accuracy of any mentioned styles, ensuring they are correctly identified and placed in the proper historical context. Pay special attention to:\\n\\n1. Architectural styles (e.g., Gothic, Baroque, Neoclassical)\\n2. Historical periods and their associated styles\\n3. Relationships between different styles (e.g., which style influenced or preceded another)\\n\\nIf you find any errors or misidentifications in the architectural or historical style terms, provide a corrected version. If the answer is accurate, simply restate it. Be concise and direct in your response, providing only the verified or corrected answer without explanations.\\n\\\"\\\"\\\"\\n\\nADDITIONAL_VERIFICATION_PROMPT = \\\"\\\"\\\"\\nPerform an additional verification on the previously style-checked answer. Focus on:\\n\\n1. Consistency with the question\\n2. Accuracy of specific details (names, dates, places, styles)\\n3. Completeness of the answer\\n4. Ensure the answer is a single word, number, or short phrase when appropriate\\n\\nIf any issues are found, provide a corrected version. If the answer is accurate and complete, restate it. Be concise and direct in your response, providing only the verified or corrected answer without explanations.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 16</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.round_16.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.answer_generate = operator.AnswerGenerate(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):\n            initial_response = await self.answer_generate(input=problem)\n            thought_process = initial_response['thought']\n            initial_answer = initial_response['answer']\n            solutions.append(initial_answer)\n\n        ensemble_result = await self.sc_ensemble(solutions=solutions)\n        best_answer = ensemble_result['response']\n        \n        name_extracted_answer = await self.custom(\n            input=f\"Question: {problem}\\nBest answer: {best_answer}\",\n            instruction=prompt_custom.NAME_EXTRACTION_PROMPT\n        )\n        \n        identity_check_answer = await self.custom(\n            input=f\"Question: {problem}\\nName-extracted answer: {name_extracted_answer['response']}\",\n            instruction=prompt_custom.IDENTITY_CHECK_PROMPT\n        )\n        \n        profession_check_answer = await self.custom(\n            input=f\"Question: {problem}\\nIdentity-checked answer: {identity_check_answer['response']}\",\n            instruction=prompt_custom.PROFESSION_CHECK_PROMPT\n        )\n        \n        fact_checked_answer = await self.custom(\n            input=f\"Question: {problem}\\nProfession-checked answer: {profession_check_answer['response']}\",\n            instruction=prompt_custom.FACT_CHECK_PROMPT\n        )\n        \n        style_check_answer = await self.custom(\n            input=f\"Question: {problem}\\nFact-checked answer: {fact_checked_answer['response']}\",\n            instruction=prompt_custom.STYLE_CHECK_PROMPT\n        )\n        \n        additional_verification = await self.custom(\n            input=f\"Question: {problem}\\nStyle-checked answer: {style_check_answer['response']}\",\n            instruction=prompt_custom.ADDITIONAL_VERIFICATION_PROMPT\n        )\n        \n        refined_solution = await self.custom(\n            input=f\"Question: {problem}\\nDouble-verified answer: {additional_verification['response']}\",\n            instruction=prompt_custom.FORMAT_ANSWER_PROMPT\n        )\n        \n        return refined_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>FORMAT_ANSWER_PROMPT = \"\"\"\nGiven the question and the double-verified answer, format the final answer to be extremely concise and directly addressing the question. Provide only the essential information without any explanation or additional context. For names, professions, or short phrases, give only that specific information.\n\nExamples:\n- For a person's name: \"John Doe\"\n- For a profession: \"Doctor\"\n- For a short phrase: \"Once in a blue moon\"\n\nDo not include any prefixes or explanatory text. Provide only the answer itself.\n\"\"\"\n\nNAME_EXTRACTION_PROMPT = \"\"\"\nGiven the question and the best answer, focus on extracting and verifying any names mentioned. Pay special attention to:\n\n1. Full names (first name, middle name, last name)\n2. Nicknames or aliases\n3. Correct spelling of names\n\nIf the answer contains a name, ensure it is accurate and complete. If a name is incorrect or incomplete, provide the correct full name. If no name is present or needed, simply restate the answer.\n\nProvide your response in a concise manner, focusing solely on the corrected or verified answer without additional explanations.\n\"\"\"\n\nIDENTITY_CHECK_PROMPT = \"\"\"\nGiven the question and the name-extracted answer, perform a thorough identity check, especially for individuals who may have changed their names, use stage names, or have multiple identities. Consider:\n\n1. Birth names vs. stage names or pseudonyms\n2. Name changes due to personal reasons (e.g., marriage, gender transition)\n3. Professional names vs. legal names\n\nIf the answer involves a person's identity and there's a discrepancy or additional information about their name, provide the most accurate and relevant name based on the context of the question. If no changes are needed, restate the answer.\n\nProvide your response in a concise manner, focusing solely on the verified or corrected identity without additional explanations.\n\"\"\"\n\nPROFESSION_CHECK_PROMPT = \"\"\"\nGiven the question and the identity-checked answer, focus on verifying and specifying any professions mentioned. Pay special attention to:\n\n1. Accurate job titles or occupations\n2. Specific roles within a broader field\n3. Multiple professions if applicable\n\nIf the answer involves a profession, ensure it is accurate and as specific as possible. If a profession is mentioned but is too general, provide a more precise description. If multiple professions are relevant, list them all.\n\nProvide your response in a concise manner, focusing solely on the verified or corrected profession(s) without additional explanations.\n\"\"\"\n\nFACT_CHECK_PROMPT = \"\"\"\nGiven the question and the profession-checked answer, carefully analyze the information provided and perform a fact-check. If you find any inconsistencies or errors in the answer, provide a corrected version. If the answer appears accurate, simply restate it. Focus on verifying key facts, names, dates, and other critical information related to the question.\n\nYour task:\n1. Analyze the question and the answer.\n2. Identify any potential errors or inconsistencies.\n3. If errors are found, provide a corrected answer.\n4. If no errors are found, restate the answer.\n\nProvide your response in a concise manner, focusing solely on the corrected or verified answer without additional explanations.\n\"\"\"\n\nSTYLE_CHECK_PROMPT = \"\"\"\nReview the fact-checked answer, focusing specifically on architectural and historical style terms. Verify the accuracy of any mentioned styles, ensuring they are correctly identified and placed in the proper historical context. Pay special attention to:\n\n1. Architectural styles (e.g., Gothic, Baroque, Neoclassical)\n2. Historical periods and their associated styles\n3. Relationships between different styles (e.g., which style influenced or preceded another)\n\nIf you find any errors or misidentifications in the architectural or historical style terms, provide a corrected version. If the answer is accurate, simply restate it. Be concise and direct in your response, providing only the verified or corrected answer without explanations.\n\"\"\"\n\nADDITIONAL_VERIFICATION_PROMPT = \"\"\"\nPerform an additional verification on the previously style-checked answer. Focus on:\n\n1. Consistency with the question\n2. Accuracy of specific details (names, dates, places, styles)\n3. Completeness of the answer\n4. Ensure the answer is a single word, number, or short phrase when appropriate\n\nIf any issues are found, provide a corrected version. If the answer is accurate and complete, restate it. Be concise and direct in your response, providing only the verified or corrected answer without explanations.\n\"\"\"</prompt>", "tag": "HotpotQA", "domain": "llm_judge", "parent_round": 15, "child_round": 16, "parent_score": 0.6197371256194785, "child_score": 0.6423561732385261, "performance_gain": 0.02261904761904765}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.87</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_9.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):\\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        # Add a review step using the Programmer operator\\n        review_result = await self.programmer(problem=problem, analysis=final_solution['response'])\\n        \\n        # Add a verification step using the Programmer operator\\n        verification_result = await self.programmer(problem=problem, analysis=f\\\"Verify if {review_result['output']} is the correct answer for the problem.\\\")\\n        \\n        if verification_result['output']:\\n            return verification_result['output'], self.llm.cost_manager.total_cost\\n        else:\\n            return review_result['output'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>MATH_SOLVE_PROMPT = \\\"\\\"\\\"\\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps:\\n\\n1. Carefully read and understand the problem.\\n2. Identify the key information and variables.\\n3. Determine the appropriate mathematical concepts or formulas to use.\\n4. Solve the problem step by step, showing all your work.\\n5. Double-check your calculations and reasoning.\\n6. Provide a clear and concise final answer.\\n\\nRemember to format your answer as follows:\\n- Use LaTeX notation for mathematical expressions where appropriate.\\n- Clearly state your final answer at the end of your solution.\\n- Express numerical answers as precise values (avoid rounding unless specified).\\n- Ensure that your final answer is a single numerical value without any units or additional text.\\n- Do not include any explanatory text with your final answer, just the number itself.\\n\\nFor example, if the final answer is 42.5, your response should end with just:\\n42.5\\n\\nHere's the problem to solve:\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 10</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_10.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(5):  # Generate 5 solutions\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\n            solutions.append(solution['response'])\n        \n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Add a verification step using the Programmer operator\n        verification = await self.programmer(problem=problem, analysis=final_solution['response'])\n        \n        if verification['output']:\n            return verification['output'], self.llm.cost_manager.total_cost\n        else:\n            return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>MATH_SOLVE_PROMPT = \"\"\"\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps carefully:\n\n1. Read and understand the problem thoroughly.\n2. Identify all key information, variables, and relationships.\n3. Determine the appropriate mathematical concepts, formulas, or equations to use.\n4. Solve the problem step-by-step, showing all your work clearly.\n5. Double-check your calculations and reasoning at each step.\n6. Provide a clear and concise final answer.\n7. Verify your solution by plugging it back into the original problem or using an alternative method if possible.\n\nFormat your answer as follows:\n- Use LaTeX notation for mathematical expressions where appropriate.\n- Show each step of your solution process clearly.\n- Clearly state your final answer at the end of your solution.\n- Express numerical answers as precise values (avoid rounding unless specified).\n- Ensure that your final answer is a single numerical value without any units or additional text.\n- Do not include any explanatory text with your final answer, just the number itself.\n\nFor example, if the final answer is 42.5, your response should end with just:\n42.5\n\nHere's the problem to solve:\n\n\"\"\"</prompt>", "tag": "GSM8K", "domain": "llm_judge", "parent_round": 9, "child_round": 10, "parent_score": 0.87, "child_score": 0.91, "performance_gain": 0.040000000000000036}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.8666666666666667</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_13.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        Custom operator to generate anything you want.\\n        But when you want to get standard code, you should use custom_code_generate operator.\\n        \\\"\\\"\\\"\\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=\\\"Generate a Python function to solve the given problem.\\\")\\n        \\n        # Review and improve the generated solution\\n        reviewed_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nGenerated solution: {solution['response']}\\\", instruction=prompt_custom.REVIEW_SOLUTION_PROMPT)\\n        \\n        # Test the reviewed solution\\n        test_result = await self.test(problem=problem, solution=reviewed_solution['response'], entry_point=entry_point)\\n        \\n        if test_result['result']:\\n            return test_result['solution'], self.llm.cost_manager.total_cost\\n        else:\\n            # If the test fails, try to improve the solution\\n            improved_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nFailed solution: {reviewed_solution['response']}\\\\nError: {test_result['solution']}\\\", instruction=prompt_custom.IMPROVE_SOLUTION_PROMPT)\\n            return improved_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>REVIEW_SOLUTION_PROMPT = \\\"\\\"\\\"\\nCarefully review the given problem and the generated solution. Your task is to analyze the code, identify any potential issues, and suggest improvements. Consider the following aspects:\\n\\n1. Correctness: Does the solution correctly address all aspects of the problem?\\n2. Efficiency: Is the solution optimized for performance?\\n3. Readability: Is the code clear and easy to understand?\\n4. Edge cases: Does the solution handle all possible input scenarios?\\n5. Best practices: Does the code follow Python best practices?\\n\\nIf you find any issues or areas for improvement, modify the code accordingly. If the solution looks good, you can return it as is.\\n\\nProvide only the reviewed and potentially improved Python function as your response, without any additional explanations or comments.\\n\\\"\\\"\\\"\\n\\nIMPROVE_SOLUTION_PROMPT = \\\"\\\"\\\"\\nAnalyze the given problem and the failed solution. Identify the errors and improve the code to solve the problem correctly. Make sure to handle edge cases and follow best practices in Python programming.\\n\\nYour task:\\n1. Understand the problem statement.\\n2. Review the failed solution and the error message.\\n3. Identify the cause of the failure.\\n4. Rewrite the solution, addressing the identified issues.\\n5. Ensure the new solution is complete, correct, and efficient.\\n\\nProvide only the improved Python function as your response, without any additional explanations or comments.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 14</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_14.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        \"\"\"\n        Implementation of the graph\n        Custom operator to generate anything you want.\n        But when you want to get standard code, you should use custom_code_generate operator.\n        \"\"\"\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=\"Generate a Python function to solve the given problem.\")\n        \n        # Review and improve the generated solution\n        reviewed_solution = await self.custom(input=f\"Problem: {problem}\\nGenerated solution: {solution['response']}\", instruction=prompt_custom.REVIEW_SOLUTION_PROMPT)\n        \n        # Test the reviewed solution\n        test_result = await self.test(problem=problem, solution=reviewed_solution['response'], entry_point=entry_point)\n        \n        if test_result['result']:\n            return test_result['solution'], self.llm.cost_manager.total_cost\n        else:\n            # If the test fails, try to improve the solution\n            improved_solution = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {reviewed_solution['response']}\\nError: {test_result['solution']}\", instruction=prompt_custom.IMPROVE_SOLUTION_PROMPT)\n            return improved_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>REVIEW_SOLUTION_PROMPT = \"\"\"\nReview the given problem and the generated solution. Analyze the code for correctness, efficiency, and adherence to best practices. Improve the solution if necessary.\n\nYour task:\n1. Understand the problem statement.\n2. Review the generated solution.\n3. Check for logical errors, edge cases, and potential improvements.\n4. Rewrite the solution if improvements are needed, or keep it as is if it's optimal.\n5. Ensure the final solution is complete, correct, and efficient.\n\nProvide only the reviewed and potentially improved Python function as your response, without any additional explanations or comments.\n\"\"\"\n\nIMPROVE_SOLUTION_PROMPT = \"\"\"\nAnalyze the given problem and the failed solution. Identify the errors and improve the code to solve the problem correctly. Make sure to handle edge cases and follow best practices in Python programming.\n\nYour task:\n1. Understand the problem statement.\n2. Review the failed solution and the error message.\n3. Identify the cause of the failure.\n4. Rewrite the solution, addressing the identified issues.\n5. Ensure the new solution is complete, correct, and efficient.\n\nProvide only the improved Python function as your response, without any additional explanations or comments.\n\"\"\"</prompt>", "tag": "HumanEval", "domain": "llm_judge", "parent_round": 13, "child_round": 14, "parent_score": 0.8666666666666667, "child_score": 0.9666666666666667, "performance_gain": 0.09999999999999998}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.6744186046511628</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_11.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        solutions = []\\n        for _ in range(3):\\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        # Add a review step\\n        reviewed_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nSolution: {best_solution['response']}\\\", instruction=prompt_custom.REVIEW_PROMPT)\\n        \\n        test_result = await self.test(problem=problem, solution=reviewed_solution['response'], entry_point=entry_point)\\n        \\n        if test_result['result']:\\n            return test_result['solution'], self.llm.cost_manager.total_cost\\n        else:\\n            fixed_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nFailed solution: {reviewed_solution['response']}\\\\nError: {test_result['solution']}\\\", instruction=prompt_custom.FIX_CODE_PROMPT)\\n            return fixed_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>CODE_GENERATE_PROMPT = \\\"\\\"\\\"\\nGenerate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity.\\n\\nProblem:\\n{problem}\\n\\nFunction signature:\\n{entry_point}\\n\\nGenerate the complete function below:\\n\\\"\\\"\\\"\\n\\nFIX_CODE_PROMPT = \\\"\\\"\\\"\\nThe provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation.\\n\\nProblem:\\n{input}\\n\\nProvide the corrected function below:\\n\\\"\\\"\\\"\\n\\nREVIEW_PROMPT = \\\"\\\"\\\"\\nReview and improve the following Python function. Ensure it correctly solves the given problem, follows best practices, and is optimized for performance. If necessary, refactor the code, add error handling, or improve the algorithm.\\n\\nProblem:\\n{input}\\n\\nProvide the improved function below:\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 12</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_12.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\n        \n        # Add a review step to improve the initial solution\n        reviewed_solution = await self.custom(input=f\"Problem: {problem}\\nInitial solution: {solution['response']}\", instruction=prompt_custom.REVIEW_PROMPT)\n        \n        test_result = await self.test(problem=problem, solution=reviewed_solution['response'], entry_point=entry_point)\n        \n        if test_result['result']:\n            return test_result['solution'], self.llm.cost_manager.total_cost\n        else:\n            fixed_solution = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {reviewed_solution['response']}\\nError: {test_result['solution']}\", instruction=prompt_custom.FIX_CODE_PROMPT)\n            return fixed_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>CODE_GENERATE_PROMPT = \"\"\"\nGenerate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity.\n\nProblem:\n{problem}\n\nFunction signature:\n{entry_point}\n\nGenerate the complete function below:\n\"\"\"\n\nREVIEW_PROMPT = \"\"\"\nReview and improve the following Python function. Ensure it correctly solves the given problem, uses appropriate data structures and algorithms, and follows best practices for code readability and efficiency. If improvements are necessary, provide the updated function.\n\nProblem:\n{input}\n\nProvide the reviewed and improved function below:\n\"\"\"\n\nFIX_CODE_PROMPT = \"\"\"\nThe provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation.\n\nProblem:\n{input}\n\nProvide the corrected function below:\n\"\"\"</prompt>", "tag": "MBPP", "domain": "llm_judge", "parent_round": 11, "child_round": 12, "parent_score": 0.6744186046511628, "child_score": 0.6046511627906976, "performance_gain": -0.06976744186046513}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>\\nPrevious failed modifications:\\n  - Add a review step using the Custom operator to evaluate and improve the best solution before testing. (Score: 0.5930232558139534)\\n  - Add a new Custom operator to generate test cases before the final test step. This will help ensure the solution is tested more thoroughly before submission. (Score: 0.7930232558139536)\\n  - Add a code review step using the Custom operator to evaluate and improve the best solution before testing. (Score: 0.786046511627907)</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.8023255813953488</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_14.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        Custom operator to generate anything you want.\\n        But when you want to get standard code, you should use custom_code_generate operator.\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):  # Generate 3 solutions\\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        test_result = await self.test(problem=problem, solution=best_solution['response'], entry_point=entry_point)\\n        \\n        if test_result['result']:\\n            return test_result['solution'], self.llm.cost_manager.total_cost\\n        else:\\n            # If the test fails, try to fix the solution\\n            fixed_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nFailed solution: {best_solution['response']}\\\\nError: {test_result['solution']}\\\", instruction=prompt_custom.FIX_CODE_PROMPT)\\n            return fixed_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>CODE_GENERATE_PROMPT = \\\"\\\"\\\"\\nGenerate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity.\\n\\nProblem:\\n{problem}\\n\\nFunction signature:\\n{entry_point}\\n\\nGenerate the complete function below:\\n\\\"\\\"\\\"\\n\\nFIX_CODE_PROMPT = \\\"\\\"\\\"\\nThe provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation.\\n\\nProblem:\\n{input}\\n\\nProvide the corrected function below:\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 15</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_15.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        solutions = []\n        for _ in range(3):\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\n            solutions.append(solution['response'])\n        \n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        test_result = await self.test(problem=problem, solution=best_solution['response'], entry_point=entry_point)\n        \n        if test_result['result']:\n            return test_result['solution'], self.llm.cost_manager.total_cost\n        else:\n            fixed_solution = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {best_solution['response']}\\nError: {test_result['solution']}\", instruction=prompt_custom.FIX_CODE_PROMPT)\n            return fixed_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>CODE_GENERATE_PROMPT = \"\"\"\nGenerate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity.\n\nProblem:\n{problem}\n\nFunction signature:\n{entry_point}\n\nGenerate the complete function below:\n\"\"\"\n\nFIX_CODE_PROMPT = \"\"\"\nThe provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation.\n\nProblem:\n{input}\n\nProvide the corrected function below:\n\"\"\"</prompt>", "tag": "MBPP", "domain": "llm_judge", "parent_round": 14, "child_round": 15, "parent_score": 0.8023255813953488, "child_score": 0.8488372093023255, "performance_gain": 0.046511627906976716}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.85</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_20.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(5):  # Generate 5 solutions\\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        # Add a verification step using the Programmer operator\\n        verification = await self.programmer(problem=problem, analysis=final_solution['response'])\\n        \\n        if verification['output']:\\n            return verification['output'], self.llm.cost_manager.total_cost\\n        else:\\n            return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>MATH_SOLVE_PROMPT = \\\"\\\"\\\"\\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps carefully:\\n\\n1. Read and understand the problem thoroughly, ensuring you consider all given information.\\n2. Identify all key information, variables, and relationships, including any percentages, additional costs, or multi-step calculations.\\n3. Determine the appropriate mathematical concepts, formulas, or equations to use.\\n4. Solve the problem step-by-step, showing all your work clearly.\\n5. If the problem involves multiple calculations or steps, ensure you complete all of them.\\n6. For problems involving costs or prices, always calculate the total cost, including any additional fees, percentages, or discounts mentioned.\\n7. Double-check your calculations and reasoning at each step.\\n8. Provide a clear and concise final answer.\\n9. Verify your solution by plugging it back into the original problem or using an alternative method if possible.\\n\\nFormat your answer as follows:\\n- Use LaTeX notation for mathematical expressions where appropriate.\\n- Show each step of your solution process clearly.\\n- Clearly state your final answer at the end of your solution.\\n- Express numerical answers as precise values (avoid rounding unless specified).\\n- Ensure that your final answer is a single numerical value without any units or additional text.\\n- Do not include any explanatory text with your final answer, just the number itself.\\n\\nFor example, if the final answer is 42.5, your response should end with just:\\n42.5\\n\\nHere's the problem to solve:\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 21</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_21.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(5):  # Generate 5 solutions\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\n            solutions.append(solution['response'])\n        \n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Add a verification step using the Programmer operator\n        verification = await self.programmer(problem=problem, analysis=final_solution['response'])\n        \n        if verification['output']:\n            final_answer = verification['output']\n        else:\n            final_answer = final_solution['response']\n\n        # Final check to ensure the answer is a single number\n        try:\n            final_answer = float(final_answer)\n        except ValueError:\n            final_answer = float(final_answer.split()[-1])\n\n        return str(final_answer), self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>MATH_SOLVE_PROMPT = \"\"\"\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps carefully:\n\n1. Read and understand the problem thoroughly, paying special attention to time-based calculations and total cost considerations including any discounts.\n2. Identify all key information, variables, and relationships, especially those related to time periods and pricing.\n3. Determine the appropriate mathematical concepts, formulas, or equations to use, including time conversion if necessary.\n4. Solve the problem step-by-step, showing all your work clearly.\n5. For problems involving time:\n   - Convert all time periods to the same unit (e.g., minutes or hours)\n   - Calculate the total time period carefully\n6. For problems involving costs:\n   - Include all mentioned costs and discounts\n   - Calculate the total cost, factoring in any discounts or special pricing\n7. Double-check your calculations and reasoning at each step.\n8. Provide a clear and concise final answer.\n9. Verify your solution by plugging it back into the original problem or using an alternative method if possible.\n\nFormat your answer as follows:\n- Use LaTeX notation for mathematical expressions where appropriate.\n- Show each step of your solution process clearly.\n- Clearly state your final answer at the end of your solution.\n- Express numerical answers as precise values (avoid rounding unless specified).\n- Ensure that your final answer is a single numerical value without any units or additional text.\n- Do not include any explanatory text with your final answer, just the number itself.\n\nFor example, if the final answer is 42.5, your response should end with just:\n42.5\n\nHere's the problem to solve:\n\n\"\"\"</prompt>", "tag": "GSM8K", "domain": "llm_judge", "parent_round": 20, "child_round": 21, "parent_score": 0.85, "child_score": 0.88, "performance_gain": 0.030000000000000027}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.7790697674418605</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_18.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        solutions = []\\n        for _ in range(3):  # Generate 3 solutions\\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        # Generate additional test cases\\n        additional_tests = await self.custom(input=f\\\"Problem: {problem}\\\\nSolution: {best_solution['response']}\\\", instruction=prompt_custom.GENERATE_TESTS_PROMPT)\\n        \\n        # Combine original problem and additional tests\\n        enhanced_problem = f\\\"{problem}\\\\n\\\\nAdditional test cases:\\\\n{additional_tests['response']}\\\"\\n        \\n        test_result = await self.test(problem=enhanced_problem, solution=best_solution['response'], entry_point=entry_point)\\n        \\n        if test_result['result']:\\n            return test_result['solution'], self.llm.cost_manager.total_cost\\n        else:\\n            # If the test fails, try to fix the solution\\n            fixed_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nFailed solution: {best_solution['response']}\\\\nError: {test_result['solution']}\\\", instruction=prompt_custom.FIX_CODE_PROMPT)\\n            return fixed_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>CODE_GENERATE_PROMPT = \\\"\\\"\\\"\\nGenerate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity.\\n\\nProblem:\\n{problem}\\n\\nFunction signature:\\n{entry_point}\\n\\nGenerate the complete function below:\\n\\\"\\\"\\\"\\n\\nFIX_CODE_PROMPT = \\\"\\\"\\\"\\nThe provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation.\\n\\nProblem:\\n{input}\\n\\nProvide the corrected function below:\\n\\\"\\\"\\\"\\n\\nGENERATE_TESTS_PROMPT = \\\"\\\"\\\"\\nGiven the problem and a potential solution, generate additional test cases to thoroughly evaluate the function. Include edge cases and typical scenarios. Format the test cases as assert statements that can be directly added to a Python test function.\\n\\nProblem:\\n{input}\\n\\nGenerate 3-5 additional test cases as assert statements:\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 19</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_19.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        solutions = []\n        for _ in range(3):  # Generate 3 solutions\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\n            solutions.append(solution['response'])\n        \n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Add a review step\n        reviewed_solution = await self.custom(input=f\"Problem: {problem}\\nSolution: {best_solution['response']}\", instruction=prompt_custom.REVIEW_PROMPT)\n        \n        test_result = await self.test(problem=problem, solution=reviewed_solution['response'], entry_point=entry_point)\n        \n        if test_result['result']:\n            return test_result['solution'], self.llm.cost_manager.total_cost\n        else:\n            # If the test fails, try to fix the solution\n            fixed_solution = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {reviewed_solution['response']}\\nError: {test_result['solution']}\", instruction=prompt_custom.FIX_CODE_PROMPT)\n            return fixed_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>CODE_GENERATE_PROMPT = \"\"\"\nGenerate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity.\n\nProblem:\n{problem}\n\nFunction signature:\n{entry_point}\n\nGenerate the complete function below:\n\"\"\"\n\nREVIEW_PROMPT = \"\"\"\nReview the following solution for the given problem. Identify any potential issues, inefficiencies, or areas for improvement. Provide an improved version of the code if necessary.\n\nProblem:\n{input}\n\nProvide the reviewed and improved function below:\n\"\"\"\n\nFIX_CODE_PROMPT = \"\"\"\nThe provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation.\n\nProblem:\n{input}\n\nProvide the corrected function below:\n\"\"\"</prompt>", "tag": "MBPP", "domain": "llm_judge", "parent_round": 18, "child_round": 19, "parent_score": 0.7790697674418605, "child_score": 0.627906976744186, "performance_gain": -0.15116279069767447}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.87</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_19.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):\\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        ensemble_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        # Verification step using the Programmer operator\\n        verification_result = await self.programmer(problem=problem, analysis=ensemble_solution['response'])\\n        \\n        # Final review step using ScEnsemble\\n        final_solutions = [ensemble_solution['response'], verification_result['output']]\\n        final_result = await self.sc_ensemble(solutions=final_solutions, problem=problem)\\n        \\n        return final_result['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>MATH_SOLVE_PROMPT = \\\"\\\"\\\"\\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps:\\n\\n1. Carefully read and understand the problem.\\n2. Identify the key information and variables.\\n3. Determine the appropriate mathematical concepts or formulas to use.\\n4. Perform any necessary unit conversions before calculations.\\n5. Solve the problem step by step, showing all your work.\\n6. Double-check your calculations, reasoning, and unit conversions.\\n7. Provide a clear and concise final answer.\\n\\nRemember to format your answer as follows:\\n- Use LaTeX notation for mathematical expressions where appropriate.\\n- Clearly state your final answer at the end of your solution.\\n- Express numerical answers as precise values (avoid rounding unless specified).\\n- Ensure that your final answer is a single numerical value without any units or additional text.\\n- Do not include any explanatory text with your final answer, just the number itself.\\n\\nFor example, if the final answer is 42.5, your response should end with just:\\n42.5\\n\\nHere's the problem to solve:\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 20</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_20.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(5):  # Generate 5 solutions\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\n            solutions.append(solution['response'])\n        \n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Add a verification step using the Programmer operator\n        verification = await self.programmer(problem=problem, analysis=final_solution['response'])\n        \n        if verification['output']:\n            return verification['output'], self.llm.cost_manager.total_cost\n        else:\n            return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>MATH_SOLVE_PROMPT = \"\"\"\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps carefully:\n\n1. Read and understand the problem thoroughly, ensuring you consider all given information.\n2. Identify all key information, variables, and relationships, including any percentages, additional costs, or multi-step calculations.\n3. Determine the appropriate mathematical concepts, formulas, or equations to use.\n4. Solve the problem step-by-step, showing all your work clearly.\n5. If the problem involves multiple calculations or steps, ensure you complete all of them.\n6. For problems involving costs or prices, always calculate the total cost, including any additional fees, percentages, or discounts mentioned.\n7. Double-check your calculations and reasoning at each step.\n8. Provide a clear and concise final answer.\n9. Verify your solution by plugging it back into the original problem or using an alternative method if possible.\n\nFormat your answer as follows:\n- Use LaTeX notation for mathematical expressions where appropriate.\n- Show each step of your solution process clearly.\n- Clearly state your final answer at the end of your solution.\n- Express numerical answers as precise values (avoid rounding unless specified).\n- Ensure that your final answer is a single numerical value without any units or additional text.\n- Do not include any explanatory text with your final answer, just the number itself.\n\nFor example, if the final answer is 42.5, your response should end with just:\n42.5\n\nHere's the problem to solve:\n\n\"\"\"</prompt>", "tag": "GSM8K", "domain": "llm_judge", "parent_round": 19, "child_round": 20, "parent_score": 0.87, "child_score": 0.9, "performance_gain": 0.030000000000000027}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve QA problems.\\nReferring to the given graph and prompt, which forms a basic example of a QA solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.6136941408312641</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_19.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.answer_generate = operator.AnswerGenerate(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):  # Generate 3 solutions\\n            step_by_step = await self.answer_generate(input=problem)\\n            solution = await self.custom(input=f\\\"Question: {problem}\\\\nStep-by-step solution: {step_by_step['thought']}\\\\nInitial answer: {step_by_step['answer']}\\\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\\n            verified_solution = await self.custom(input=f\\\"Question: {problem}\\\\nStep-by-step solution: {step_by_step['thought']}\\\\nRefined answer: {solution['response']}\\\", instruction=prompt_custom.VERIFY_NUMERICAL_ANSWER_PROMPT)\\n            solutions.append(verified_solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions)\\n        return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\\n\\n1. Ensure the answer is concise and directly addresses the question.\\n2. If the answer is a number, provide only the number without additional text.\\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\\n4. Remove any explanations or reasoning from the final answer.\\n5. Double-check that the refined answer is consistent with the step-by-step solution and initial answer.\\n6. If the answer involves selecting between options, clearly state the chosen option.\\n\\nYour task is to extract or refine the most accurate answer based on the provided information.\\n\\\"\\\"\\\"\\n\\nVERIFY_NUMERICAL_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question, step-by-step solution, and refined answer, please verify and correct the numerical answer if necessary. Follow these guidelines:\\n\\n1. Check if the answer is consistent with the question and step-by-step solution.\\n2. Ensure the answer is a number or numbers separated by a vertical bar (|) if multiple answers are possible.\\n3. If the answer is incorrect or inconsistent, recalculate based on the step-by-step solution.\\n4. Remove any non-numeric characters or explanations, keeping only the numerical value(s).\\n5. If the question asks for a difference or comparison between values, double-check the calculation.\\n6. If no numerical answer is required, return the refined answer as is.\\n\\nYour task is to provide the most accurate numerical answer based on the given information and calculations.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 20</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_20.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.answer_generate = operator.AnswerGenerate(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):\n            step_by_step = await self.answer_generate(input=problem)\n            solution = await self.custom(input=f\"Question: {problem}\\nStep-by-step solution: {step_by_step['thought']}\\nInitial answer: {step_by_step['answer']}\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n            solutions.append(solution['response'])\n        \n        final_solution = await self.sc_ensemble(solutions=solutions)\n        return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>REFINE_ANSWER_PROMPT = \"\"\"\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\n\n1. Ensure the answer is concise and directly addresses the question.\n2. If the answer is a number, provide only the number without additional text.\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\n4. Remove any explanations or reasoning from the final answer.\n5. Double-check the calculation and reasoning to ensure accuracy.\n6. If the answer involves a range or multiple possibilities, include all valid options.\n\nYour task is to extract or refine the most accurate answer based on the provided information.\n\n\"\"\"</prompt>", "tag": "DROP", "domain": "llm_judge", "parent_round": 19, "child_round": 20, "parent_score": 0.6136941408312641, "child_score": 0.7348039215686274, "performance_gain": 0.12110978073736334}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.8372093023255814</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_8.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        # Analyze problem and generate test cases\\n        analysis = await self.custom(input=problem, instruction=prompt_custom.ANALYZE_PROBLEM_PROMPT)\\n        \\n        solutions = []\\n        for _ in range(3):  # Generate 3 solutions\\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT + f\\\"\\\\nProblem analysis: {analysis['response']}\\\")\\n            solutions.append(solution['response'])\\n        \\n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        test_result = await self.test(problem=problem, solution=best_solution['response'], entry_point=entry_point)\\n        \\n        if test_result['result']:\\n            return test_result['solution'], self.llm.cost_manager.total_cost\\n        else:\\n            fixed_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nFailed solution: {best_solution['response']}\\\\nError: {test_result['solution']}\\\", instruction=prompt_custom.FIX_CODE_PROMPT)\\n            return fixed_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>ANALYZE_PROBLEM_PROMPT = \\\"\\\"\\\"\\nAnalyze the given problem and generate a set of test cases that cover various scenarios. Consider edge cases, typical inputs, and potential pitfalls. Your analysis should include:\\n1. A brief description of the problem\\n2. Key considerations for implementation\\n3. A list of at least 3 test cases with expected outputs\\n\\nProblem:\\n{input}\\n\\nProvide your analysis below:\\n\\\"\\\"\\\"\\n\\nCODE_GENERATE_PROMPT = \\\"\\\"\\\"\\nGenerate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity.\\n\\nProblem:\\n{problem}\\n\\nFunction signature:\\n{entry_point}\\n\\nProblem analysis:\\n{analysis['response']}\\n\\nGenerate the complete function below:\\n\\\"\\\"\\\"\\n\\nFIX_CODE_PROMPT = \\\"\\\"\\\"\\nThe provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation.\\n\\nProblem:\\n{input}\\n\\nProvide the corrected function below:\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 10</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_10.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        solutions = []\n        for _ in range(3):\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\n            solutions.append(solution['response'])\n        \n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        test_result = await self.test(problem=problem, solution=best_solution['response'], entry_point=entry_point)\n        \n        if test_result['result']:\n            return test_result['solution'], self.llm.cost_manager.total_cost\n        else:\n            fixed_solution = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {best_solution['response']}\\nError: {test_result['solution']}\", instruction=prompt_custom.FIX_CODE_PROMPT)\n            return fixed_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>CODE_GENERATE_PROMPT = \"\"\"\nGenerate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity.\n\nProblem:\n{problem}\n\nFunction signature:\n{entry_point}\n\nGenerate the complete function below:\n\"\"\"\n\nFIX_CODE_PROMPT = \"\"\"\nThe provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation.\n\nProblem:\n{input}\n\nProvide the corrected function below:\n\"\"\"</prompt>", "tag": "MBPP", "domain": "llm_judge", "parent_round": 8, "child_round": 10, "parent_score": 0.8372093023255814, "child_score": 0.8488372093023255, "performance_gain": 0.011627906976744096}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.6333333333333333</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_3.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        Custom operator to generate anything you want.\\n        But when you want to get standard code, you should use custom_code_generate operator.\\n        \\\"\\\"\\\"\\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=\\\"\\\")\\n        \\n        # Add a review step using the Custom operator\\n        review_result = await self.custom(input=f\\\"Problem: {problem}\\\\nGenerated Solution: {solution['response']}\\\", instruction=prompt_custom.REVIEW_PROMPT)\\n        \\n        if \\\"Improved Solution:\\\" in review_result['response']:\\n            final_solution = review_result['response'].split(\\\"Improved Solution:\\\")[1].strip()\\n        else:\\n            final_solution = solution['response']\\n        \\n        return final_solution, self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>REVIEW_PROMPT = \\\"\\\"\\\"\\nReview the following problem and the generated solution. If you find any issues or potential improvements, provide an improved solution. If the solution is already optimal, state that no improvements are needed.\\n\\nProblem: {input}\\n\\nYour response should be in the following format:\\nReview: [Your review comments]\\nImproved Solution: [The improved solution if any, or \\\"No improvements needed\\\" if the original solution is optimal]\\n\\nEnsure that your review is thorough and that any improved solution addresses the problem correctly and efficiently.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 4</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_4.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\n        \n        # Add a review step\n        review = await self.custom(input=f\"Problem: {problem}\\nGenerated solution: {solution['response']}\", instruction=prompt_custom.REVIEW_PROMPT)\n        \n        # Improve the solution based on the review\n        improved_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\"{prompt_custom.CODE_GENERATE_PROMPT}\\n\\nConsider this review: {review['response']}\")\n        \n        test_result = await self.test(problem=problem, solution=improved_solution['response'], entry_point=entry_point)\n        \n        if not test_result['result']:\n            analysis = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {improved_solution['response']}\\nTest result: {test_result['solution']}\", instruction=prompt_custom.ANALYZE_AND_IMPROVE_PROMPT)\n            final_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\"{prompt_custom.CODE_GENERATE_PROMPT}\\n\\nConsider this analysis: {analysis['response']}\")\n            return final_solution['response'], self.llm.cost_manager.total_cost\n        \n        return improved_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>CODE_GENERATE_PROMPT = \"\"\"\nGenerate a Python function that solves the given problem. Ensure the function signature matches the problem description. Include docstrings and comments to explain the logic. The solution should be efficient and handle edge cases. Pay special attention to the order of operations and ensure that the function evaluates the expression correctly.\n\"\"\"\n\nREVIEW_PROMPT = \"\"\"\nReview the generated solution and suggest improvements. Consider the following:\n1. Does the function correctly implement the order of operations?\n2. Are all required operators (+, -, *, //, **) handled properly?\n3. Is there proper error handling for cases like division by zero?\n4. Does the function handle the case where the operator list is empty?\n5. Is the code efficient and readable?\nProvide specific suggestions for improvement.\n\"\"\"\n\nANALYZE_AND_IMPROVE_PROMPT = \"\"\"\nAnalyze the failed solution and provide suggestions for improvement. Consider the following:\n1. Identify logical errors or misunderstandings of the problem.\n2. Check for edge cases that might not be handled correctly.\n3. Ensure the order of operations is correctly implemented.\n4. Suggest optimizations or alternative approaches if applicable.\n5. Provide specific code snippets or pseudocode to address the issues found.\n\"\"\"</prompt>", "tag": "HumanEval", "domain": "llm_judge", "parent_round": 3, "child_round": 4, "parent_score": 0.6333333333333333, "child_score": 0.9333333333333333, "performance_gain": 0.30000000000000004}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.4369747899159664</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.round_8.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):\\n            solution = await self.custom(input=problem, instruction=prompt_custom.SOLVE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>SOLVE_PROMPT = \\\"\\\"\\\"\\nYou are a mathematical problem solver. Your task is to solve the given problem step by step, showing all your work. Follow these guidelines:\\n\\n1. Read the problem carefully and identify the key information.\\n2. Write out the given information and what needs to be found.\\n3. Choose the appropriate mathematical concept or formula to solve the problem.\\n4. Show each step of your calculation clearly.\\n5. Check your answer to make sure it makes sense in the context of the problem.\\n6. Provide a clear, concise final answer.\\n\\nRemember to use proper mathematical notation and explain your reasoning at each step. If there are multiple ways to solve the problem, choose the most straightforward method.\\n\\nHere's the problem to solve:\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 9</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.round_9.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        # Use Programmer to generate and execute Python code\n        code_solution = await self.programmer(problem=problem)\n        \n        # Use Custom to refine and format the answer\n        refined_solution = await self.custom(input=problem + f\"\\nCode output: {code_solution['output']}\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n        \n        # Generate multiple solutions using Custom\n        solutions = []\n        for _ in range(3):\n            solution = await self.custom(input=problem, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT)\n            solutions.append(solution['response'])\n        \n        # Generate a detailed step-by-step solution\n        detailed_solution = await self.custom(input=problem, instruction=prompt_custom.DETAILED_SOLUTION_PROMPT)\n        solutions.append(detailed_solution['response'])\n        \n        # Use ScEnsemble to select the best solution\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>REFINE_ANSWER_PROMPT = \"\"\"\nGiven the mathematical problem and the output from the code execution, please provide a well-formatted and detailed solution. Follow these guidelines:\n\n1. Begin with a clear statement of the problem.\n2. Explain the approach and any formulas or concepts used.\n3. Show step-by-step calculations, using LaTeX notation for mathematical expressions.\n4. Interpret the code output and incorporate it into your explanation.\n5. Provide a final answer, enclosed in \\boxed{} LaTeX notation.\n6. Ensure all mathematical notation is in LaTeX format.\n\nYour response should be comprehensive, mathematically rigorous, and easy to follow.\n\"\"\"\n\nGENERATE_SOLUTION_PROMPT = \"\"\"\nPlease solve the given mathematical problem step by step. Follow these guidelines:\n\n1. State the problem clearly.\n2. Outline the approach and any relevant formulas or concepts.\n3. Provide detailed calculations, using LaTeX notation for mathematical expressions.\n4. Explain each step of your reasoning.\n5. Present the final answer enclosed in \\boxed{} LaTeX notation.\n6. Ensure all mathematical notation is in LaTeX format.\n\nYour solution should be thorough, mathematically sound, and easy to understand.\n\"\"\"\n\nDETAILED_SOLUTION_PROMPT = \"\"\"\nProvide a comprehensive, step-by-step solution to the given mathematical problem. Your response should include:\n\n1. A clear restatement of the problem.\n2. An explanation of the mathematical concepts and formulas involved.\n3. A detailed, logical progression of steps to solve the problem.\n4. Clear explanations for each step, including the reasoning behind it.\n5. All mathematical expressions and equations in LaTeX format.\n6. Visual aids or diagrams if applicable (described in text).\n7. A final answer clearly marked and enclosed in \\boxed{} LaTeX notation.\n8. A brief explanation of the significance of the answer in the context of the original problem.\n\nAim for clarity, accuracy, and thoroughness in your solution.\n\"\"\"</prompt>", "tag": "MATH", "domain": "llm_judge", "parent_round": 8, "child_round": 9, "parent_score": 0.4369747899159664, "child_score": 0.5630252100840336, "performance_gain": 0.12605042016806722}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve QA problems.\\nReferring to the given graph and prompt, which forms a basic example of a QA solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.6405228758169935</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_16.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.answer_generate = operator.AnswerGenerate(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):  # Generate 3 solutions\\n            step_by_step = await self.answer_generate(input=problem)\\n            solutions.append(step_by_step['answer'])\\n        \\n        ensemble_solution = await self.sc_ensemble(solutions=solutions)\\n        \\n        refined_solution = await self.custom(input=f\\\"Question: {problem}\\\\nBest solution: {ensemble_solution['response']}\\\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\\n        \\n        final_solution = await self.custom(input=f\\\"Question: {problem}\\\\nRefined answer: {refined_solution['response']}\\\", instruction=prompt_custom.EXTRACT_VALIDATE_PROMPT)\\n\\n        return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\\n\\n1. Ensure the answer is concise and directly addresses the question.\\n2. If the answer is a number, provide only the number without additional text.\\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\\n4. Remove any explanations or reasoning from the final answer.\\n\\nYour task is to extract or refine the most accurate answer based on the provided information.\\n\\\"\\\"\\\"\\n\\nEXTRACT_VALIDATE_PROMPT = \\\"\\\"\\\"\\nGiven the question and the refined answer, please extract and validate the numerical answer. Follow these guidelines:\\n\\n1. Extract only the numerical value from the refined answer.\\n2. Ensure the extracted number is relevant to the question asked.\\n3. If the answer is a decimal, maintain the original decimal places.\\n4. If the answer is a whole number, do not add decimal places.\\n5. If no valid numerical answer can be extracted, respond with \\\"Unable to extract a valid numerical answer.\\\"\\n\\nProvide only the extracted and validated numerical answer without any additional text or explanations.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 17</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_17.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.answer_generate = operator.AnswerGenerate(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):  # Generate 3 solutions\n            step_by_step = await self.answer_generate(input=problem)\n            solution = await self.custom(input=f\"Question: {problem}\\nStep-by-step solution: {step_by_step['thought']}\\nInitial answer: {step_by_step['answer']}\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n            solutions.append(solution['response'])\n        \n        final_solution = await self.sc_ensemble(solutions=solutions)\n        \n        # Add verification step\n        verified_solution = await self.custom(input=f\"Question: {problem}\\nProposed answer: {final_solution['response']}\", instruction=prompt_custom.VERIFY_ANSWER_PROMPT)\n        \n        return verified_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>REFINE_ANSWER_PROMPT = \"\"\"\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\n\n1. Ensure the answer is concise and directly addresses the question.\n2. If the answer is a number, provide only the number without additional text.\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\n4. Remove any explanations or reasoning from the final answer.\n5. Double-check that the refined answer is consistent with the step-by-step solution and initial answer.\n6. If the answer involves selecting between options, clearly state the chosen option.\n\nYour task is to extract or refine the most accurate answer based on the provided information.\n\"\"\"\n\nVERIFY_ANSWER_PROMPT = \"\"\"\nGiven the question and the proposed answer, please verify and format the answer according to the following rules:\n\n1. If the answer is a single number, ensure it's provided without any units or additional text (e.g., \"5\" instead of \"5%\").\n2. If the answer consists of multiple numbers, separate them with a vertical bar (|) without spaces (e.g., \"3|20|32\").\n3. Remove any explanatory text or reasoning from the answer.\n4. Ensure the answer directly addresses the question without any extraneous information.\n5. If the original answer doesn't meet these criteria, modify it to comply.\n\nProvide only the verified and formatted answer without any additional explanation.\n\"\"\"</prompt>", "tag": "DROP", "domain": "llm_judge", "parent_round": 16, "child_round": 17, "parent_score": 0.6405228758169935, "child_score": 0.7044117647058823, "performance_gain": 0.06388888888888877}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>Previous successful modifications:\\n  - Add a CustomCodeGenerate step to generate multiple solutions, then use ScEnsemble to select the best one before testing. This approach leverages the ensemble technique to potentially improve the quality of the generated solution. (Score: 0.841860465116279)\\n\\nPrevious failed modifications:\\n  - Add a review step using the Custom operator to evaluate and improve the best solution before testing. (Score: 0.6465116279069768)</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.8488372093023255</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_10.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        solutions = []\\n        for _ in range(3):\\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        test_result = await self.test(problem=problem, solution=best_solution['response'], entry_point=entry_point)\\n        \\n        if test_result['result']:\\n            return test_result['solution'], self.llm.cost_manager.total_cost\\n        else:\\n            fixed_solution = await self.custom(input=f\\\"Problem: {problem}\\\\nFailed solution: {best_solution['response']}\\\\nError: {test_result['solution']}\\\", instruction=prompt_custom.FIX_CODE_PROMPT)\\n            return fixed_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>CODE_GENERATE_PROMPT = \\\"\\\"\\\"\\nGenerate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity.\\n\\nProblem:\\n{problem}\\n\\nFunction signature:\\n{entry_point}\\n\\nGenerate the complete function below:\\n\\\"\\\"\\\"\\n\\nFIX_CODE_PROMPT = \\\"\\\"\\\"\\nThe provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation.\\n\\nProblem:\\n{input}\\n\\nProvide the corrected function below:\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Add a review step using the Custom operator to evaluate and improve the best solution before testing.</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.MBPP.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.MBPP.graphs.round_11.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        solutions = []\n        for _ in range(3):\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\n            solutions.append(solution['response'])\n        \n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Add a review step\n        reviewed_solution = await self.custom(input=f\"Problem: {problem}\\nSolution: {best_solution['response']}\", instruction=prompt_custom.REVIEW_PROMPT)\n        \n        test_result = await self.test(problem=problem, solution=reviewed_solution['response'], entry_point=entry_point)\n        \n        if test_result['result']:\n            return test_result['solution'], self.llm.cost_manager.total_cost\n        else:\n            fixed_solution = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {reviewed_solution['response']}\\nError: {test_result['solution']}\", instruction=prompt_custom.FIX_CODE_PROMPT)\n            return fixed_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>CODE_GENERATE_PROMPT = \"\"\"\nGenerate a Python function to solve the given problem. Ensure the function name matches the one specified in the problem. Include necessary imports. Use clear variable names and add comments for clarity.\n\nProblem:\n{problem}\n\nFunction signature:\n{entry_point}\n\nGenerate the complete function below:\n\"\"\"\n\nFIX_CODE_PROMPT = \"\"\"\nThe provided solution failed to pass the tests. Please analyze the error and fix the code. Ensure the function name and signature remain unchanged. If necessary, add or modify imports, correct logical errors, and improve the implementation.\n\nProblem:\n{input}\n\nProvide the corrected function below:\n\"\"\"\n\nREVIEW_PROMPT = \"\"\"\nReview and improve the following Python function. Ensure it correctly solves the given problem, follows best practices, and is optimized for performance. If necessary, refactor the code, add error handling, or improve the algorithm.\n\nProblem:\n{input}\n\nProvide the improved function below:\n\"\"\"</prompt>", "tag": "MBPP", "domain": "llm_judge", "parent_round": 10, "child_round": 11, "parent_score": 0.8488372093023255, "child_score": 0.6744186046511628, "performance_gain": -0.17441860465116277}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve QA problems.\\nReferring to the given graph and prompt, which forms a basic example of a QA solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.588597505634338</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_19.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.answer_generate = operator.AnswerGenerate(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):  # Generate 3 solutions\\n            step_by_step = await self.answer_generate(input=problem)\\n            solution = await self.custom(input=f\\\"Question: {problem}\\\\nStep-by-step solution: {step_by_step['thought']}\\\\nInitial answer: {step_by_step['answer']}\\\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\\n            verified_solution = await self.custom(input=f\\\"Question: {problem}\\\\nStep-by-step solution: {step_by_step['thought']}\\\\nRefined answer: {solution['response']}\\\", instruction=prompt_custom.VERIFY_NUMERICAL_ANSWER_PROMPT)\\n            solutions.append(verified_solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions)\\n        return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\\n\\n1. Ensure the answer is concise and directly addresses the question.\\n2. If the answer is a number, provide only the number without additional text.\\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\\n4. Remove any explanations or reasoning from the final answer.\\n5. Double-check that the refined answer is consistent with the step-by-step solution and initial answer.\\n6. If the answer involves selecting between options, clearly state the chosen option.\\n\\nYour task is to extract or refine the most accurate answer based on the provided information.\\n\\\"\\\"\\\"\\n\\nVERIFY_NUMERICAL_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question, step-by-step solution, and refined answer, please verify and correct the numerical answer if necessary. Follow these guidelines:\\n\\n1. Check if the answer is consistent with the question and step-by-step solution.\\n2. Ensure the answer is a number or numbers separated by a vertical bar (|) if multiple answers are possible.\\n3. If the answer is incorrect or inconsistent, recalculate based on the step-by-step solution.\\n4. Remove any non-numeric characters or explanations, keeping only the numerical value(s).\\n5. If the question asks for a difference or comparison between values, double-check the calculation.\\n6. If no numerical answer is required, return the refined answer as is.\\n\\nYour task is to provide the most accurate numerical answer based on the given information and calculations.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 20</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_20.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.answer_generate = operator.AnswerGenerate(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):\n            step_by_step = await self.answer_generate(input=problem)\n            solution = await self.custom(input=f\"Question: {problem}\\nStep-by-step solution: {step_by_step['thought']}\\nInitial answer: {step_by_step['answer']}\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n            solutions.append(solution['response'])\n        \n        final_solution = await self.sc_ensemble(solutions=solutions)\n        return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>REFINE_ANSWER_PROMPT = \"\"\"\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\n\n1. Ensure the answer is concise and directly addresses the question.\n2. If the answer is a number, provide only the number without additional text.\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\n4. Remove any explanations or reasoning from the final answer.\n5. Double-check the calculation and reasoning to ensure accuracy.\n6. If the answer involves a range or multiple possibilities, include all valid options.\n\nYour task is to extract or refine the most accurate answer based on the provided information.\n\n\"\"\"</prompt>", "tag": "DROP", "domain": "llm_judge", "parent_round": 19, "child_round": 20, "parent_score": 0.588597505634338, "child_score": 0.7348039215686274, "performance_gain": 0.1462064159342894}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>\\nPrevious failed modifications:\\n  - Add a new Custom operator to generate a detailed step-by-step solution with explanations, and incorporate it into the ensemble process. This will provide a more comprehensive approach to solving math problems. (Score: 0.5159663865546219)\\n  - Add a new Custom operator to generate multiple solution approaches, then use ScEnsemble to select the best solution. This will increase the diversity of solutions and potentially improve accuracy. (Score: 0.0)\\n  - Add a new Custom operator to generate multiple solution approaches, then use ScEnsemble to select the best solution. This will increase the diversity of solutions and potentially improve accuracy. (Score: 0.5210084033613446)</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.5462184873949579</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.round_9.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        # Use Programmer to generate and execute Python code\\n        code_solution = await self.programmer(problem=problem)\\n        \\n        # Use Custom to refine and format the answer\\n        refined_solution = await self.custom(input=problem + f\\\"\\\\nCode output: {code_solution['output']}\\\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\\n        \\n        # Generate multiple solutions using Custom\\n        solutions = []\\n        for _ in range(3):\\n            solution = await self.custom(input=problem, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        # Generate a detailed step-by-step solution\\n        detailed_solution = await self.custom(input=problem, instruction=prompt_custom.DETAILED_SOLUTION_PROMPT)\\n        solutions.append(detailed_solution['response'])\\n        \\n        # Use ScEnsemble to select the best solution\\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the mathematical problem and the output from the code execution, please provide a well-formatted and detailed solution. Follow these guidelines:\\n\\n1. Begin with a clear statement of the problem.\\n2. Explain the approach and any formulas or concepts used.\\n3. Show step-by-step calculations, using LaTeX notation for mathematical expressions.\\n4. Interpret the code output and incorporate it into your explanation.\\n5. Provide a final answer, enclosed in \\\\boxed{} LaTeX notation.\\n6. Ensure all mathematical notation is in LaTeX format.\\n\\nYour response should be comprehensive, mathematically rigorous, and easy to follow.\\n\\\"\\\"\\\"\\n\\nGENERATE_SOLUTION_PROMPT = \\\"\\\"\\\"\\nPlease solve the given mathematical problem step by step. Follow these guidelines:\\n\\n1. State the problem clearly.\\n2. Outline the approach and any relevant formulas or concepts.\\n3. Provide detailed calculations, using LaTeX notation for mathematical expressions.\\n4. Explain each step of your reasoning.\\n5. Present the final answer enclosed in \\\\boxed{} LaTeX notation.\\n6. Ensure all mathematical notation is in LaTeX format.\\n\\nYour solution should be thorough, mathematically sound, and easy to understand.\\n\\\"\\\"\\\"\\n\\nDETAILED_SOLUTION_PROMPT = \\\"\\\"\\\"\\nProvide a comprehensive, step-by-step solution to the given mathematical problem. Your response should include:\\n\\n1. A clear restatement of the problem.\\n2. An explanation of the mathematical concepts and formulas involved.\\n3. A detailed, logical progression of steps to solve the problem.\\n4. Clear explanations for each step, including the reasoning behind it.\\n5. All mathematical expressions and equations in LaTeX format.\\n6. Visual aids or diagrams if applicable (described in text).\\n7. A final answer clearly marked and enclosed in \\\\boxed{} LaTeX notation.\\n8. A brief explanation of the significance of the answer in the context of the original problem.\\n\\nAim for clarity, accuracy, and thoroughness in your solution.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 10</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.round_10.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        # Use Programmer to generate and execute Python code\n        code_solution = await self.programmer(problem=problem)\n        \n        # Use Custom to refine and format the answer\n        refined_solution = await self.custom(input=problem + f\"\\nCode output: {code_solution['output']}\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n        \n        # Generate multiple solutions using Custom\n        solutions = []\n        for _ in range(3):\n            solution = await self.custom(input=problem, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT)\n            solutions.append(solution['response'])\n        \n        # Generate a step-by-step solution\n        step_by_step = await self.custom(input=problem, instruction=prompt_custom.STEP_BY_STEP_PROMPT)\n        solutions.append(step_by_step['response'])\n        \n        # Use ScEnsemble to select the most consistent and detailed solution\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>REFINE_ANSWER_PROMPT = \"\"\"\nGiven the mathematical problem and the output from the code execution, please provide a well-formatted and detailed solution. Follow these guidelines:\n\n1. Begin with a clear statement of the problem.\n2. Explain the approach and any formulas or concepts used.\n3. Show step-by-step calculations, using LaTeX notation for mathematical expressions.\n4. Interpret the code output and incorporate it into your explanation.\n5. Provide a final answer, enclosed in \\boxed{} LaTeX notation.\n6. Ensure all mathematical notation is in LaTeX format.\n\nYour response should be comprehensive, mathematically rigorous, and easy to follow.\n\"\"\"\n\nGENERATE_SOLUTION_PROMPT = \"\"\"\nPlease solve the given mathematical problem step by step. Follow these guidelines:\n\n1. State the problem clearly.\n2. Outline the approach and any relevant formulas or concepts.\n3. Provide detailed calculations, using LaTeX notation for mathematical expressions.\n4. Explain each step of your reasoning.\n5. Present the final answer enclosed in \\boxed{} LaTeX notation.\n6. Ensure all mathematical notation is in LaTeX format.\n\nYour solution should be thorough, mathematically sound, and easy to understand.\n\"\"\"\n\nSTEP_BY_STEP_PROMPT = \"\"\"\nProvide a detailed, step-by-step solution to the given mathematical problem. Follow these guidelines:\n\n1. Clearly state the problem and identify the key information given.\n2. Break down the solution into logical steps, numbering each step.\n3. For each step:\n   a. Explain the reasoning behind the step.\n   b. Show any calculations or transformations, using LaTeX notation for mathematical expressions.\n   c. Provide intermediate results.\n4. Use appropriate mathematical notation, formulas, and theorems, explaining them when first introduced.\n5. Include visual aids (e.g., diagrams, graphs) if they help clarify the solution, describing them in LaTeX format.\n6. Conclude with the final answer, enclosed in \\boxed{} LaTeX notation.\n7. Add a brief explanation of the significance of the result or any important observations.\n\nEnsure your solution is clear, concise, and mathematically rigorous, suitable for a student learning the concept.\n\"\"\"</prompt>", "tag": "MATH", "domain": "llm_judge", "parent_round": 9, "child_round": 10, "parent_score": 0.5462184873949579, "child_score": 0.5462184873949579, "performance_gain": 0.0}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>Previous successful modifications:\\n  - Add a review step using the Programmer operator to verify and potentially correct the final solution. (Score: 0.8720000000000001)</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.83</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_2.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):\\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>MATH_SOLVE_PROMPT = \\\"\\\"\\\"\\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps:\\n\\n1. Carefully read and understand the problem.\\n2. Identify the key information and variables.\\n3. Determine the appropriate mathematical concepts or formulas to use.\\n4. Solve the problem step by step, showing all your work.\\n5. Double-check your calculations and reasoning.\\n6. Provide a clear and concise final answer.\\n\\nRemember to format your answer as follows:\\n- Use LaTeX notation for mathematical expressions where appropriate.\\n- Clearly state your final answer at the end of your solution.\\n- Express numerical answers as precise values (avoid rounding unless specified).\\n\\nHere's the problem to solve:\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Add a review step using the Programmer operator to verify and potentially correct the final solution.</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_3.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\n            solutions.append(solution['response'])\n        \n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Add a review step using the Programmer operator\n        review_result = await self.programmer(problem=problem, analysis=final_solution['response'])\n        \n        if review_result['output']:\n            return review_result['output'], self.llm.cost_manager.total_cost\n        else:\n            return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>MATH_SOLVE_PROMPT = \"\"\"\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps:\n\n1. Carefully read and understand the problem.\n2. Identify the key information and variables.\n3. Determine the appropriate mathematical concepts or formulas to use.\n4. Solve the problem step by step, showing all your work.\n5. Double-check your calculations and reasoning.\n6. Provide a clear and concise final answer.\n\nRemember to format your answer as follows:\n- Use LaTeX notation for mathematical expressions where appropriate.\n- Clearly state your final answer at the end of your solution.\n- Express numerical answers as precise values (avoid rounding unless specified).\n- Ensure that your final answer is a single numerical value without any units or additional text.\n\nHere's the problem to solve:\n\n\"\"\"</prompt>", "tag": "GSM8K", "domain": "llm_judge", "parent_round": 2, "child_round": 3, "parent_score": 0.83, "child_score": 0.89, "performance_gain": 0.06000000000000005}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.9666666666666667</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_16.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=\\\"\\\")\\n        \\n        # Add a review step\\n        review = await self.custom(input=problem + f\\\"\\\\nGenerated solution:\\\\n{solution['response']}\\\", instruction=prompt_custom.REVIEW_PROMPT)\\n        \\n        if \\\"No issues found\\\" not in review['response']:\\n            # If issues are found, regenerate the solution\\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.IMPROVE_CODE_PROMPT + f\\\"\\\\nReview feedback: {review['response']}\\\")\\n        \\n        test_result = await self.test(problem=problem, solution=solution['response'], entry_point=entry_point)\\n        \\n        if test_result['result']:\\n            return test_result['solution'], self.llm.cost_manager.total_cost\\n        else:\\n            # If the test fails, try to generate a new solution\\n            new_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.IMPROVE_CODE_PROMPT)\\n            return new_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>IMPROVE_CODE_PROMPT = \\\"\\\"\\\"\\nThe previous solution failed some test cases. Please analyze the problem carefully and provide an improved solution that addresses all edge cases and requirements. Ensure your code is efficient and follows best practices.\\n\\\"\\\"\\\"\\n\\nREVIEW_PROMPT = \\\"\\\"\\\"\\nReview the generated solution and identify any potential issues, edge cases, or improvements. If no issues are found, respond with 'No issues found'. Otherwise, provide a brief description of the issues and suggested improvements.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 17</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_17.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        \"\"\"\n        Implementation of the graph\n        Custom operator to generate anything you want.\n        But when you want to get standard code, you should use custom_code_generate operator.\n        \"\"\"\n        # Generate multiple solutions using different prompts\n        solution1 = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT1)\n        solution2 = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT2)\n        solution3 = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT3)\n        \n        # Use ScEnsemble to select the best solution\n        solutions = [solution1['response'], solution2['response'], solution3['response']]\n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Review and improve the selected solution\n        reviewed_solution = await self.custom(input=f\"Problem: {problem}\\nGenerated solution: {best_solution['response']}\", instruction=prompt_custom.REVIEW_SOLUTION_PROMPT)\n        \n        # Test the reviewed solution\n        test_result = await self.test(problem=problem, solution=reviewed_solution['response'], entry_point=entry_point)\n        \n        if test_result['result']:\n            return test_result['solution'], self.llm.cost_manager.total_cost\n        else:\n            # If the test fails, try to improve the solution\n            improved_solution = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {reviewed_solution['response']}\\nError: {test_result['solution']}\", instruction=prompt_custom.IMPROVE_SOLUTION_PROMPT)\n            return improved_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>GENERATE_SOLUTION_PROMPT1 = \"\"\"\nGenerate a Python function to solve the given problem. Focus on correctness and efficiency.\n\"\"\"\n\nGENERATE_SOLUTION_PROMPT2 = \"\"\"\nCreate a Python function that solves the given problem. Pay special attention to edge cases and input validation.\n\"\"\"\n\nGENERATE_SOLUTION_PROMPT3 = \"\"\"\nDevelop a Python function to address the given problem. Prioritize readability and maintainability in your code.\n\"\"\"\n\nREVIEW_SOLUTION_PROMPT = \"\"\"\nReview the given problem and the generated solution. Analyze the code for correctness, efficiency, and adherence to best practices. Improve the solution if necessary.\n\nYour task:\n1. Understand the problem statement.\n2. Review the generated solution.\n3. Check for logical errors, edge cases, and potential improvements.\n4. Rewrite the solution if improvements are needed, or keep it as is if it's optimal.\n5. Ensure the final solution is complete, correct, and efficient.\n\nProvide only the reviewed and potentially improved Python function as your response, without any additional explanations or comments.\n\"\"\"\n\nIMPROVE_SOLUTION_PROMPT = \"\"\"\nAnalyze the given problem and the failed solution. Identify the errors and improve the code to solve the problem correctly. Make sure to handle edge cases and follow best practices in Python programming.\n\nYour task:\n1. Understand the problem statement.\n2. Review the failed solution and the error message.\n3. Identify the cause of the failure.\n4. Rewrite the solution, addressing the identified issues.\n5. Ensure the new solution is complete, correct, and efficient.\n\nProvide only the improved Python function as your response, without any additional explanations or comments.\n\"\"\"</prompt>", "tag": "HumanEval", "domain": "llm_judge", "parent_round": 16, "child_round": 17, "parent_score": 0.9666666666666667, "child_score": 0.9333333333333333, "performance_gain": -0.033333333333333326}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve QA problems.\\nReferring to the given graph and prompt, which forms a basic example of a QA solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.594798828622358</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.round_13.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.answer_generate = operator.AnswerGenerate(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):\\n            initial_response = await self.answer_generate(input=problem)\\n            thought_process = initial_response['thought']\\n            initial_answer = initial_response['answer']\\n            solutions.append(initial_answer)\\n\\n        ensemble_result = await self.sc_ensemble(solutions=solutions)\\n        best_answer = ensemble_result['response']\\n        \\n        refined_solution = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nBest answer: {best_answer}\\\",\\n            instruction=prompt_custom.REFINE_AND_FORMAT_ANSWER_PROMPT\\n        )\\n        \\n        final_answer = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nRefined answer: {refined_solution['response']}\\\",\\n            instruction=prompt_custom.EXTRACT_CORE_ANSWER_PROMPT\\n        )\\n        \\n        return final_answer['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_AND_FORMAT_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question and the best answer, refine and format the answer to be concise, accurate, and directly addressing the question. Ensure the answer is clear and brief, without additional explanation or reasoning. Focus on extracting the most relevant information.\\n\\nIf the answer is a name, profession, or short phrase, provide only that information. Do not include any prefixes like \\\"The answer is\\\" or \\\"The profession is\\\". Just provide the refined answer itself.\\n\\\"\\\"\\\"\\n\\nEXTRACT_CORE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question and the refined answer, extract the core information that directly answers the question. Provide only the essential details without any additional context or explanation. The output should be as concise as possible, ideally limited to a few words or a short phrase.\\n\\nFor names, provide only the name.\\nFor professions, state only the profession.\\nFor short phrases, give only that phrase.\\nFor years or dates, provide only the year or date.\\n\\nEnsure the extracted answer is the most relevant and accurate response to the question asked.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 14</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.round_14.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.answer_generate = operator.AnswerGenerate(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):\n            initial_response = await self.answer_generate(input=problem)\n            thought_process = initial_response['thought']\n            initial_answer = initial_response['answer']\n            solutions.append(initial_answer)\n\n        ensemble_result = await self.sc_ensemble(solutions=solutions)\n        best_answer = ensemble_result['response']\n        \n        name_extracted_answer = await self.custom(\n            input=f\"Question: {problem}\\nBest answer: {best_answer}\",\n            instruction=prompt_custom.NAME_EXTRACTION_PROMPT\n        )\n        \n        identity_check_answer = await self.custom(\n            input=f\"Question: {problem}\\nName-extracted answer: {name_extracted_answer['response']}\",\n            instruction=prompt_custom.IDENTITY_CHECK_PROMPT\n        )\n        \n        fact_checked_answer = await self.custom(\n            input=f\"Question: {problem}\\nIdentity-checked answer: {identity_check_answer['response']}\",\n            instruction=prompt_custom.FACT_CHECK_PROMPT\n        )\n        \n        style_check_answer = await self.custom(\n            input=f\"Question: {problem}\\nFact-checked answer: {fact_checked_answer['response']}\",\n            instruction=prompt_custom.STYLE_CHECK_PROMPT\n        )\n        \n        additional_verification = await self.custom(\n            input=f\"Question: {problem}\\nStyle-checked answer: {style_check_answer['response']}\",\n            instruction=prompt_custom.ADDITIONAL_VERIFICATION_PROMPT\n        )\n        \n        refined_solution = await self.custom(\n            input=f\"Question: {problem}\\nDouble-verified answer: {additional_verification['response']}\",\n            instruction=prompt_custom.FORMAT_ANSWER_PROMPT\n        )\n        \n        return refined_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>FORMAT_ANSWER_PROMPT = \"\"\"\nGiven the question and the double-verified answer, format the final answer to be extremely concise and directly addressing the question. Provide only the essential information without any explanation or additional context. For names, professions, or short phrases, give only that specific information.\n\nExamples:\n- For a person's name: \"John Doe\"\n- For a profession: \"Doctor\"\n- For a short phrase: \"Once in a blue moon\"\n\nDo not include any prefixes or explanatory text. Provide only the answer itself.\n\"\"\"\n\nNAME_EXTRACTION_PROMPT = \"\"\"\nGiven the question and the best answer, focus on extracting and verifying any names mentioned. Pay special attention to:\n\n1. Full names (first name, middle name, last name)\n2. Nicknames or aliases\n3. Correct spelling of names\n\nIf the answer contains a name, ensure it is accurate and complete. If a name is incorrect or incomplete, provide the correct full name. If no name is present or needed, simply restate the answer.\n\nProvide your response in a concise manner, focusing solely on the corrected or verified answer without additional explanations.\n\"\"\"\n\nIDENTITY_CHECK_PROMPT = \"\"\"\nGiven the question and the name-extracted answer, perform a thorough identity check, especially for individuals who may have changed their names, use stage names, or have multiple identities. Consider:\n\n1. Birth names vs. stage names or pseudonyms\n2. Name changes due to personal reasons (e.g., marriage, gender transition)\n3. Professional names vs. legal names\n\nIf the answer involves a person's identity and there's a discrepancy or additional information about their name, provide the most accurate and relevant name based on the context of the question. If no changes are needed, restate the answer.\n\nProvide your response in a concise manner, focusing solely on the verified or corrected identity without additional explanations.\n\"\"\"\n\nFACT_CHECK_PROMPT = \"\"\"\nGiven the question and the identity-checked answer, carefully analyze the information provided and perform a fact-check. If you find any inconsistencies or errors in the answer, provide a corrected version. If the answer appears accurate, simply restate it. Focus on verifying key facts, names, dates, and other critical information related to the question.\n\nYour task:\n1. Analyze the question and the answer.\n2. Identify any potential errors or inconsistencies.\n3. If errors are found, provide a corrected answer.\n4. If no errors are found, restate the answer.\n\nProvide your response in a concise manner, focusing solely on the corrected or verified answer without additional explanations.\n\"\"\"\n\nSTYLE_CHECK_PROMPT = \"\"\"\nReview the fact-checked answer, focusing specifically on architectural and historical style terms. Verify the accuracy of any mentioned styles, ensuring they are correctly identified and placed in the proper historical context. Pay special attention to:\n\n1. Architectural styles (e.g., Gothic, Baroque, Neoclassical)\n2. Historical periods and their associated styles\n3. Relationships between different styles (e.g., which style influenced or preceded another)\n\nIf you find any errors or misidentifications in the architectural or historical style terms, provide a corrected version. If the answer is accurate, simply restate it. Be concise and direct in your response, providing only the verified or corrected answer without explanations.\n\"\"\"\n\nADDITIONAL_VERIFICATION_PROMPT = \"\"\"\nPerform an additional verification on the previously style-checked answer. Focus on:\n\n1. Consistency with the question\n2. Accuracy of specific details (names, dates, places, styles)\n3. Completeness of the answer\n4. Ensure the answer is a single word, number, or short phrase when appropriate\n\nIf any issues are found, provide a corrected version. If the answer is accurate and complete, restate it. Be concise and direct in your response, providing only the verified or corrected answer without explanations.\n\"\"\"</prompt>", "tag": "HotpotQA", "domain": "llm_judge", "parent_round": 13, "child_round": 14, "parent_score": 0.594798828622358, "child_score": 0.6250509294626941, "performance_gain": 0.030252100840336138}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.8333333333333334</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_4.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\\n        \\n        # Add a review step\\n        review = await self.custom(input=f\\\"Problem: {problem}\\\\nGenerated solution: {solution['response']}\\\", instruction=prompt_custom.REVIEW_PROMPT)\\n        \\n        # Improve the solution based on the review\\n        improved_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\\\"{prompt_custom.CODE_GENERATE_PROMPT}\\\\n\\\\nConsider this review: {review['response']}\\\")\\n        \\n        test_result = await self.test(problem=problem, solution=improved_solution['response'], entry_point=entry_point)\\n        \\n        if not test_result['result']:\\n            analysis = await self.custom(input=f\\\"Problem: {problem}\\\\nFailed solution: {improved_solution['response']}\\\\nTest result: {test_result['solution']}\\\", instruction=prompt_custom.ANALYZE_AND_IMPROVE_PROMPT)\\n            final_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\\\"{prompt_custom.CODE_GENERATE_PROMPT}\\\\n\\\\nConsider this analysis: {analysis['response']}\\\")\\n            return final_solution['response'], self.llm.cost_manager.total_cost\\n        \\n        return improved_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>CODE_GENERATE_PROMPT = \\\"\\\"\\\"\\nGenerate a Python function that solves the given problem. Ensure the function signature matches the problem description. Include docstrings and comments to explain the logic. The solution should be efficient and handle edge cases. Pay special attention to the order of operations and ensure that the function evaluates the expression correctly.\\n\\\"\\\"\\\"\\n\\nREVIEW_PROMPT = \\\"\\\"\\\"\\nReview the generated solution and suggest improvements. Consider the following:\\n1. Does the function correctly implement the order of operations?\\n2. Are all required operators (+, -, *, //, **) handled properly?\\n3. Is there proper error handling for cases like division by zero?\\n4. Does the function handle the case where the operator list is empty?\\n5. Is the code efficient and readable?\\nProvide specific suggestions for improvement.\\n\\\"\\\"\\\"\\n\\nANALYZE_AND_IMPROVE_PROMPT = \\\"\\\"\\\"\\nAnalyze the failed solution and provide suggestions for improvement. Consider the following:\\n1. Identify logical errors or misunderstandings of the problem.\\n2. Check for edge cases that might not be handled correctly.\\n3. Ensure the order of operations is correctly implemented.\\n4. Suggest optimizations or alternative approaches if applicable.\\n5. Provide specific code snippets or pseudocode to address the issues found.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 5</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_5.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        \"\"\"\n        Implementation of the graph\n        Custom operator to generate anything you want.\n        But when you want to get standard code, you should use custom_code_generate operator.\n        \"\"\"\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=\"\")\n        test_result = await self.test(problem=problem, solution=solution['response'], entry_point=entry_point)\n        \n        if test_result['result']:\n            return test_result['solution'], self.llm.cost_manager.total_cost\n        else:\n            # If the test fails, try to generate a new solution\n            new_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.IMPROVE_CODE_PROMPT)\n            return new_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>IMPROVE_CODE_PROMPT = \"\"\"\nThe previous solution failed some test cases. Please analyze the problem carefully and provide an improved solution that addresses all edge cases and requirements. Ensure your code is efficient and follows best practices.\n\"\"\"</prompt>", "tag": "HumanEval", "domain": "llm_judge", "parent_round": 4, "child_round": 5, "parent_score": 0.8333333333333334, "child_score": 0.9666666666666667, "performance_gain": 0.1333333333333333}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve QA problems.\\nReferring to the given graph and prompt, which forms a basic example of a QA solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>Previous successful modifications:\\n  - Add a new Custom operator to specifically handle name extraction and verification, addressing the issue with incorrect name identification as seen in the \\\"Jack Benny Binion\\\" question. (Score: 0.6218939883645767)\\n\\nPrevious failed modifications:\\n  - Add a new Custom operator to handle numerical answer verification and formatting, addressing the issue with numerical answers as seen in the \\\"How many major novels\\\" question. (Score: 0.6138544951780245)</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.606665230194642</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.round_7.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.answer_generate = operator.AnswerGenerate(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):\\n            initial_response = await self.answer_generate(input=problem)\\n            thought_process = initial_response['thought']\\n            initial_answer = initial_response['answer']\\n            solutions.append(initial_answer)\\n\\n        ensemble_result = await self.sc_ensemble(solutions=solutions)\\n        best_answer = ensemble_result['response']\\n        \\n        fact_checked_answer = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nBest answer: {best_answer}\\\",\\n            instruction=prompt_custom.FACT_CHECK_PROMPT\\n        )\\n        \\n        style_check_answer = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nFact-checked answer: {fact_checked_answer['response']}\\\",\\n            instruction=prompt_custom.STYLE_CHECK_PROMPT\\n        )\\n        \\n        additional_verification = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nStyle-checked answer: {style_check_answer['response']}\\\",\\n            instruction=prompt_custom.ADDITIONAL_VERIFICATION_PROMPT\\n        )\\n        \\n        refined_solution = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nDouble-verified answer: {additional_verification['response']}\\\",\\n            instruction=prompt_custom.FORMAT_ANSWER_PROMPT\\n        )\\n        \\n        return refined_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>FORMAT_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question and the double-verified answer, format the final answer to be extremely concise and directly addressing the question. Provide only the essential information without any explanation or additional context. For names, professions, or short phrases, give only that specific information.\\n\\nExamples:\\n- For a person's name: \\\"John Doe\\\"\\n- For a profession: \\\"Doctor\\\"\\n- For a short phrase: \\\"Once in a blue moon\\\"\\n\\nDo not include any prefixes or explanatory text. Provide only the answer itself.\\n\\\"\\\"\\\"\\n\\nFACT_CHECK_PROMPT = \\\"\\\"\\\"\\nGiven the question and the best answer, carefully analyze the information provided and perform a fact-check. If you find any inconsistencies or errors in the best answer, provide a corrected version. If the best answer appears accurate, simply restate it. Focus on verifying key facts, names, dates, and other critical information related to the question.\\n\\nQuestion: {question}\\nBest answer: {best_answer}\\n\\nYour task:\\n1. Analyze the question and the best answer.\\n2. Identify any potential errors or inconsistencies.\\n3. If errors are found, provide a corrected answer.\\n4. If no errors are found, restate the best answer.\\n\\nProvide your response in a concise manner, focusing solely on the corrected or verified answer without additional explanations.\\n\\\"\\\"\\\"\\n\\nSTYLE_CHECK_PROMPT = \\\"\\\"\\\"\\nReview the fact-checked answer, focusing specifically on architectural and historical style terms. Verify the accuracy of any mentioned styles, ensuring they are correctly identified and placed in the proper historical context. Pay special attention to:\\n\\n1. Architectural styles (e.g., Gothic, Baroque, Neoclassical)\\n2. Historical periods and their associated styles\\n3. Relationships between different styles (e.g., which style influenced or preceded another)\\n\\nIf you find any errors or misidentifications in the architectural or historical style terms, provide a corrected version. If the answer is accurate, simply restate it. Be concise and direct in your response, providing only the verified or corrected answer without explanations.\\n\\\"\\\"\\\"\\n\\nADDITIONAL_VERIFICATION_PROMPT = \\\"\\\"\\\"\\nPerform an additional verification on the previously style-checked answer. Focus on:\\n\\n1. Consistency with the question\\n2. Accuracy of specific details (names, dates, places, styles)\\n3. Completeness of the answer\\n\\nIf any issues are found, provide a corrected version. If the answer is accurate and complete, restate it. Be concise and direct in your response, providing only the verified or corrected answer without explanations.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 8</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.round_8.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.answer_generate = operator.AnswerGenerate(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):\n            initial_response = await self.answer_generate(input=problem)\n            thought_process = initial_response['thought']\n            initial_answer = initial_response['answer']\n            solutions.append(initial_answer)\n\n        ensemble_result = await self.sc_ensemble(solutions=solutions)\n        best_answer = ensemble_result['response']\n        \n        formatted_solution = await self.custom(\n            input=f\"Question: {problem}\\nBest answer: {best_answer}\",\n            instruction=prompt_custom.FORMAT_ANSWER_PROMPT\n        )\n        \n        verified_solution = await self.custom(\n            input=f\"Question: {problem}\\nFormatted answer: {formatted_solution['response']}\",\n            instruction=prompt_custom.VERIFY_ANSWER_PROMPT\n        )\n        \n        return verified_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>FORMAT_ANSWER_PROMPT = \"\"\"\nGiven the question and the best answer, format the final answer to be concise, accurate, and directly addressing the question. Ensure the answer is a clear, brief statement without additional explanation or reasoning. If the answer is a name, profession, or short phrase, provide only that information without forming a complete sentence.\n\nFor example:\n- If the answer is a person's name, just provide the name.\n- If the answer is a profession, state only the profession.\n- If the answer is a short phrase, give only that phrase.\n\nDo not include any prefixes like \"The answer is\" or \"The profession is\". Just provide the answer itself.\n\"\"\"\n\nVERIFY_ANSWER_PROMPT = \"\"\"\nGiven the question and the formatted answer, verify if the answer is appropriate and make adjustments if necessary. Follow these guidelines:\n\n1. If the answer is a name, profession, or short phrase, ensure it's presented without any additional context or sentence structure.\n2. If the answer is \"The context does not provide...\", replace it with a more concise statement like \"Information not available\" or \"Unknown\".\n3. If the answer is too long or includes unnecessary explanation, trim it down to the essential information.\n4. Ensure the answer directly addresses the question asked.\n\nProvide the final, verified answer without any additional explanation or reasoning.\n\"\"\"</prompt>", "tag": "HotpotQA", "domain": "llm_judge", "parent_round": 7, "child_round": 8, "parent_score": 0.606665230194642, "child_score": 0.6236586942469295, "performance_gain": 0.01699346405228752}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve QA problems.\\nReferring to the given graph and prompt, which forms a basic example of a QA solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.573270199537661</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_19.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.answer_generate = operator.AnswerGenerate(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):  # Generate 3 solutions\\n            step_by_step = await self.answer_generate(input=problem)\\n            solution = await self.custom(input=f\\\"Question: {problem}\\\\nStep-by-step solution: {step_by_step['thought']}\\\\nInitial answer: {step_by_step['answer']}\\\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\\n            verified_solution = await self.custom(input=f\\\"Question: {problem}\\\\nStep-by-step solution: {step_by_step['thought']}\\\\nRefined answer: {solution['response']}\\\", instruction=prompt_custom.VERIFY_NUMERICAL_ANSWER_PROMPT)\\n            solutions.append(verified_solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions)\\n        return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\\n\\n1. Ensure the answer is concise and directly addresses the question.\\n2. If the answer is a number, provide only the number without additional text.\\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\\n4. Remove any explanations or reasoning from the final answer.\\n5. Double-check that the refined answer is consistent with the step-by-step solution and initial answer.\\n6. If the answer involves selecting between options, clearly state the chosen option.\\n\\nYour task is to extract or refine the most accurate answer based on the provided information.\\n\\\"\\\"\\\"\\n\\nVERIFY_NUMERICAL_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question, step-by-step solution, and refined answer, please verify and correct the numerical answer if necessary. Follow these guidelines:\\n\\n1. Check if the answer is consistent with the question and step-by-step solution.\\n2. Ensure the answer is a number or numbers separated by a vertical bar (|) if multiple answers are possible.\\n3. If the answer is incorrect or inconsistent, recalculate based on the step-by-step solution.\\n4. Remove any non-numeric characters or explanations, keeping only the numerical value(s).\\n5. If the question asks for a difference or comparison between values, double-check the calculation.\\n6. If no numerical answer is required, return the refined answer as is.\\n\\nYour task is to provide the most accurate numerical answer based on the given information and calculations.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 20</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_20.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.answer_generate = operator.AnswerGenerate(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):\n            step_by_step = await self.answer_generate(input=problem)\n            solution = await self.custom(input=f\"Question: {problem}\\nStep-by-step solution: {step_by_step['thought']}\\nInitial answer: {step_by_step['answer']}\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n            solutions.append(solution['response'])\n        \n        final_solution = await self.sc_ensemble(solutions=solutions)\n        return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>REFINE_ANSWER_PROMPT = \"\"\"\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\n\n1. Ensure the answer is concise and directly addresses the question.\n2. If the answer is a number, provide only the number without additional text.\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\n4. Remove any explanations or reasoning from the final answer.\n5. Double-check the calculation and reasoning to ensure accuracy.\n6. If the answer involves a range or multiple possibilities, include all valid options.\n\nYour task is to extract or refine the most accurate answer based on the provided information.\n\n\"\"\"</prompt>", "tag": "DROP", "domain": "llm_judge", "parent_round": 19, "child_round": 20, "parent_score": 0.573270199537661, "child_score": 0.7348039215686274, "performance_gain": 0.1615337220309664}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.5546218487394958</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.round_19.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        # Use Programmer to generate and execute Python code\\n        code_solution = await self.programmer(problem=problem)\\n        \\n        # Use Custom to refine and format the answer\\n        refined_solution = await self.custom(input=problem + f\\\"\\\\nCode output: {code_solution['output']}\\\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\\n        \\n        # Generate a detailed step-by-step solution using Custom\\n        detailed_solution = await self.custom(input=problem, instruction=prompt_custom.DETAILED_SOLUTION_PROMPT)\\n        \\n        # Generate a simplified solution using Custom\\n        simplified_solution = await self.custom(input=problem, instruction=prompt_custom.SIMPLIFIED_SOLUTION_PROMPT)\\n        \\n        # Generate multiple solutions using Custom\\n        solutions = [\\n            refined_solution['response'],\\n            detailed_solution['response'],\\n            simplified_solution['response']\\n        ]\\n        for _ in range(2):\\n            solution = await self.custom(input=problem, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        # Use ScEnsemble to select the best solution\\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the mathematical problem and the output from the code execution, please provide a well-formatted and detailed solution. Follow these guidelines:\\n\\n1. Begin with a clear statement of the problem.\\n2. Explain the approach and any formulas or concepts used.\\n3. Show step-by-step calculations, using LaTeX notation for mathematical expressions.\\n4. Interpret the code output and incorporate it into your explanation.\\n5. Provide a final answer, enclosed in \\\\boxed{} LaTeX notation.\\n6. Ensure all mathematical notation is in LaTeX format.\\n\\nYour response should be comprehensive, mathematically rigorous, and easy to follow.\\n\\\"\\\"\\\"\\n\\nGENERATE_SOLUTION_PROMPT = \\\"\\\"\\\"\\nPlease solve the given mathematical problem step by step. Follow these guidelines:\\n\\n1. State the problem clearly.\\n2. Outline the approach and any relevant formulas or concepts.\\n3. Provide detailed calculations, using LaTeX notation for mathematical expressions.\\n4. Explain each step of your reasoning.\\n5. Present the final answer enclosed in \\\\boxed{} LaTeX notation.\\n6. Ensure all mathematical notation is in LaTeX format.\\n\\nYour solution should be thorough, mathematically sound, and easy to understand.\\n\\\"\\\"\\\"\\n\\nDETAILED_SOLUTION_PROMPT = \\\"\\\"\\\"\\nProvide a comprehensive, step-by-step solution to the given mathematical problem. Your response should include:\\n\\n1. A clear restatement of the problem.\\n2. An explanation of the mathematical concepts and theorems involved.\\n3. A detailed, logical progression of steps leading to the solution.\\n4. Clear explanations for each step, including the reasoning behind it.\\n5. All mathematical expressions and equations in LaTeX format.\\n6. Visual aids or diagrams if applicable (described in text).\\n7. A final answer clearly marked and enclosed in \\\\boxed{} LaTeX notation.\\n8. A brief explanation of the significance of the result, if relevant.\\n\\nEnsure your solution is rigorous, easy to follow, and educational for someone learning the concept.\\n\\\"\\\"\\\"\\n\\nSIMPLIFIED_SOLUTION_PROMPT = \\\"\\\"\\\"\\nProvide a concise and simplified solution to the given mathematical problem. Your response should include:\\n\\n1. A brief restatement of the problem.\\n2. The main approach or key concept used to solve the problem.\\n3. Essential steps in the solution process, without extensive details.\\n4. The final answer enclosed in \\\\boxed{} LaTeX notation.\\n5. Use LaTeX notation for all mathematical expressions.\\n\\nKeep the solution clear and straightforward, focusing on the core ideas and steps needed to arrive at the answer.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 20</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.round_20.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        # Generate a summary of the problem and key concepts\n        summary = await self.custom(input=problem, instruction=prompt_custom.SUMMARIZE_PROBLEM_PROMPT)\n        \n        # Use Programmer to generate and execute Python code\n        code_solution = await self.programmer(problem=problem)\n        \n        # Use Custom to refine and format the answer\n        refined_solution = await self.custom(input=problem + f\"\\nSummary: {summary['response']}\\nCode output: {code_solution['output']}\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n        \n        # Generate multiple solutions using Custom\n        solutions = []\n        for _ in range(3):\n            solution = await self.custom(input=problem + f\"\\nSummary: {summary['response']}\", instruction=prompt_custom.GENERATE_SOLUTION_PROMPT)\n            solutions.append(solution['response'])\n        \n        # Generate a detailed step-by-step solution\n        detailed_solution = await self.custom(input=problem + f\"\\nSummary: {summary['response']}\", instruction=prompt_custom.DETAILED_SOLUTION_PROMPT)\n        solutions.append(detailed_solution['response'])\n        \n        # Use ScEnsemble to select the best solution\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>SUMMARIZE_PROBLEM_PROMPT = \"\"\"\nProvide a concise summary of the given mathematical problem, highlighting the key concepts and formulas involved. Your summary should:\n\n1. Restate the problem briefly.\n2. Identify the main mathematical topics or areas relevant to the problem.\n3. List any important formulas or theorems that may be useful in solving the problem.\n4. Mention any specific constraints or conditions given in the problem.\n\nKeep your summary clear and concise, focusing on the essential elements needed to understand and approach the problem.\n\"\"\"\n\nREFINE_ANSWER_PROMPT = \"\"\"\nGiven the mathematical problem, the problem summary, and the output from the code execution, please provide a well-formatted and detailed solution. Follow these guidelines:\n\n1. Begin with a clear statement of the problem.\n2. Briefly mention the key concepts identified in the summary.\n3. Explain the approach and any formulas or concepts used.\n4. Show step-by-step calculations, using LaTeX notation for mathematical expressions.\n5. Interpret the code output and incorporate it into your explanation.\n6. Provide a final answer, enclosed in \\boxed{} LaTeX notation.\n7. Ensure all mathematical notation is in LaTeX format.\n\nYour response should be comprehensive, mathematically rigorous, and easy to follow.\n\"\"\"\n\nGENERATE_SOLUTION_PROMPT = \"\"\"\nPlease solve the given mathematical problem step by step, taking into account the provided problem summary. Follow these guidelines:\n\n1. State the problem clearly.\n2. Reference the key concepts and formulas mentioned in the summary.\n3. Outline the approach and any relevant formulas or concepts.\n4. Provide detailed calculations, using LaTeX notation for mathematical expressions.\n5. Explain each step of your reasoning.\n6. Present the final answer enclosed in \\boxed{} LaTeX notation.\n7. Ensure all mathematical notation is in LaTeX format.\n\nYour solution should be thorough, mathematically sound, and easy to understand.\n\"\"\"\n\nDETAILED_SOLUTION_PROMPT = \"\"\"\nProvide a comprehensive, step-by-step solution to the given mathematical problem, incorporating the information from the problem summary. Your response should include:\n\n1. A clear restatement of the problem.\n2. An explanation of the mathematical concepts and formulas involved, referencing the summary.\n3. A detailed, logical progression of steps to solve the problem.\n4. Clear explanations for each step, including the reasoning behind it.\n5. All mathematical expressions and equations in LaTeX format.\n6. Visual aids or diagrams if applicable (described in text).\n7. A final answer clearly marked and enclosed in \\boxed{} LaTeX notation.\n8. A brief explanation of the significance of the answer in the context of the original problem.\n\nAim for clarity, accuracy, and thoroughness in your solution.\n\"\"\"</prompt>", "tag": "MATH", "domain": "llm_judge", "parent_round": 19, "child_round": 20, "parent_score": 0.5546218487394958, "child_score": 0.5378151260504201, "performance_gain": -0.01680672268907568}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve QA problems.\\nReferring to the given graph and prompt, which forms a basic example of a QA solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.6258169934640523</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_16.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.answer_generate = operator.AnswerGenerate(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):  # Generate 3 solutions\\n            step_by_step = await self.answer_generate(input=problem)\\n            solutions.append(step_by_step['answer'])\\n        \\n        ensemble_solution = await self.sc_ensemble(solutions=solutions)\\n        \\n        refined_solution = await self.custom(input=f\\\"Question: {problem}\\\\nBest solution: {ensemble_solution['response']}\\\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\\n        \\n        final_solution = await self.custom(input=f\\\"Question: {problem}\\\\nRefined answer: {refined_solution['response']}\\\", instruction=prompt_custom.EXTRACT_VALIDATE_PROMPT)\\n\\n        return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\\n\\n1. Ensure the answer is concise and directly addresses the question.\\n2. If the answer is a number, provide only the number without additional text.\\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\\n4. Remove any explanations or reasoning from the final answer.\\n\\nYour task is to extract or refine the most accurate answer based on the provided information.\\n\\\"\\\"\\\"\\n\\nEXTRACT_VALIDATE_PROMPT = \\\"\\\"\\\"\\nGiven the question and the refined answer, please extract and validate the numerical answer. Follow these guidelines:\\n\\n1. Extract only the numerical value from the refined answer.\\n2. Ensure the extracted number is relevant to the question asked.\\n3. If the answer is a decimal, maintain the original decimal places.\\n4. If the answer is a whole number, do not add decimal places.\\n5. If no valid numerical answer can be extracted, respond with \\\"Unable to extract a valid numerical answer.\\\"\\n\\nProvide only the extracted and validated numerical answer without any additional text or explanations.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 17</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_17.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.answer_generate = operator.AnswerGenerate(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):  # Generate 3 solutions\n            step_by_step = await self.answer_generate(input=problem)\n            solution = await self.custom(input=f\"Question: {problem}\\nStep-by-step solution: {step_by_step['thought']}\\nInitial answer: {step_by_step['answer']}\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n            solutions.append(solution['response'])\n        \n        final_solution = await self.sc_ensemble(solutions=solutions)\n        \n        # Add verification step\n        verified_solution = await self.custom(input=f\"Question: {problem}\\nProposed answer: {final_solution['response']}\", instruction=prompt_custom.VERIFY_ANSWER_PROMPT)\n        \n        return verified_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>REFINE_ANSWER_PROMPT = \"\"\"\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\n\n1. Ensure the answer is concise and directly addresses the question.\n2. If the answer is a number, provide only the number without additional text.\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\n4. Remove any explanations or reasoning from the final answer.\n5. Double-check that the refined answer is consistent with the step-by-step solution and initial answer.\n6. If the answer involves selecting between options, clearly state the chosen option.\n\nYour task is to extract or refine the most accurate answer based on the provided information.\n\"\"\"\n\nVERIFY_ANSWER_PROMPT = \"\"\"\nGiven the question and the proposed answer, please verify and format the answer according to the following rules:\n\n1. If the answer is a single number, ensure it's provided without any units or additional text (e.g., \"5\" instead of \"5%\").\n2. If the answer consists of multiple numbers, separate them with a vertical bar (|) without spaces (e.g., \"3|20|32\").\n3. Remove any explanatory text or reasoning from the answer.\n4. Ensure the answer directly addresses the question without any extraneous information.\n5. If the original answer doesn't meet these criteria, modify it to comply.\n\nProvide only the verified and formatted answer without any additional explanation.\n\"\"\"</prompt>", "tag": "DROP", "domain": "llm_judge", "parent_round": 16, "child_round": 17, "parent_score": 0.6258169934640523, "child_score": 0.7044117647058823, "performance_gain": 0.07859477124183001}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.87</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_6.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):\\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        # Add a review step using the Programmer operator\\n        review_result = await self.programmer(problem=problem, analysis=final_solution['response'])\\n        \\n        if review_result['output']:\\n            return review_result['output'], self.llm.cost_manager.total_cost\\n        else:\\n            return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>MATH_SOLVE_PROMPT = \\\"\\\"\\\"\\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps:\\n\\n1. Carefully read and understand the problem.\\n2. Identify the key information and variables.\\n3. Determine the appropriate mathematical concepts or formulas to use.\\n4. Solve the problem step by step, showing all your work.\\n5. Double-check your calculations and reasoning.\\n6. Provide a clear and concise final answer.\\n7. Format your final answer as a single numerical value without units or additional text.\\n\\nRemember to format your answer as follows:\\n- Use LaTeX notation for mathematical expressions where appropriate.\\n- Clearly state your final answer at the end of your solution.\\n- Express numerical answers as precise values (avoid rounding unless specified).\\n- Ensure that your final answer is a single numerical value without any units or additional text.\\n\\nHere's the problem to solve:\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 7</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_7.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\n            solutions.append(solution['response'])\n        \n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Add a verification step using the Programmer operator\n        verification_result = await self.programmer(problem=problem, analysis=final_solution['response'])\n        \n        if verification_result['output']:\n            return verification_result['output'], self.llm.cost_manager.total_cost\n        else:\n            return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>MATH_SOLVE_PROMPT = \"\"\"\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps:\n\n1. Carefully read and understand the problem.\n2. Identify the key information and variables.\n3. Determine the appropriate mathematical concepts or formulas to use.\n4. Solve the problem step by step, showing all your work.\n5. Double-check your calculations and reasoning.\n6. Provide a clear and concise final answer.\n\nImportant considerations:\n- Pay special attention to problems involving discounts. Calculate the discounted amount correctly and subtract it from the original price.\n- When dealing with multiple item purchases, ensure you account for all items and their respective prices or quantities.\n- For problems involving time calculations, convert all time units to a common unit (e.g., hours or minutes) before performing calculations.\n\nRemember to format your answer as follows:\n- Use LaTeX notation for mathematical expressions where appropriate.\n- Clearly state your final answer at the end of your solution.\n- Express numerical answers as precise values (avoid rounding unless specified).\n- Ensure that your final answer is a single numerical value without any units or additional text.\n\nHere's the problem to solve:\n\n\"\"\"</prompt>", "tag": "GSM8K", "domain": "llm_judge", "parent_round": 6, "child_round": 7, "parent_score": 0.87, "child_score": 0.89, "performance_gain": 0.020000000000000018}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve QA problems.\\nReferring to the given graph and prompt, which forms a basic example of a QA solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.6960207612456747</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_5.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.answer_generate = operator.AnswerGenerate(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):  # Generate 3 solutions\\n            step_by_step = await self.answer_generate(input=problem)\\n            solutions.append(step_by_step['answer'])\\n        \\n        ensemble_solution = await self.sc_ensemble(solutions=solutions)\\n        \\n        refined_solution = await self.custom(input=f\\\"Question: {problem}\\\\nBest solution: {ensemble_solution['response']}\\\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\\n        \\n        final_solution = await self.custom(input=f\\\"Question: {problem}\\\\nRefined answer: {refined_solution['response']}\\\", instruction=prompt_custom.REVIEW_ANSWER_PROMPT)\\n\\n        return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\\n\\n1. Ensure the answer is concise and directly addresses the question.\\n2. If the answer is a number, provide only the number without additional text.\\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\\n4. Remove any explanations or reasoning from the final answer.\\n\\nYour task is to extract or refine the most accurate answer based on the provided information.\\n\\\"\\\"\\\"\\n\\nREVIEW_ANSWER_PROMPT = \\\"\\\"\\\"\\nReview the refined answer for the given question. Ensure it meets the following criteria:\\n\\n1. The answer is directly related to the question asked.\\n2. If the answer is a number, it should be provided without any additional text or symbols (e.g., no %, $, etc.).\\n3. The answer is in its simplest form (e.g., fractions are reduced, unnecessary decimal places are removed).\\n4. If multiple answers are possible, they are separated by a vertical bar (|) without spaces.\\n\\nIf the answer meets all criteria, return it as is. If not, modify the answer to meet these criteria and return the corrected version.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 6</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_6.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.answer_generate = operator.AnswerGenerate(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        step_by_step = await self.answer_generate(input=problem)\n        solution = await self.custom(input=f\"Problem: {problem}\\nStep-by-step solution: {step_by_step['thought']}\\nInitial answer: {step_by_step['answer']}\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n        return solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>REFINE_ANSWER_PROMPT = \"\"\"\nGiven the problem, step-by-step solution, and initial answer, please refine and format the answer to ensure it is concise, accurate, and directly addresses the question. Follow these guidelines:\n\n1. Review the step-by-step solution for accuracy and completeness.\n2. Ensure the final answer is clearly stated and matches the question asked.\n3. If the answer is a numerical value, include only the number without additional explanation.\n4. If the answer requires a brief explanation, keep it concise and to the point.\n5. Remove any unnecessary information or verbosity.\n\nProvide the refined answer in a clear and concise format.\n\"\"\"</prompt>", "tag": "DROP", "domain": "llm_judge", "parent_round": 5, "child_round": 6, "parent_score": 0.6960207612456747, "child_score": 0.524159663865546, "performance_gain": -0.17186109738012867}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.9</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_7.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        # Generate multiple solutions\\n        solutions = []\\n        for _ in range(3):\\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        # Use ScEnsemble to select the best solution\\n        best_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        # Self-review step\\n        review = await self.custom(input=f\\\"Problem: {problem}\\\\nGenerated solution: {best_solution['response']}\\\", instruction=prompt_custom.SELF_REVIEW_PROMPT)\\n        \\n        # Improve the solution based on the review\\n        improved_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\\\"{prompt_custom.CODE_GENERATE_PROMPT}\\\\n\\\\nConsider this review: {review['response']}\\\")\\n        \\n        test_result = await self.test(problem=problem, solution=improved_solution['response'], entry_point=entry_point)\\n        \\n        if not test_result['result']:\\n            analysis = await self.custom(input=f\\\"Problem: {problem}\\\\nFailed solution: {improved_solution['response']}\\\\nTest result: {test_result['solution']}\\\", instruction=prompt_custom.ANALYZE_AND_IMPROVE_PROMPT)\\n            final_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\\\"{prompt_custom.CODE_GENERATE_PROMPT}\\\\n\\\\nConsider this analysis: {analysis['response']}\\\")\\n            return final_solution['response'], self.llm.cost_manager.total_cost\\n        \\n        return improved_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>CODE_GENERATE_PROMPT = \\\"\\\"\\\"\\nGenerate a Python function that solves the given problem. Ensure the function signature matches the problem description. Include docstrings and comments to explain the logic. The solution should be efficient and handle edge cases.\\n\\\"\\\"\\\"\\n\\nSELF_REVIEW_PROMPT = \\\"\\\"\\\"\\nReview the generated solution and provide feedback on its correctness, efficiency, and adherence to best practices. Consider the following:\\n1. Does the solution correctly implement the problem requirements?\\n2. Are there any potential edge cases that are not handled?\\n3. Can the code be optimized for better performance?\\n4. Does the code follow Python best practices and style guidelines?\\n5. Are there any logical errors or potential bugs?\\nProvide specific suggestions for improvements if necessary.\\n\\\"\\\"\\\"\\n\\nANALYZE_AND_IMPROVE_PROMPT = \\\"\\\"\\\"\\nAnalyze the failed solution and provide suggestions for improvement. Consider the following:\\n1. Identify logical errors or misunderstandings of the problem.\\n2. Check for edge cases that might not be handled correctly.\\n3. Suggest optimizations or alternative approaches if applicable.\\n4. Provide specific code snippets or pseudocode to address the issues found.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 8</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_8.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\n        test_result = await self.test(problem=problem, solution=solution['response'], entry_point=entry_point)\n        \n        if not test_result['result']:\n            # Comprehensive analysis of the problem and failed solution\n            analysis = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {solution['response']}\\nTest result: {test_result['solution']}\", instruction=prompt_custom.COMPREHENSIVE_ANALYSIS_PROMPT)\n            \n            # Generate improved solution based on the comprehensive analysis\n            improved_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\"{prompt_custom.CODE_GENERATE_PROMPT}\\n\\nConsider this analysis: {analysis['response']}\")\n            \n            # Test the improved solution\n            improved_test_result = await self.test(problem=problem, solution=improved_solution['response'], entry_point=entry_point)\n            \n            if improved_test_result['result']:\n                return improved_solution['response'], self.llm.cost_manager.total_cost\n            else:\n                # If the improved solution still fails, return the original solution\n                return solution['response'], self.llm.cost_manager.total_cost\n        \n        return solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>CODE_GENERATE_PROMPT = \"\"\"\nGenerate a Python function that solves the given problem. Ensure the function signature matches the problem description. Include docstrings and comments to explain the logic. The solution should be efficient and handle edge cases.\n\"\"\"\n\nCOMPREHENSIVE_ANALYSIS_PROMPT = \"\"\"\nPerform a comprehensive analysis of the problem and the failed solution. Consider the following aspects:\n\n1. Problem understanding: Identify any potential misinterpretations of the problem statement.\n2. Logical errors: Pinpoint any flaws in the solution's logic or algorithm.\n3. Edge cases: Determine if all possible input scenarios are properly handled.\n4. Efficiency: Evaluate the time and space complexity of the solution.\n5. Coding style: Assess the readability and adherence to Python best practices.\n6. Test case failures: Analyze why specific test cases are failing.\n7. Alternative approaches: Suggest different algorithms or data structures that might be more suitable.\n\nProvide a detailed breakdown of these aspects and suggest specific improvements for each identified issue.\n\"\"\"</prompt>", "tag": "HumanEval", "domain": "llm_judge", "parent_round": 7, "child_round": 8, "parent_score": 0.9, "child_score": 0.9333333333333333, "performance_gain": 0.033333333333333326}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.8</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_4.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\\n        \\n        # Add a review step\\n        review = await self.custom(input=f\\\"Problem: {problem}\\\\nGenerated solution: {solution['response']}\\\", instruction=prompt_custom.REVIEW_PROMPT)\\n        \\n        # Improve the solution based on the review\\n        improved_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\\\"{prompt_custom.CODE_GENERATE_PROMPT}\\\\n\\\\nConsider this review: {review['response']}\\\")\\n        \\n        test_result = await self.test(problem=problem, solution=improved_solution['response'], entry_point=entry_point)\\n        \\n        if not test_result['result']:\\n            analysis = await self.custom(input=f\\\"Problem: {problem}\\\\nFailed solution: {improved_solution['response']}\\\\nTest result: {test_result['solution']}\\\", instruction=prompt_custom.ANALYZE_AND_IMPROVE_PROMPT)\\n            final_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\\\"{prompt_custom.CODE_GENERATE_PROMPT}\\\\n\\\\nConsider this analysis: {analysis['response']}\\\")\\n            return final_solution['response'], self.llm.cost_manager.total_cost\\n        \\n        return improved_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>CODE_GENERATE_PROMPT = \\\"\\\"\\\"\\nGenerate a Python function that solves the given problem. Ensure the function signature matches the problem description. Include docstrings and comments to explain the logic. The solution should be efficient and handle edge cases. Pay special attention to the order of operations and ensure that the function evaluates the expression correctly.\\n\\\"\\\"\\\"\\n\\nREVIEW_PROMPT = \\\"\\\"\\\"\\nReview the generated solution and suggest improvements. Consider the following:\\n1. Does the function correctly implement the order of operations?\\n2. Are all required operators (+, -, *, //, **) handled properly?\\n3. Is there proper error handling for cases like division by zero?\\n4. Does the function handle the case where the operator list is empty?\\n5. Is the code efficient and readable?\\nProvide specific suggestions for improvement.\\n\\\"\\\"\\\"\\n\\nANALYZE_AND_IMPROVE_PROMPT = \\\"\\\"\\\"\\nAnalyze the failed solution and provide suggestions for improvement. Consider the following:\\n1. Identify logical errors or misunderstandings of the problem.\\n2. Check for edge cases that might not be handled correctly.\\n3. Ensure the order of operations is correctly implemented.\\n4. Suggest optimizations or alternative approaches if applicable.\\n5. Provide specific code snippets or pseudocode to address the issues found.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 5</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_5.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        \"\"\"\n        Implementation of the graph\n        Custom operator to generate anything you want.\n        But when you want to get standard code, you should use custom_code_generate operator.\n        \"\"\"\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=\"\")\n        test_result = await self.test(problem=problem, solution=solution['response'], entry_point=entry_point)\n        \n        if test_result['result']:\n            return test_result['solution'], self.llm.cost_manager.total_cost\n        else:\n            # If the test fails, try to generate a new solution\n            new_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.IMPROVE_CODE_PROMPT)\n            return new_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>IMPROVE_CODE_PROMPT = \"\"\"\nThe previous solution failed some test cases. Please analyze the problem carefully and provide an improved solution that addresses all edge cases and requirements. Ensure your code is efficient and follows best practices.\n\"\"\"</prompt>", "tag": "HumanEval", "domain": "llm_judge", "parent_round": 4, "child_round": 5, "parent_score": 0.8, "child_score": 0.9666666666666667, "performance_gain": 0.16666666666666663}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.89</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_20.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(5):  # Generate 5 solutions\\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        # Add a verification step using the Programmer operator\\n        verification = await self.programmer(problem=problem, analysis=final_solution['response'])\\n        \\n        if verification['output']:\\n            return verification['output'], self.llm.cost_manager.total_cost\\n        else:\\n            return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>MATH_SOLVE_PROMPT = \\\"\\\"\\\"\\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps carefully:\\n\\n1. Read and understand the problem thoroughly, ensuring you consider all given information.\\n2. Identify all key information, variables, and relationships, including any percentages, additional costs, or multi-step calculations.\\n3. Determine the appropriate mathematical concepts, formulas, or equations to use.\\n4. Solve the problem step-by-step, showing all your work clearly.\\n5. If the problem involves multiple calculations or steps, ensure you complete all of them.\\n6. For problems involving costs or prices, always calculate the total cost, including any additional fees, percentages, or discounts mentioned.\\n7. Double-check your calculations and reasoning at each step.\\n8. Provide a clear and concise final answer.\\n9. Verify your solution by plugging it back into the original problem or using an alternative method if possible.\\n\\nFormat your answer as follows:\\n- Use LaTeX notation for mathematical expressions where appropriate.\\n- Show each step of your solution process clearly.\\n- Clearly state your final answer at the end of your solution.\\n- Express numerical answers as precise values (avoid rounding unless specified).\\n- Ensure that your final answer is a single numerical value without any units or additional text.\\n- Do not include any explanatory text with your final answer, just the number itself.\\n\\nFor example, if the final answer is 42.5, your response should end with just:\\n42.5\\n\\nHere's the problem to solve:\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 21</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_21.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(5):  # Generate 5 solutions\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\n            solutions.append(solution['response'])\n        \n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Add a verification step using the Programmer operator\n        verification = await self.programmer(problem=problem, analysis=final_solution['response'])\n        \n        if verification['output']:\n            final_answer = verification['output']\n        else:\n            final_answer = final_solution['response']\n\n        # Final check to ensure the answer is a single number\n        try:\n            final_answer = float(final_answer)\n        except ValueError:\n            final_answer = float(final_answer.split()[-1])\n\n        return str(final_answer), self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>MATH_SOLVE_PROMPT = \"\"\"\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps carefully:\n\n1. Read and understand the problem thoroughly, paying special attention to time-based calculations and total cost considerations including any discounts.\n2. Identify all key information, variables, and relationships, especially those related to time periods and pricing.\n3. Determine the appropriate mathematical concepts, formulas, or equations to use, including time conversion if necessary.\n4. Solve the problem step-by-step, showing all your work clearly.\n5. For problems involving time:\n   - Convert all time periods to the same unit (e.g., minutes or hours)\n   - Calculate the total time period carefully\n6. For problems involving costs:\n   - Include all mentioned costs and discounts\n   - Calculate the total cost, factoring in any discounts or special pricing\n7. Double-check your calculations and reasoning at each step.\n8. Provide a clear and concise final answer.\n9. Verify your solution by plugging it back into the original problem or using an alternative method if possible.\n\nFormat your answer as follows:\n- Use LaTeX notation for mathematical expressions where appropriate.\n- Show each step of your solution process clearly.\n- Clearly state your final answer at the end of your solution.\n- Express numerical answers as precise values (avoid rounding unless specified).\n- Ensure that your final answer is a single numerical value without any units or additional text.\n- Do not include any explanatory text with your final answer, just the number itself.\n\nFor example, if the final answer is 42.5, your response should end with just:\n42.5\n\nHere's the problem to solve:\n\n\"\"\"</prompt>", "tag": "GSM8K", "domain": "llm_judge", "parent_round": 20, "child_round": 21, "parent_score": 0.89, "child_score": 0.88, "performance_gain": -0.010000000000000009}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.85</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_7.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):\\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        # Add a verification step using the Programmer operator\\n        verification_result = await self.programmer(problem=problem, analysis=final_solution['response'])\\n        \\n        if verification_result['output']:\\n            return verification_result['output'], self.llm.cost_manager.total_cost\\n        else:\\n            return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>MATH_SOLVE_PROMPT = \\\"\\\"\\\"\\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps:\\n\\n1. Carefully read and understand the problem.\\n2. Identify the key information and variables.\\n3. Determine the appropriate mathematical concepts or formulas to use.\\n4. Solve the problem step by step, showing all your work.\\n5. Double-check your calculations and reasoning.\\n6. Provide a clear and concise final answer.\\n\\nImportant considerations:\\n- Pay special attention to problems involving discounts. Calculate the discounted amount correctly and subtract it from the original price.\\n- When dealing with multiple item purchases, ensure you account for all items and their respective prices or quantities.\\n- For problems involving time calculations, convert all time units to a common unit (e.g., hours or minutes) before performing calculations.\\n\\nRemember to format your answer as follows:\\n- Use LaTeX notation for mathematical expressions where appropriate.\\n- Clearly state your final answer at the end of your solution.\\n- Express numerical answers as precise values (avoid rounding unless specified).\\n- Ensure that your final answer is a single numerical value without any units or additional text.\\n\\nHere's the problem to solve:\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 8</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_8.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\n            solutions.append(solution['response'])\n        \n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Add a review step using the Programmer operator\n        review_result = await self.programmer(problem=problem, analysis=final_solution['response'])\n        \n        if review_result['output']:\n            return review_result['output'], self.llm.cost_manager.total_cost\n        else:\n            return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>MATH_SOLVE_PROMPT = \"\"\"\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps:\n\n1. Carefully read and understand the problem.\n2. Identify the key information and variables.\n3. Determine the appropriate mathematical concepts or formulas to use.\n4. Solve the problem step by step, showing all your work.\n5. Double-check your calculations and reasoning.\n6. Provide a clear and concise final answer.\n\nRemember to format your answer as follows:\n- Use LaTeX notation for mathematical expressions where appropriate.\n- Clearly state your final answer at the end of your solution.\n- Express numerical answers as precise values (avoid rounding unless specified).\n- Ensure that your final answer is a single numerical value without any units or additional text.\n- Do not include any explanatory text with your final answer, just the number itself.\n\nFor example, if the final answer is 42.5, your response should end with just:\n42.5\n\nHere's the problem to solve:\n\n\"\"\"</prompt>", "tag": "GSM8K", "domain": "llm_judge", "parent_round": 7, "child_round": 8, "parent_score": 0.85, "child_score": 0.9, "performance_gain": 0.050000000000000044}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.87</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_7.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):\\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        # Add a verification step using the Programmer operator\\n        verification_result = await self.programmer(problem=problem, analysis=final_solution['response'])\\n        \\n        if verification_result['output']:\\n            return verification_result['output'], self.llm.cost_manager.total_cost\\n        else:\\n            return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>MATH_SOLVE_PROMPT = \\\"\\\"\\\"\\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps:\\n\\n1. Carefully read and understand the problem.\\n2. Identify the key information and variables.\\n3. Determine the appropriate mathematical concepts or formulas to use.\\n4. Solve the problem step by step, showing all your work.\\n5. Double-check your calculations and reasoning.\\n6. Provide a clear and concise final answer.\\n\\nImportant considerations:\\n- Pay special attention to problems involving discounts. Calculate the discounted amount correctly and subtract it from the original price.\\n- When dealing with multiple item purchases, ensure you account for all items and their respective prices or quantities.\\n- For problems involving time calculations, convert all time units to a common unit (e.g., hours or minutes) before performing calculations.\\n\\nRemember to format your answer as follows:\\n- Use LaTeX notation for mathematical expressions where appropriate.\\n- Clearly state your final answer at the end of your solution.\\n- Express numerical answers as precise values (avoid rounding unless specified).\\n- Ensure that your final answer is a single numerical value without any units or additional text.\\n\\nHere's the problem to solve:\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 8</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_8.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\n            solutions.append(solution['response'])\n        \n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Add a review step using the Programmer operator\n        review_result = await self.programmer(problem=problem, analysis=final_solution['response'])\n        \n        if review_result['output']:\n            return review_result['output'], self.llm.cost_manager.total_cost\n        else:\n            return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>MATH_SOLVE_PROMPT = \"\"\"\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps:\n\n1. Carefully read and understand the problem.\n2. Identify the key information and variables.\n3. Determine the appropriate mathematical concepts or formulas to use.\n4. Solve the problem step by step, showing all your work.\n5. Double-check your calculations and reasoning.\n6. Provide a clear and concise final answer.\n\nRemember to format your answer as follows:\n- Use LaTeX notation for mathematical expressions where appropriate.\n- Clearly state your final answer at the end of your solution.\n- Express numerical answers as precise values (avoid rounding unless specified).\n- Ensure that your final answer is a single numerical value without any units or additional text.\n- Do not include any explanatory text with your final answer, just the number itself.\n\nFor example, if the final answer is 42.5, your response should end with just:\n42.5\n\nHere's the problem to solve:\n\n\"\"\"</prompt>", "tag": "GSM8K", "domain": "llm_judge", "parent_round": 7, "child_round": 8, "parent_score": 0.87, "child_score": 0.9, "performance_gain": 0.030000000000000027}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve QA problems.\\nReferring to the given graph and prompt, which forms a basic example of a QA solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.5927763413057531</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.round_8.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.answer_generate = operator.AnswerGenerate(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):\\n            initial_response = await self.answer_generate(input=problem)\\n            thought_process = initial_response['thought']\\n            initial_answer = initial_response['answer']\\n            solutions.append(initial_answer)\\n\\n        ensemble_result = await self.sc_ensemble(solutions=solutions)\\n        best_answer = ensemble_result['response']\\n        \\n        formatted_solution = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nBest answer: {best_answer}\\\",\\n            instruction=prompt_custom.FORMAT_ANSWER_PROMPT\\n        )\\n        \\n        verified_solution = await self.custom(\\n            input=f\\\"Question: {problem}\\\\nFormatted answer: {formatted_solution['response']}\\\",\\n            instruction=prompt_custom.VERIFY_ANSWER_PROMPT\\n        )\\n        \\n        return verified_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>FORMAT_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question and the best answer, format the final answer to be concise, accurate, and directly addressing the question. Ensure the answer is a clear, brief statement without additional explanation or reasoning. If the answer is a name, profession, or short phrase, provide only that information without forming a complete sentence.\\n\\nFor example:\\n- If the answer is a person's name, just provide the name.\\n- If the answer is a profession, state only the profession.\\n- If the answer is a short phrase, give only that phrase.\\n\\nDo not include any prefixes like \\\"The answer is\\\" or \\\"The profession is\\\". Just provide the answer itself.\\n\\\"\\\"\\\"\\n\\nVERIFY_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question and the formatted answer, verify if the answer is appropriate and make adjustments if necessary. Follow these guidelines:\\n\\n1. If the answer is a name, profession, or short phrase, ensure it's presented without any additional context or sentence structure.\\n2. If the answer is \\\"The context does not provide...\\\", replace it with a more concise statement like \\\"Information not available\\\" or \\\"Unknown\\\".\\n3. If the answer is too long or includes unnecessary explanation, trim it down to the essential information.\\n4. Ensure the answer directly addresses the question asked.\\n\\nProvide the final, verified answer without any additional explanation or reasoning.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 9</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.HotpotQA.graphs.round_9.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.answer_generate = operator.AnswerGenerate(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):\n            initial_response = await self.answer_generate(input=problem)\n            thought_process = initial_response['thought']\n            initial_answer = initial_response['answer']\n            solutions.append(initial_answer)\n\n        ensemble_result = await self.sc_ensemble(solutions=solutions)\n        best_answer = ensemble_result['response']\n        \n        fact_checked_answer = await self.custom(\n            input=f\"Question: {problem}\\nBest answer: {best_answer}\",\n            instruction=prompt_custom.FACT_CHECK_PROMPT\n        )\n        \n        refined_solution = await self.custom(\n            input=f\"Question: {problem}\\nVerified answer: {fact_checked_answer['response']}\",\n            instruction=prompt_custom.FORMAT_ANSWER_PROMPT\n        )\n        \n        return refined_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>FORMAT_ANSWER_PROMPT = \"\"\"\nGiven the question and the verified answer, format the final answer to be concise, accurate, and directly addressing the question. Ensure the answer is clear and brief, without unnecessary explanation. Follow these guidelines:\n\n1. For questions about people, provide only the name or profession.\n2. For questions about dates or numbers, provide only the specific date or number.\n3. For questions asking about differences or comparisons, provide a brief, one-sentence explanation highlighting the key difference.\n4. For questions about facts or events, provide a concise statement of the fact or event.\n\nDo not include any prefixes like \"The answer is\" or \"The difference is\". Provide only the essential information to answer the question.\n\nQuestion: {question}\nVerified answer: {verified_answer}\n\nFormat your response accordingly:\n\"\"\"\n\nFACT_CHECK_PROMPT = \"\"\"\nGiven the question and the best answer, carefully analyze the information provided and perform a fact-check. If you find any inconsistencies or errors in the best answer, provide a corrected version. If the best answer appears accurate, simply restate it. Focus on verifying key facts, names, dates, and other critical information related to the question.\n\nQuestion: {question}\nBest answer: {best_answer}\n\nYour task:\n1. Analyze the question and the best answer.\n2. Identify any potential errors or inconsistencies.\n3. If errors are found, provide a corrected answer.\n4. If no errors are found, restate the best answer.\n\nProvide your response in a concise manner, focusing solely on the corrected or verified answer without additional explanations.\n\"\"\"</prompt>", "tag": "HotpotQA", "domain": "llm_judge", "parent_round": 8, "child_round": 9, "parent_score": 0.5927763413057531, "child_score": 0.558064263687101, "performance_gain": -0.034712077618652026}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.9</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_18.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):\\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        # Add a verification step using the Programmer operator\\n        verification_prompt = f\\\"Verify the following solution, focusing on unit conversions and complex calculations:\\\\n\\\\nProblem: {problem}\\\\n\\\\nSolution: {final_solution['response']}\\\\n\\\\nProvide the correct numerical answer as a single value without units.\\\"\\n        verification_result = await self.programmer(problem=verification_prompt)\\n        \\n        if verification_result['output']:\\n            return verification_result['output'], self.llm.cost_manager.total_cost\\n        else:\\n            return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>MATH_SOLVE_PROMPT = \\\"\\\"\\\"\\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps:\\n\\n1. Carefully read and understand the problem.\\n2. Identify the key information and variables.\\n3. Determine the appropriate mathematical concepts or formulas to use.\\n4. Solve the problem step by step, showing all your work.\\n5. Pay special attention to unit conversions (e.g., inches to feet, minutes to hours).\\n6. For time-based problems, convert all time units to a single unit (preferably hours or minutes).\\n7. For problems involving money, ensure all calculations are in the same currency unit.\\n8. Double-check your calculations and reasoning, especially for unit conversions and complex calculations.\\n9. Provide a clear and concise final answer.\\n\\nRemember to format your answer as follows:\\n- Use LaTeX notation for mathematical expressions where appropriate.\\n- Clearly state your final answer at the end of your solution.\\n- Express numerical answers as precise values (avoid rounding unless specified).\\n- Ensure that your final answer is a single numerical value without any units or additional text.\\n- Do not include any explanatory text with your final answer, just the number itself.\\n\\nFor example, if the final answer is 42.5 hours, your response should end with just:\\n42.5\\n\\nHere's the problem to solve:\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 19</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_19.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\n            solutions.append(solution['response'])\n        \n        ensemble_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Verification step using the Programmer operator\n        verification_result = await self.programmer(problem=problem, analysis=ensemble_solution['response'])\n        \n        # Final review step using ScEnsemble\n        final_solutions = [ensemble_solution['response'], verification_result['output']]\n        final_result = await self.sc_ensemble(solutions=final_solutions, problem=problem)\n        \n        return final_result['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>MATH_SOLVE_PROMPT = \"\"\"\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps:\n\n1. Carefully read and understand the problem.\n2. Identify the key information and variables.\n3. Determine the appropriate mathematical concepts or formulas to use.\n4. Perform any necessary unit conversions before calculations.\n5. Solve the problem step by step, showing all your work.\n6. Double-check your calculations, reasoning, and unit conversions.\n7. Provide a clear and concise final answer.\n\nRemember to format your answer as follows:\n- Use LaTeX notation for mathematical expressions where appropriate.\n- Clearly state your final answer at the end of your solution.\n- Express numerical answers as precise values (avoid rounding unless specified).\n- Ensure that your final answer is a single numerical value without any units or additional text.\n- Do not include any explanatory text with your final answer, just the number itself.\n\nFor example, if the final answer is 42.5, your response should end with just:\n42.5\n\nHere's the problem to solve:\n\n\"\"\"</prompt>", "tag": "GSM8K", "domain": "llm_judge", "parent_round": 18, "child_round": 19, "parent_score": 0.9, "child_score": 0.87, "performance_gain": -0.030000000000000027}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve QA problems.\\nReferring to the given graph and prompt, which forms a basic example of a QA solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.7495098039215685</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_13.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.answer_generate = operator.AnswerGenerate(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):  # Generate 3 solutions\\n            step_by_step = await self.answer_generate(input=problem)\\n            solution = await self.custom(input=f\\\"Question: {problem}\\\\nStep-by-step solution: {step_by_step['thought']}\\\\nInitial answer: {step_by_step['answer']}\\\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions)\\n        return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the question, step-by-step solution, and initial answer, please refine and format the final answer. Follow these guidelines:\\n\\n1. Ensure the answer is concise and directly addresses the question.\\n2. If the answer is a number, provide only the number without additional text.\\n3. If multiple correct answers are possible, separate them with a vertical bar (|).\\n4. Remove any explanations or reasoning from the final answer.\\n5. Double-check the numerical calculations and ensure they are correct.\\n6. If the question asks for a specific unit (e.g., years, yards), make sure the answer includes only the number without the unit.\\n\\nYour task is to extract or refine the most accurate answer based on the provided information.\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 14</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.DROP.graphs.round_14.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.answer_generate = operator.AnswerGenerate(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        step_by_step = await self.answer_generate(input=problem)\n        solution = await self.custom(input=problem + f\"\\nStep-by-step thought: {step_by_step['thought']}\\nInitial answer: {step_by_step['answer']}\", instruction=prompt_custom.REFINE_PROMPT)\n        return solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>REFINE_PROMPT = \"\"\"\nGiven the problem, step-by-step thought process, and initial answer, please refine and format the final answer. Ensure that:\n1. The answer is concise and directly addresses the question.\n2. Only include numerical values or short phrases as required by the question.\n3. Do not include explanations or additional context unless specifically asked.\n4. If the answer involves multiple items, separate them with a vertical bar (|).\n\nProblem: {input}\n\nProvide the refined answer:\n\"\"\"</prompt>", "tag": "DROP", "domain": "llm_judge", "parent_round": 13, "child_round": 14, "parent_score": 0.7495098039215685, "child_score": 0.5235294117647058, "performance_gain": -0.22598039215686272}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.87</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_21.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(5):  # Generate 5 solutions\\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        # Add a verification step using the Programmer operator\\n        verification = await self.programmer(problem=problem, analysis=final_solution['response'])\\n        \\n        if verification['output']:\\n            final_answer = verification['output']\\n        else:\\n            final_answer = final_solution['response']\\n\\n        # Final check to ensure the answer is a single number\\n        try:\\n            final_answer = float(final_answer)\\n        except ValueError:\\n            final_answer = float(final_answer.split()[-1])\\n\\n        return str(final_answer), self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>MATH_SOLVE_PROMPT = \\\"\\\"\\\"\\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps carefully:\\n\\n1. Read and understand the problem thoroughly, paying special attention to time-based calculations and total cost considerations including any discounts.\\n2. Identify all key information, variables, and relationships, especially those related to time periods and pricing.\\n3. Determine the appropriate mathematical concepts, formulas, or equations to use, including time conversion if necessary.\\n4. Solve the problem step-by-step, showing all your work clearly.\\n5. For problems involving time:\\n   - Convert all time periods to the same unit (e.g., minutes or hours)\\n   - Calculate the total time period carefully\\n6. For problems involving costs:\\n   - Include all mentioned costs and discounts\\n   - Calculate the total cost, factoring in any discounts or special pricing\\n7. Double-check your calculations and reasoning at each step.\\n8. Provide a clear and concise final answer.\\n9. Verify your solution by plugging it back into the original problem or using an alternative method if possible.\\n\\nFormat your answer as follows:\\n- Use LaTeX notation for mathematical expressions where appropriate.\\n- Show each step of your solution process clearly.\\n- Clearly state your final answer at the end of your solution.\\n- Express numerical answers as precise values (avoid rounding unless specified).\\n- Ensure that your final answer is a single numerical value without any units or additional text.\\n- Do not include any explanatory text with your final answer, just the number itself.\\n\\nFor example, if the final answer is 42.5, your response should end with just:\\n42.5\\n\\nHere's the problem to solve:\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 22</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_22.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\n            solutions.append(solution['response'])\n        \n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Add a verification step using the Programmer operator\n        review_result = await self.programmer(problem=problem, analysis=final_solution['response'])\n        \n        # Add a final review step using the Custom operator\n        final_review = await self.custom(input=f\"Problem: {problem}\\nCalculated answer: {review_result['output']}\", instruction=prompt_custom.FINAL_REVIEW_PROMPT)\n        \n        return final_review['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>MATH_SOLVE_PROMPT = \"\"\"\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps:\n\n1. Carefully read and understand the problem.\n2. Identify the key information and variables.\n3. Determine the appropriate mathematical concepts or formulas to use.\n4. Pay special attention to time-based calculations and unit conversions.\n5. Solve the problem step by step, showing all your work.\n6. Double-check your calculations and reasoning.\n7. Provide a clear and concise final answer.\n\nRemember to format your answer as follows:\n- Use LaTeX notation for mathematical expressions where appropriate.\n- Clearly state your final answer at the end of your solution.\n- Express numerical answers as precise values (avoid rounding unless specified).\n- Ensure that your final answer is a single numerical value without any units or additional text.\n- Do not include any explanatory text with your final answer, just the number itself.\n\nFor example, if the final answer is 42.5, your response should end with just:\n42.5\n\nHere's the problem to solve:\n\n\"\"\"\n\nFINAL_REVIEW_PROMPT = \"\"\"\nReview the given problem and the calculated answer. Ensure that the answer is correct and properly formatted. The final output should be a single numerical value without any units or additional text. If the calculated answer is correct and properly formatted, return it as is. If it needs adjustment, make the necessary changes and return the corrected value.\n\nProblem: {problem}\nCalculated answer: {calculated_answer}\n\nYour task:\n1. Verify the correctness of the calculation.\n2. Check if the answer is a single numerical value without units or additional text.\n3. If needed, adjust the answer to meet the required format.\n4. Return only the final numerical value.\n\nFinal answer:\n\"\"\"</prompt>", "tag": "GSM8K", "domain": "llm_judge", "parent_round": 21, "child_round": 22, "parent_score": 0.87, "child_score": 0.9, "performance_gain": 0.030000000000000027}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>\\nPrevious failed modifications:\\n  - Add a new Custom operator to generate multiple solutions using different approaches, and modify the ScEnsemble operator to select the best solution from a larger pool of candidates. (Score: 0.0)\\n  - Add a new Custom operator to generate a simplified solution, which will be used alongside the existing detailed solution to provide a more comprehensive answer. This simplified solution will be added to the list of solutions for the ScEnsemble operator to consider. (Score: 0.5445378151260505)</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.5630252100840336</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.round_5.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        # Use Programmer to generate and execute Python code\\n        code_solution = await self.programmer(problem=problem)\\n        \\n        # Use Custom to refine and format the answer\\n        refined_solution = await self.custom(input=problem + f\\\"\\\\nCode output: {code_solution['output']}\\\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\\n        \\n        # Generate a detailed step-by-step solution using Custom\\n        detailed_solution = await self.custom(input=problem, instruction=prompt_custom.DETAILED_SOLUTION_PROMPT)\\n        \\n        # Generate multiple solutions using Custom\\n        solutions = [\\n            refined_solution['response'],\\n            detailed_solution['response']\\n        ]\\n        for _ in range(2):\\n            solution = await self.custom(input=problem, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        # Use ScEnsemble to select the best solution\\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>REFINE_ANSWER_PROMPT = \\\"\\\"\\\"\\nGiven the mathematical problem and the output from the code execution, please provide a well-formatted and detailed solution. Follow these guidelines:\\n\\n1. Begin with a clear statement of the problem.\\n2. Explain the approach and any formulas or concepts used.\\n3. Show step-by-step calculations, using LaTeX notation for mathematical expressions.\\n4. Interpret the code output and incorporate it into your explanation.\\n5. Provide a final answer, enclosed in \\\\boxed{} LaTeX notation.\\n6. Ensure all mathematical notation is in LaTeX format.\\n\\nYour response should be comprehensive, mathematically rigorous, and easy to follow.\\n\\\"\\\"\\\"\\n\\nGENERATE_SOLUTION_PROMPT = \\\"\\\"\\\"\\nPlease solve the given mathematical problem step by step. Follow these guidelines:\\n\\n1. State the problem clearly.\\n2. Outline the approach and any relevant formulas or concepts.\\n3. Provide detailed calculations, using LaTeX notation for mathematical expressions.\\n4. Explain each step of your reasoning.\\n5. Present the final answer enclosed in \\\\boxed{} LaTeX notation.\\n6. Ensure all mathematical notation is in LaTeX format.\\n\\nYour solution should be thorough, mathematically sound, and easy to understand.\\n\\\"\\\"\\\"\\n\\nDETAILED_SOLUTION_PROMPT = \\\"\\\"\\\"\\nProvide a comprehensive, step-by-step solution to the given mathematical problem. Your response should include:\\n\\n1. A clear restatement of the problem.\\n2. An explanation of the mathematical concepts and theorems involved.\\n3. A detailed, logical progression of steps leading to the solution.\\n4. Clear explanations for each step, including the reasoning behind it.\\n5. All mathematical expressions and equations in LaTeX format.\\n6. Visual aids or diagrams if applicable (described in text).\\n7. A final answer clearly marked and enclosed in \\\\boxed{} LaTeX notation.\\n8. A brief explanation of the significance of the result, if relevant.\\n\\nEnsure your solution is rigorous, easy to follow, and educational for someone learning the concept.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 6</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.MATH.graphs.round_6.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        # Use Programmer to generate and execute Python code\n        code_solution = await self.programmer(problem=problem)\n        \n        # Use Custom to refine and format the answer\n        refined_answer = await self.custom(input=problem + f\"\\nCode output: {code_solution['output']}\", instruction=prompt_custom.REFINE_ANSWER_PROMPT)\n        \n        # Generate multiple solutions using Custom\n        solutions = []\n        for _ in range(3):\n            solution = await self.custom(input=problem, instruction=prompt_custom.GENERATE_SOLUTION_PROMPT)\n            solutions.append(solution['response'])\n        \n        # Use ScEnsemble to select the most consistent solution\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>REFINE_ANSWER_PROMPT = \"\"\"\nGiven the mathematical problem and the output from the code execution, please provide a well-formatted and detailed solution. Follow these guidelines:\n\n1. Begin with a clear statement of the problem.\n2. Explain the approach and any formulas or concepts used.\n3. Show step-by-step calculations, using LaTeX notation for mathematical expressions.\n4. Interpret the code output and incorporate it into your explanation.\n5. Provide a final answer, enclosed in \\boxed{} LaTeX notation.\n6. Ensure all mathematical notation is in LaTeX format.\n\nYour response should be comprehensive, mathematically rigorous, and easy to follow.\n\"\"\"\n\nGENERATE_SOLUTION_PROMPT = \"\"\"\nPlease solve the given mathematical problem step by step. Follow these guidelines:\n\n1. State the problem clearly.\n2. Outline the approach and any relevant formulas or concepts.\n3. Provide detailed calculations, using LaTeX notation for mathematical expressions.\n4. Explain each step of your reasoning.\n5. Present the final answer in \\boxed{} LaTeX notation.\n6. Ensure all mathematical notation is in LaTeX format.\n\nAim for a clear, concise, and mathematically sound solution.\n\"\"\"</prompt>", "tag": "MATH", "domain": "llm_judge", "parent_round": 5, "child_round": 6, "parent_score": 0.5630252100840336, "child_score": 0.5294117647058824, "performance_gain": -0.03361344537815125}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>Previous successful modifications:\\n  - Add a review step using the Custom operator to analyze the generated solution before testing. This will help identify potential issues and improve the solution quality before running the test cases. (Score: 0.9533333333333334)\\n\\nPrevious failed modifications:\\n  - Add a review step using the Custom operator to analyze the generated solution before testing. This will help identify potential issues and improve the solution quality before running the test cases. (Score: 0.9066666666666666)\\n  - Add a review step using the Custom operator to analyze the generated solution before testing. This will help identify potential issues and improve the solution quality before running the test cases. (Score: 0.9333333333333333)\\n  - Add a review step using the Custom operator to analyze the generated solution before testing. This will help identify potential issues and improve the solution quality before running the test cases. (Score: 0.8866666666666667)</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.9333333333333333</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_5.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        Custom operator to generate anything you want.\\n        But when you want to get standard code, you should use custom_code_generate operator.\\n        \\\"\\\"\\\"\\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=\\\"\\\")\\n        test_result = await self.test(problem=problem, solution=solution['response'], entry_point=entry_point)\\n        \\n        if test_result['result']:\\n            return test_result['solution'], self.llm.cost_manager.total_cost\\n        else:\\n            # If the test fails, try to generate a new solution\\n            new_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.IMPROVE_CODE_PROMPT)\\n            return new_solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>IMPROVE_CODE_PROMPT = \\\"\\\"\\\"\\nThe previous solution failed some test cases. Please analyze the problem carefully and provide an improved solution that addresses all edge cases and requirements. Ensure your code is efficient and follows best practices.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 6</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_6.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\n        \n        # Self-review step\n        review = await self.custom(input=f\"Problem: {problem}\\nGenerated solution: {solution['response']}\", instruction=prompt_custom.SELF_REVIEW_PROMPT)\n        \n        # Improve the solution based on the review\n        improved_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\"{prompt_custom.CODE_GENERATE_PROMPT}\\n\\nConsider this review: {review['response']}\")\n        \n        test_result = await self.test(problem=problem, solution=improved_solution['response'], entry_point=entry_point)\n        \n        if not test_result['result']:\n            analysis = await self.custom(input=f\"Problem: {problem}\\nFailed solution: {improved_solution['response']}\\nTest result: {test_result['solution']}\", instruction=prompt_custom.ANALYZE_AND_IMPROVE_PROMPT)\n            final_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\"{prompt_custom.CODE_GENERATE_PROMPT}\\n\\nConsider this analysis: {analysis['response']}\")\n            return final_solution['response'], self.llm.cost_manager.total_cost\n        \n        return improved_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>CODE_GENERATE_PROMPT = \"\"\"\nGenerate a Python function that solves the given problem. Ensure the function signature matches the problem description. Include docstrings and comments to explain the logic. The solution should be efficient and handle edge cases.\n\"\"\"\n\nSELF_REVIEW_PROMPT = \"\"\"\nReview the generated solution and provide feedback on its correctness, efficiency, and adherence to best practices. Consider the following:\n1. Does the solution correctly implement the problem requirements?\n2. Are there any potential edge cases that are not handled?\n3. Can the code be optimized for better performance?\n4. Does the code follow Python best practices and style guidelines?\n5. Are there any logical errors or potential bugs?\nProvide specific suggestions for improvements if necessary.\n\"\"\"\n\nANALYZE_AND_IMPROVE_PROMPT = \"\"\"\nAnalyze the failed solution and provide suggestions for improvement. Consider the following:\n1. Identify logical errors or misunderstandings of the problem.\n2. Check for edge cases that might not be handled correctly.\n3. Suggest optimizations or alternative approaches if applicable.\n4. Provide specific code snippets or pseudocode to address the issues found.\n\"\"\"</prompt>", "tag": "HumanEval", "domain": "llm_judge", "parent_round": 5, "child_round": 6, "parent_score": 0.9333333333333333, "child_score": 0.9333333333333333, "performance_gain": 0.0}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.8666666666666667</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_9.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\\n        \\n        # Add a review step\\n        review = await self.custom(input=f\\\"Problem: {problem}\\\\nGenerated solution: {solution['response']}\\\", instruction=prompt_custom.REVIEW_PROMPT)\\n        \\n        if \\\"No issues found\\\" not in review['response']:\\n            # If issues are found, generate an improved solution\\n            improved_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\\\"{prompt_custom.CODE_GENERATE_PROMPT}\\\\n\\\\nConsider this review: {review['response']}\\\")\\n            solution = improved_solution\\n        \\n        test_result = await self.test(problem=problem, solution=solution['response'], entry_point=entry_point)\\n        \\n        if not test_result['result']:\\n            # Comprehensive analysis of the problem and failed solution\\n            analysis = await self.custom(input=f\\\"Problem: {problem}\\\\nFailed solution: {solution['response']}\\\\nTest result: {test_result['solution']}\\\", instruction=prompt_custom.COMPREHENSIVE_ANALYSIS_PROMPT)\\n            \\n            # Generate improved solution based on the comprehensive analysis\\n            improved_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\\\"{prompt_custom.CODE_GENERATE_PROMPT}\\\\n\\\\nConsider this analysis: {analysis['response']}\\\")\\n            \\n            # Test the improved solution\\n            improved_test_result = await self.test(problem=problem, solution=improved_solution['response'], entry_point=entry_point)\\n            \\n            if improved_test_result['result']:\\n                return improved_solution['response'], self.llm.cost_manager.total_cost\\n            else:\\n                # If the improved solution still fails, return the original solution\\n                return solution['response'], self.llm.cost_manager.total_cost\\n        \\n        return solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>CODE_GENERATE_PROMPT = \\\"\\\"\\\"\\nGenerate a Python function that solves the given problem. Ensure the function signature matches the problem description. Include docstrings and comments to explain the logic. The solution should be efficient and handle edge cases.\\n\\\"\\\"\\\"\\n\\nREVIEW_PROMPT = \\\"\\\"\\\"\\nReview the generated solution for the given problem. Check for:\\n1. Correctness of the function signature\\n2. Proper implementation of the problem requirements\\n3. Efficient use of data structures and algorithms\\n4. Proper handling of edge cases\\n5. Clear and helpful comments and docstrings\\n\\nIf you find any issues, explain them clearly. If no issues are found, respond with \\\"No issues found.\\\"\\n\\\"\\\"\\\"\\n\\nCOMPREHENSIVE_ANALYSIS_PROMPT = \\\"\\\"\\\"\\nPerform a comprehensive analysis of the problem and the failed solution. Consider the following aspects:\\n\\n1. Problem understanding: Identify any potential misinterpretations of the problem statement.\\n2. Logical errors: Pinpoint any flaws in the solution's logic or algorithm.\\n3. Edge cases: Determine if all possible input scenarios are properly handled.\\n4. Efficiency: Evaluate the time and space complexity of the solution.\\n5. Coding style: Assess the readability and adherence to Python best practices.\\n6. Test case failures: Analyze why specific test cases are failing.\\n7. Alternative approaches: Suggest different algorithms or data structures that might be more suitable.\\n\\nProvide a detailed breakdown of these aspects and suggest specific improvements for each identified issue.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 10</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_10.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        \"\"\"\n        Implementation of the graph\n        Custom operator to generate anything you want.\n        But when you want to get standard code, you should use custom_code_generate operator.\n        \"\"\"\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=\"\")\n        \n        # Add a review step\n        review_result = await self.custom(input=problem + f\"\\nGenerated solution:\\n{solution['response']}\", instruction=prompt_custom.REVIEW_CODE_PROMPT)\n        \n        if \"improvements needed\" in review_result['response'].lower():\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.IMPROVE_CODE_PROMPT)\n        \n        test_result = await self.test(problem=problem, solution=solution['response'], entry_point=entry_point)\n        \n        if test_result['result']:\n            return test_result['solution'], self.llm.cost_manager.total_cost\n        else:\n            # If the test fails, try to generate a new solution\n            new_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.IMPROVE_CODE_PROMPT)\n            return new_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>IMPROVE_CODE_PROMPT = \"\"\"\nThe previous solution failed some test cases. Please analyze the problem carefully and provide an improved solution that addresses all edge cases and requirements. Ensure your code is efficient and follows best practices.\n\"\"\"\n\nREVIEW_CODE_PROMPT = \"\"\"\nPlease review the following code solution and provide feedback. Analyze the code for potential issues, edge cases, and adherence to the problem requirements. If you find any areas for improvement, please respond with \"Improvements needed:\" followed by a brief explanation. If the code appears to be correct and efficient, respond with \"No improvements needed.\"\n\"\"\"</prompt>", "tag": "HumanEval", "domain": "llm_judge", "parent_round": 9, "child_round": 10, "parent_score": 0.8666666666666667, "child_score": 0.9333333333333333, "performance_gain": 0.06666666666666665}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve code problems.\\nReferring to the given graph and prompt, which forms a basic example of a code solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.8666666666666667</score>\\n    <graph>from typing import Literal\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_15.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\\n        self.test = operator.Test(self.llm)\\n\\n    async def __call__(self, problem: str, entry_point: str):\\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.CODE_GENERATE_PROMPT)\\n        \\n        # Add a review step\\n        review = await self.custom(input=f\\\"Problem: {problem}\\\\nGenerated solution: {solution['response']}\\\", instruction=prompt_custom.REVIEW_PROMPT)\\n        \\n        # If review suggests improvements, apply them\\n        if \\\"No improvements needed\\\" not in review['response']:\\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\\\"{prompt_custom.CODE_GENERATE_PROMPT}\\\\n\\\\nConsider these improvements: {review['response']}\\\")\\n        \\n        test_result = await self.test(problem=problem, solution=solution['response'], entry_point=entry_point)\\n        \\n        if not test_result['result']:\\n            # Comprehensive analysis of the problem and failed solution\\n            analysis = await self.custom(input=f\\\"Problem: {problem}\\\\nFailed solution: {solution['response']}\\\\nTest result: {test_result['solution']}\\\", instruction=prompt_custom.COMPREHENSIVE_ANALYSIS_PROMPT)\\n            \\n            # Generate improved solution based on the comprehensive analysis\\n            improved_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=f\\\"{prompt_custom.CODE_GENERATE_PROMPT}\\\\n\\\\nConsider this analysis: {analysis['response']}\\\")\\n            \\n            # Test the improved solution\\n            improved_test_result = await self.test(problem=problem, solution=improved_solution['response'], entry_point=entry_point)\\n            \\n            if improved_test_result['result']:\\n                return improved_solution['response'], self.llm.cost_manager.total_cost\\n            else:\\n                # If the improved solution still fails, return the original solution\\n                return solution['response'], self.llm.cost_manager.total_cost\\n        \\n        return solution['response'], self.llm.cost_manager.total_cost\\n</graph>\\n    <prompt>CODE_GENERATE_PROMPT = \\\"\\\"\\\"\\nGenerate a Python function that solves the given problem. Ensure the function signature matches the problem description. Include docstrings and comments to explain the logic. The solution should be efficient and handle edge cases.\\n\\\"\\\"\\\"\\n\\nREVIEW_PROMPT = \\\"\\\"\\\"\\nReview the generated solution for the given problem. Check for:\\n1. Correctness: Does the solution solve the problem as described?\\n2. Efficiency: Is the solution optimized for performance?\\n3. Readability: Is the code well-structured and easy to understand?\\n4. Edge cases: Are all possible scenarios handled?\\n5. Python best practices: Does the code follow PEP 8 and other Python conventions?\\n\\nIf improvements are needed, provide specific suggestions. If no improvements are needed, state \\\"No improvements needed\\\".\\n\\\"\\\"\\\"\\n\\nCOMPREHENSIVE_ANALYSIS_PROMPT = \\\"\\\"\\\"\\nPerform a comprehensive analysis of the problem and the failed solution. Consider the following aspects:\\n\\n1. Problem understanding: Identify any potential misinterpretations of the problem statement.\\n2. Logical errors: Pinpoint any flaws in the solution's logic or algorithm.\\n3. Edge cases: Determine if all possible input scenarios are properly handled.\\n4. Efficiency: Evaluate the time and space complexity of the solution.\\n5. Coding style: Assess the readability and adherence to Python best practices.\\n6. Test case failures: Analyze why specific test cases are failing.\\n7. Alternative approaches: Suggest different algorithms or data structures that might be more suitable.\\n\\nProvide a detailed breakdown of these aspects and suggest specific improvements for each identified issue.\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 16</modification>\n<graph>from typing import Literal\nimport examples.aflow.scripts.optimized.HumanEval.graphs.template.operator as operator\nimport examples.aflow.scripts.optimized.HumanEval.graphs.round_16.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.custom_code_generate = operator.CustomCodeGenerate(self.llm)\n        self.test = operator.Test(self.llm)\n\n    async def __call__(self, problem: str, entry_point: str):\n        solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=\"\")\n        \n        # Add a review step\n        review = await self.custom(input=problem + f\"\\nGenerated solution:\\n{solution['response']}\", instruction=prompt_custom.REVIEW_PROMPT)\n        \n        if \"No issues found\" not in review['response']:\n            # If issues are found, regenerate the solution\n            solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.IMPROVE_CODE_PROMPT + f\"\\nReview feedback: {review['response']}\")\n        \n        test_result = await self.test(problem=problem, solution=solution['response'], entry_point=entry_point)\n        \n        if test_result['result']:\n            return test_result['solution'], self.llm.cost_manager.total_cost\n        else:\n            # If the test fails, try to generate a new solution\n            new_solution = await self.custom_code_generate(problem=problem, entry_point=entry_point, instruction=prompt_custom.IMPROVE_CODE_PROMPT)\n            return new_solution['response'], self.llm.cost_manager.total_cost\n</graph>\n<prompt>IMPROVE_CODE_PROMPT = \"\"\"\nThe previous solution failed some test cases. Please analyze the problem carefully and provide an improved solution that addresses all edge cases and requirements. Ensure your code is efficient and follows best practices.\n\"\"\"\n\nREVIEW_PROMPT = \"\"\"\nReview the generated solution and identify any potential issues, edge cases, or improvements. If no issues are found, respond with 'No issues found'. Otherwise, provide a brief description of the issues and suggested improvements.\n\"\"\"</prompt>", "tag": "HumanEval", "domain": "llm_judge", "parent_round": 15, "child_round": 16, "parent_score": 0.8666666666666667, "child_score": 0.9666666666666667, "performance_gain": 0.09999999999999998}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.87</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_6.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(3):\\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        # Add a review step using the Programmer operator\\n        review_result = await self.programmer(problem=problem, analysis=final_solution['response'])\\n        \\n        if review_result['output']:\\n            return review_result['output'], self.llm.cost_manager.total_cost\\n        else:\\n            return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>MATH_SOLVE_PROMPT = \\\"\\\"\\\"\\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps:\\n\\n1. Carefully read and understand the problem.\\n2. Identify the key information and variables.\\n3. Determine the appropriate mathematical concepts or formulas to use.\\n4. Solve the problem step by step, showing all your work.\\n5. Double-check your calculations and reasoning.\\n6. Provide a clear and concise final answer.\\n7. Format your final answer as a single numerical value without units or additional text.\\n\\nRemember to format your answer as follows:\\n- Use LaTeX notation for mathematical expressions where appropriate.\\n- Clearly state your final answer at the end of your solution.\\n- Express numerical answers as precise values (avoid rounding unless specified).\\n- Ensure that your final answer is a single numerical value without any units or additional text.\\n\\nHere's the problem to solve:\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 7</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_7.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\n            solutions.append(solution['response'])\n        \n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Add a verification step using the Programmer operator\n        verification_result = await self.programmer(problem=problem, analysis=final_solution['response'])\n        \n        if verification_result['output']:\n            return verification_result['output'], self.llm.cost_manager.total_cost\n        else:\n            return final_solution['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>MATH_SOLVE_PROMPT = \"\"\"\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps:\n\n1. Carefully read and understand the problem.\n2. Identify the key information and variables.\n3. Determine the appropriate mathematical concepts or formulas to use.\n4. Solve the problem step by step, showing all your work.\n5. Double-check your calculations and reasoning.\n6. Provide a clear and concise final answer.\n\nImportant considerations:\n- Pay special attention to problems involving discounts. Calculate the discounted amount correctly and subtract it from the original price.\n- When dealing with multiple item purchases, ensure you account for all items and their respective prices or quantities.\n- For problems involving time calculations, convert all time units to a common unit (e.g., hours or minutes) before performing calculations.\n\nRemember to format your answer as follows:\n- Use LaTeX notation for mathematical expressions where appropriate.\n- Clearly state your final answer at the end of your solution.\n- Express numerical answers as precise values (avoid rounding unless specified).\n- Ensure that your final answer is a single numerical value without any units or additional text.\n\nHere's the problem to solve:\n\n\"\"\"</prompt>", "tag": "GSM8K", "domain": "llm_judge", "parent_round": 6, "child_round": 7, "parent_score": 0.87, "child_score": 0.89, "performance_gain": 0.020000000000000018}
{"messages": "[{\"role\": \"system\", \"content\": \"You are building a Graph and corresponding Prompt to jointly solve math problems.\\nReferring to the given graph and prompt, which forms a basic example of a math solution approach,\\nplease reconstruct and optimize them. You can add, modify, or delete nodes, parameters, or prompts. Include your\\nsingle modification in XML tags in your reply. Ensure they are complete and correct to avoid runtime failures. When\\noptimizing, you can incorporate critical thinking methods like review, revise, ensemble (generating multiple answers through different/similar prompts, then voting/integrating/checking the majority to obtain a final answer), selfAsk, etc. Consider\\nPython's loops (for, while, list comprehensions), conditional statements (if-elif-else, ternary operators),\\nor machine learning techniques (e.g., linear regression, decision trees, neural networks, clustering). The graph\\ncomplexity should not exceed 10. Use logical and control flow (IF-ELSE, loops) for a more enhanced graphical\\nrepresentation.Ensure that all the prompts required by the current graph from prompt_custom are included.Exclude any other prompts.\\nOutput the modified graph and all the necessary Prompts in prompt_custom (if needed).\\nThe prompt you need to generate is only the one used in `prompt_custom.XXX` within Custom. Other methods already have built-in prompts and are prohibited from being generated. Only generate those needed for use in `prompt_custom`; please remove any unused prompts in prompt_custom.\\nthe generated prompt must not contain any placeholders.\\nConsidering information loss, complex graphs may yield better results, but insufficient information transmission can omit the solution. It's crucial to include necessary context during the process.\"}, {\"role\": \"user\", \"content\": \"\\nHere is a graph and the corresponding prompt (prompt only related to the custom method) that performed excellently in a previous iteration (maximum score is 1). You must make further optimizations and improvements based on this graph. The modified graph must differ from the provided example, and the specific differences should be noted within the <modification>xxx</modification> section.\\n\\n<sample>\\n    <experience>No previous experience available.</experience>\\n    <modification>(such as:add /delete /modify/ ...)</modification>\\n    <score>0.81</score>\\n    <graph>from typing import Literal\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_23.prompt as prompt_custom\\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\\nfrom metagpt.utils.cost_manager import CostManager\\n\\nDatasetType = Literal[\\\"HumanEval\\\", \\\"MBPP\\\", \\\"GSM8K\\\", \\\"MATH\\\", \\\"HotpotQA\\\", \\\"DROP\\\"]\\n\\nclass Workflow:\\n    def __init__(\\n        self,\\n        name: str,\\n        llm_config,\\n        dataset: DatasetType,\\n    ) -> None:\\n        self.name = name\\n        self.dataset = dataset\\n        self.llm = create_llm_instance(llm_config)\\n        self.llm.cost_manager = CostManager()\\n        self.custom = operator.Custom(self.llm)\\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\\n        self.programmer = operator.Programmer(self.llm)\\n\\n    async def __call__(self, problem: str):\\n        \\\"\\\"\\\"\\n        Implementation of the graph\\n        \\\"\\\"\\\"\\n        solutions = []\\n        for _ in range(5):  # Generate 5 solutions\\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\\n            solutions.append(solution['response'])\\n        \\n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\\n        \\n        # Add a verification step using the Programmer operator\\n        verification = await self.programmer(problem=problem, analysis=final_solution['response'])\\n        \\n        # Double-check the total cost calculation\\n        total_cost_check = await self.custom(input=problem + f\\\"\\\\nPrevious solution: {final_solution['response']}\\\", instruction=prompt_custom.TOTAL_COST_CHECK_PROMPT)\\n        \\n        if verification['output'] and total_cost_check['response']:\\n            return total_cost_check['response'], self.llm.cost_manager.total_cost\\n        else:\\n            return final_solution['response'], self.llm.cost_manager.total_cost\\n                    </graph>\\n    <prompt>MATH_SOLVE_PROMPT = \\\"\\\"\\\"\\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps carefully:\\n\\n1. Read and understand the problem thoroughly.\\n2. Identify all key information, variables, and relationships, including multiple items and any discounts mentioned.\\n3. Determine the appropriate mathematical concepts, formulas, or equations to use.\\n4. Solve the problem step-by-step, showing all your work clearly.\\n5. Calculate the total cost, considering all items and applying any discounts mentioned in the problem.\\n6. Double-check your calculations and reasoning at each step.\\n7. Provide a clear and concise final answer.\\n8. Verify your solution by plugging it back into the original problem or using an alternative method if possible.\\n\\nFormat your answer as follows:\\n- Use LaTeX notation for mathematical expressions where appropriate.\\n- Show each step of your solution process clearly.\\n- Clearly state your final answer at the end of your solution.\\n- Express numerical answers as precise values (avoid rounding unless specified).\\n- Ensure that your final answer is a single numerical value without any units or additional text.\\n- Do not include any explanatory text with your final answer, just the number itself.\\n\\nFor example, if the final answer is 42.5, your response should end with just:\\n42.5\\n\\nHere's the problem to solve:\\n\\n\\\"\\\"\\\"\\n\\nTOTAL_COST_CHECK_PROMPT = \\\"\\\"\\\"\\nYou are a detail-oriented accountant tasked with double-checking a total cost calculation. Review the given problem and the previous solution, then recalculate the total cost, paying special attention to:\\n\\n1. All items mentioned in the problem\\n2. Any discounts or special pricing\\n3. Quantities of each item\\n\\nProvide only the final total cost as a single numerical value, without any units or additional text. If you find an error in the previous solution, correct it in your calculation.\\n\\nHere's the problem and previous solution:\\n\\n\\\"\\\"\\\"</prompt>(only prompt_custom)\\n    <operator_description>Available operators:\\n- Custom: Flexible LLM call with custom instruction\\n- ScEnsemble: Self-consistency ensemble with voting\\n- Programmer: Generate and execute Python code\\n- Test: Code testing and reflection\\n- Review: Critical evaluation\\n- Revise: Improve based on feedback\\n- AnswerGenerate: Structured thinking + answer generation</operator_description>\\n</sample>\\nBelow are the logs of some results with the aforementioned Graph that performed well but encountered errors, which can be used as references for optimization:\\n\\n\\nFirst, provide optimization ideas. **Only one detail point can be modified at a time**, and no more than 5 lines of code may be changed per modification\u2014extensive modifications are strictly prohibited to maintain project focus!\\nWhen introducing new functionalities in the graph, please make sure to import the necessary libraries or modules yourself, except for operator, prompt_custom, create_llm_instance, and CostManage, which have already been automatically imported.\\n**Under no circumstances should Graph output None for any field.**\\nUse custom methods to restrict your output format, rather than using code (outside of the code, the system will extract answers based on certain rules and score them).\\nIt is very important to format the Graph output answers, you can refer to the standard answer format in the log.\\nYou do not need to manually import prompt_custom or operator to use them; they are already included in the execution environment.\\n\"}]", "ground_truth": "<modification>Optimization in round 24</modification>\n<graph>from typing import Literal\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.template.operator as operator\nimport metagpt.ext.aflow.scripts.optimized.Gsm8K.graphs.round_24.prompt as prompt_custom\nfrom metagpt.provider.llm_provider_registry import create_llm_instance\nfrom metagpt.utils.cost_manager import CostManager\n\nDatasetType = Literal[\"HumanEval\", \"MBPP\", \"GSM8K\", \"MATH\", \"HotpotQA\", \"DROP\"]\n\nclass Workflow:\n    def __init__(\n        self,\n        name: str,\n        llm_config,\n        dataset: DatasetType,\n    ) -> None:\n        self.name = name\n        self.dataset = dataset\n        self.llm = create_llm_instance(llm_config)\n        self.llm.cost_manager = CostManager()\n        self.custom = operator.Custom(self.llm)\n        self.sc_ensemble = operator.ScEnsemble(self.llm)\n        self.programmer = operator.Programmer(self.llm)\n\n    async def __call__(self, problem: str):\n        \"\"\"\n        Implementation of the graph\n        \"\"\"\n        solutions = []\n        for _ in range(3):\n            solution = await self.custom(input=problem, instruction=prompt_custom.MATH_SOLVE_PROMPT)\n            solutions.append(solution['response'])\n        \n        final_solution = await self.sc_ensemble(solutions=solutions, problem=problem)\n        \n        # Add a verification step using the Programmer operator\n        verification_result = await self.programmer(problem=problem, analysis=final_solution['response'])\n        \n        # Add a final review step using the Custom operator\n        review_result = await self.custom(input=f\"Problem: {problem}\\nCalculated answer: {verification_result['output']}\", instruction=prompt_custom.FINAL_REVIEW_PROMPT)\n        \n        return review_result['response'], self.llm.cost_manager.total_cost\n                    </graph>\n<prompt>MATH_SOLVE_PROMPT = \"\"\"\nYou are a highly skilled mathematician tasked with solving a math problem. Follow these steps:\n\n1. Carefully read and understand the problem.\n2. Identify the key information and variables.\n3. Determine the appropriate mathematical concepts or formulas to use.\n4. Pay special attention to time-based calculations and unit conversions.\n5. Solve the problem step by step, showing all your work.\n6. Double-check your calculations and reasoning.\n7. Provide a clear and concise final answer.\n\nRemember to format your answer as follows:\n- Use LaTeX notation for mathematical expressions where appropriate.\n- Clearly state your final answer at the end of your solution.\n- Express numerical answers as precise values (avoid rounding unless specified).\n- Ensure that your final answer is a single numerical value without any units or additional text.\n- Do not include any explanatory text with your final answer, just the number itself.\n\nFor example, if the final answer is 42.5, your response should end with just:\n42.5\n\nHere's the problem to solve:\n\n\"\"\"\n\nFINAL_REVIEW_PROMPT = \"\"\"\nYou are a meticulous reviewer tasked with ensuring the correctness and proper formatting of a mathematical solution. Please review the problem and the calculated answer, then follow these steps:\n\n1. Verify that the answer is logically consistent with the problem statement.\n2. Check if the answer is a single numerical value without any units or additional text.\n3. If the answer includes units or explanatory text, remove them and keep only the numerical value.\n4. If the answer is not a single numerical value, attempt to extract or calculate the correct single numerical value based on the problem and the given answer.\n5. Ensure the final answer is expressed as a precise value (avoid rounding unless specified in the original problem).\n\nProvide your final reviewed answer as a single numerical value without any additional text or explanation.\n\n\"\"\"</prompt>", "tag": "GSM8K", "domain": "llm_judge", "parent_round": 23, "child_round": 24, "parent_score": 0.81, "child_score": 0.88, "performance_gain": 0.06999999999999995}
